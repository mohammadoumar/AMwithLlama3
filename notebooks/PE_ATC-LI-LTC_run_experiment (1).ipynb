{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "671272c9-0c9d-4265-a75b-480471345729",
   "metadata": {},
   "source": [
    "# Run Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1165cbdc-bb7a-48d3-b17d-442687c00173",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3de7add-5182-4d9f-af93-5446726c9d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e11ea0-ff3f-44eb-9577-5eedba91e3cc",
   "metadata": {},
   "source": [
    "## Run notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d31e870a-6452-42fb-9206-19e4e4da5e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"unsloth/llama-3-8b-Instruct-bnb-4bit\", \n",
    "    \"unsloth/llama-3-8b-Instruct\", \n",
    "    # \"unsloth/llama-3-70b-Instruct-bnb-4bit\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73d02aa6-1840-4b3e-a5c3-a283f3884c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\n",
    "    # Paragraph level\n",
    "    [\"PE_ATC-LI-LTC_paragraph_train.json\", \"PE_ATC-LI-LTC_paragraph_test.json\"],\n",
    "    [\"PE_ATC-LI-LTC_paragraph_wo_tags_train.json\", \"PE_ATC-LI-LTC_paragraph_wo_tags_test.json\"], \n",
    "    # Essay level\n",
    "    #[\"PE_ATC-LI-LTC_essay_train.json\", \"PE_ATC-LI-LTC_essay_test.json\"],\n",
    "    [\"PE_ATC-LI-LTC_essay_wo_tags_train.json\", \"PE_ATC-LI-LTC_essay_wo_tags_test.json\"]    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd041309-0821-4132-ad90-94835c839690",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running experiment: ['unsloth/llama-3-8b-Instruct-bnb-4bit', 'PE_ATC-LI-LTC_paragraph_train.json', 'PE_ATC-LI-LTC_paragraph_test.json']\n",
      "/Utilisateurs/umushtaq/LLaMA-Factory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Utilisateurs/umushtaq/.conda/envs/llama-factory-notebook/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/14/2024 14:16:29 - WARNING - llamafactory.hparams.parser - We recommend enable `upcast_layernorm` in quantized training.\n",
      "06/14/2024 14:16:29 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: torch.float16\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 14:16:29,956 >> loading file tokenizer.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 14:16:29,956 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 14:16:29,957 >> loading file special_tokens_map.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 14:16:29,957 >> loading file tokenizer_config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/tokenizer_config.json\n",
      "[WARNING|logging.py:314] 2024-06-14 14:16:30,223 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "06/14/2024 14:16:30 - INFO - llamafactory.data.template - Replace eos token: <|eot_id|>\n",
      "06/14/2024 14:16:30 - INFO - llamafactory.data.loader - Loading dataset /Utilisateurs/umushtaq/datasets/PE_ATC-LI-LTC_paragraph_train.json...\n",
      "input_ids:\n",
      "[128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 18328, 13, 128009, 128006, 882, 128007, 271, 14711, 1472, 527, 459, 6335, 304, 14138, 26917, 13, 1472, 527, 2728, 264, 14646, 902, 5727, 5811, 6956, 44910, 555, 366, 1741, 1500, 1741, 29, 9681, 13, 4718, 3465, 374, 311, 49229, 279, 5811, 6956, 439, 1664, 439, 311, 10765, 323, 49229, 5811, 4398, 1990, 5811, 6956, 304, 279, 14646, 13, 1789, 1855, 5811, 3777, 11, 1202, 10807, 955, 320, 496, 8, 374, 3060, 330, 35575, 46644, 498, 330, 46644, 1, 477, 330, 42562, 1082, 3343, 1789, 1855, 5811, 12976, 320, 5775, 10807, 320, 396, 705, 2592, 10807, 320, 396, 5850, 1202, 2723, 955, 320, 496, 8, 374, 3060, 330, 8075, 1, 477, 330, 29702, 3343, 1472, 2011, 471, 1403, 11725, 304, 2768, 4823, 3645, 25, 5324, 1638, 24297, 9962, 794, 510, 1741, 955, 320, 496, 705, 61453, 10807, 955, 320, 496, 26090, 330, 1638, 9202, 95321, 8543, 9962, 794, 4416, 5775, 10807, 320, 396, 705, 2592, 10807, 320, 396, 705, 2723, 955, 320, 496, 26090, 61453, 510, 5775, 10807, 320, 396, 705, 2592, 10807, 320, 396, 705, 2723, 955, 320, 496, 8, 5163, 633, 14711, 5810, 374, 279, 14646, 1495, 25, 366, 16816, 29, 12540, 4236, 387, 15972, 311, 20874, 477, 311, 47903, 949, 694, 16816, 29, 128009, 128006, 78191, 128007, 271, 5018, 1638, 24297, 9962, 794, 10277, 330, 1638, 9202, 95321, 8543, 9962, 794, 3132, 92, 128009]\n",
      "inputs:\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "### You are an expert in Argument Mining. You are given a paragraph which contains argument components enclosed by <AC></AC> tags. Your task is to classify the argument components as well as to identify and classify argument relations between argument components in the paragraph. For each argument component, its AC type (str) is either \"MajorClaim\", \"Claim\" or \"Premise\". For each argument relation (target AC (int), source AC (int)), its link type (str) is either \"Support\" or \"Attack\". You must return two lists in following JSON format: {\"list_component_types\": [AC type (str),..., AC type (str)], \"list_argument_relations_and_types\": [[target AC (int), source AC (int), link type (str)],..., [target AC (int), source AC (int), link type (str)]]}\n",
      "\n",
      "### Here is the paragraph text: <topic> Should students be taught to compete or to cooperate? </topic><|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\"list_component_types\": [], \"list_argument_relations_and_types\": []}<|eot_id|>\n",
      "label_ids:\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 5018, 1638, 24297, 9962, 794, 10277, 330, 1638, 9202, 95321, 8543, 9962, 794, 3132, 92, 128009]\n",
      "labels:\n",
      "{\"list_component_types\": [], \"list_argument_relations_and_types\": []}<|eot_id|>\n",
      "/Utilisateurs/umushtaq/.conda/envs/llama-factory-notebook/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "[INFO|configuration_utils.py:733] 2024-06-14 14:16:30,797 >> loading configuration file config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/config.json\n",
      "[INFO|configuration_utils.py:796] 2024-06-14 14:16:30,798 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"_load_in_4bit\": true,\n",
      "    \"_load_in_8bit\": false,\n",
      "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "    \"bnb_4bit_quant_type\": \"nf4\",\n",
      "    \"bnb_4bit_use_double_quant\": true,\n",
      "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "    \"llm_int8_has_fp16_weight\": false,\n",
      "    \"llm_int8_skip_modules\": null,\n",
      "    \"llm_int8_threshold\": 6.0,\n",
      "    \"load_in_4bit\": true,\n",
      "    \"load_in_8bit\": false,\n",
      "    \"quant_method\": \"bitsandbytes\"\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "06/14/2024 14:16:30 - INFO - llamafactory.model.utils.quantization - Loading ?-bit BITSANDBYTES-quantized model.\n",
      "[WARNING|quantization_config.py:393] 2024-06-14 14:16:30,867 >> Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "[INFO|modeling_utils.py:3474] 2024-06-14 14:16:30,870 >> loading weights file model.safetensors from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/model.safetensors\n",
      "[INFO|modeling_utils.py:1519] 2024-06-14 14:16:30,901 >> Instantiating LlamaForCausalLM model under default dtype torch.float16.\n",
      "[INFO|configuration_utils.py:962] 2024-06-14 14:16:30,905 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:4280] 2024-06-14 14:16:34,137 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4288] 2024-06-14 14:16:34,137 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at unsloth/llama-3-8b-Instruct-bnb-4bit.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:917] 2024-06-14 14:16:34,246 >> loading configuration file generation_config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/generation_config.json\n",
      "[INFO|configuration_utils.py:962] 2024-06-14 14:16:34,246 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128009\n",
      "  ]\n",
      "}\n",
      "\n",
      "06/14/2024 14:16:34 - INFO - llamafactory.model.utils.checkpointing - Gradient checkpointing enabled.\n",
      "06/14/2024 14:16:34 - INFO - llamafactory.model.utils.attention - Using torch SDPA for faster training and inference.\n",
      "06/14/2024 14:16:34 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n",
      "06/14/2024 14:16:34 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n",
      "06/14/2024 14:16:34 - INFO - llamafactory.model.utils.misc - Found linear modules: v_proj,q_proj,up_proj,k_proj,gate_proj,down_proj,o_proj\n",
      "06/14/2024 14:16:34 - INFO - llamafactory.model.loader - trainable params: 20971520 || all params: 8051232768 || trainable%: 0.2605\n",
      "[INFO|trainer.py:641] 2024-06-14 14:16:34,703 >> Using auto half precision backend\n",
      "06/14/2024 14:16:34 - WARNING - llamafactory.extras.callbacks - Previous trainer log in this folder will be deleted.\n",
      "06/14/2024 14:16:34 - INFO - llamafactory.train.utils - Using LoRA+ optimizer with loraplus lr ratio 16.00.\n",
      "[INFO|trainer.py:2078] 2024-06-14 14:16:34,911 >> ***** Running training *****\n",
      "[INFO|trainer.py:2079] 2024-06-14 14:16:34,911 >>   Num examples = 1,796\n",
      "[INFO|trainer.py:2080] 2024-06-14 14:16:34,911 >>   Num Epochs = 10\n",
      "[INFO|trainer.py:2081] 2024-06-14 14:16:34,911 >>   Instantaneous batch size per device = 2\n",
      "[INFO|trainer.py:2084] 2024-06-14 14:16:34,911 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "[INFO|trainer.py:2085] 2024-06-14 14:16:34,911 >>   Gradient Accumulation steps = 4\n",
      "[INFO|trainer.py:2086] 2024-06-14 14:16:34,911 >>   Total optimization steps = 2,240\n",
      "[INFO|trainer.py:2087] 2024-06-14 14:16:34,914 >>   Number of trainable parameters = 20,971,520\n",
      "{'loss': 0.5251, 'grad_norm': 3.43926739692688, 'learning_rate': 2.0089285714285715e-06, 'epoch': 0.04}\n",
      "{'loss': 0.1526, 'grad_norm': 1.0216894149780273, 'learning_rate': 4.241071428571429e-06, 'epoch': 0.09}\n",
      "{'loss': 0.1125, 'grad_norm': 0.5761942267417908, 'learning_rate': 6.473214285714287e-06, 'epoch': 0.13}\n",
      "{'loss': 0.0868, 'grad_norm': 0.833625078201294, 'learning_rate': 8.705357142857143e-06, 'epoch': 0.18}\n",
      "{'loss': 0.0931, 'grad_norm': 0.5239991545677185, 'learning_rate': 1.09375e-05, 'epoch': 0.22}\n",
      "{'loss': 0.075, 'grad_norm': 0.4471679925918579, 'learning_rate': 1.3169642857142858e-05, 'epoch': 0.27}\n",
      "{'loss': 0.0613, 'grad_norm': 0.21281279623508453, 'learning_rate': 1.5401785714285715e-05, 'epoch': 0.31}\n",
      "{'loss': 0.0512, 'grad_norm': 0.5125253200531006, 'learning_rate': 1.7633928571428573e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0556, 'grad_norm': 0.385680615901947, 'learning_rate': 1.9866071428571427e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0565, 'grad_norm': 0.5948638916015625, 'learning_rate': 2.2098214285714286e-05, 'epoch': 0.45}\n",
      "{'loss': 0.0513, 'grad_norm': 0.33001694083213806, 'learning_rate': 2.4330357142857144e-05, 'epoch': 0.49}\n",
      "{'loss': 0.0562, 'grad_norm': 0.3178357481956482, 'learning_rate': 2.6562500000000002e-05, 'epoch': 0.53}\n",
      "{'loss': 0.0413, 'grad_norm': 0.44799336791038513, 'learning_rate': 2.8794642857142857e-05, 'epoch': 0.58}\n",
      "{'loss': 0.0432, 'grad_norm': 0.05576032027602196, 'learning_rate': 3.102678571428572e-05, 'epoch': 0.62}\n",
      "{'loss': 0.0329, 'grad_norm': 0.28732889890670776, 'learning_rate': 3.325892857142857e-05, 'epoch': 0.67}\n",
      "{'loss': 0.0569, 'grad_norm': 0.2461235374212265, 'learning_rate': 3.5491071428571435e-05, 'epoch': 0.71}\n",
      "{'loss': 0.0554, 'grad_norm': 0.6251832246780396, 'learning_rate': 3.7723214285714286e-05, 'epoch': 0.76}\n",
      "{'loss': 0.0556, 'grad_norm': 0.7847697734832764, 'learning_rate': 3.9955357142857144e-05, 'epoch': 0.8}\n",
      "{'loss': 0.0408, 'grad_norm': 0.5207706093788147, 'learning_rate': 4.21875e-05, 'epoch': 0.85}\n",
      "{'loss': 0.0427, 'grad_norm': 1.2808657884597778, 'learning_rate': 4.4419642857142854e-05, 'epoch': 0.89}\n",
      "{'loss': 0.046, 'grad_norm': 0.4265592396259308, 'learning_rate': 4.665178571428572e-05, 'epoch': 0.94}\n",
      "{'loss': 0.0461, 'grad_norm': 0.39300116896629333, 'learning_rate': 4.888392857142857e-05, 'epoch': 0.98}\n",
      "{'loss': 0.0404, 'grad_norm': 0.616611897945404, 'learning_rate': 4.9999241131520337e-05, 'epoch': 1.02}\n",
      "{'loss': 0.0284, 'grad_norm': 0.19702333211898804, 'learning_rate': 4.999317046010329e-05, 'epoch': 1.07}\n",
      "{'loss': 0.0222, 'grad_norm': 0.2077251523733139, 'learning_rate': 4.998103059143599e-05, 'epoch': 1.11}\n",
      "{'loss': 0.0341, 'grad_norm': 0.7410733103752136, 'learning_rate': 4.996282447349408e-05, 'epoch': 1.16}\n",
      "{'loss': 0.0352, 'grad_norm': 0.17864511907100677, 'learning_rate': 4.9938556527346155e-05, 'epoch': 1.2}\n",
      "{'loss': 0.0356, 'grad_norm': 0.1447676420211792, 'learning_rate': 4.9908232646080166e-05, 'epoch': 1.25}\n",
      "{'loss': 0.0353, 'grad_norm': 0.22895273566246033, 'learning_rate': 4.987186019337242e-05, 'epoch': 1.29}\n",
      "{'loss': 0.0271, 'grad_norm': 0.47883209586143494, 'learning_rate': 4.9829448001699384e-05, 'epoch': 1.34}\n",
      "{'loss': 0.0326, 'grad_norm': 0.23527081310749054, 'learning_rate': 4.9781006370192876e-05, 'epoch': 1.38}\n",
      "{'loss': 0.0305, 'grad_norm': 0.4292024075984955, 'learning_rate': 4.972654706213906e-05, 'epoch': 1.43}\n",
      "{'loss': 0.0285, 'grad_norm': 0.9333896636962891, 'learning_rate': 4.966608330212198e-05, 'epoch': 1.47}\n",
      "{'loss': 0.0403, 'grad_norm': 0.3894634246826172, 'learning_rate': 4.9599629772812096e-05, 'epoch': 1.51}\n",
      "{'loss': 0.0414, 'grad_norm': 0.5709952712059021, 'learning_rate': 4.95272026114009e-05, 'epoch': 1.56}\n",
      "{'loss': 0.0412, 'grad_norm': 0.8702038526535034, 'learning_rate': 4.9448819405682193e-05, 'epoch': 1.6}\n",
      "{'loss': 0.038, 'grad_norm': 0.13489249348640442, 'learning_rate': 4.9364499189781224e-05, 'epoch': 1.65}\n",
      "{'loss': 0.028, 'grad_norm': 0.10227931290864944, 'learning_rate': 4.927426243953252e-05, 'epoch': 1.69}\n",
      "{'loss': 0.0305, 'grad_norm': 0.23863138258457184, 'learning_rate': 4.9178131067507625e-05, 'epoch': 1.74}\n",
      "{'loss': 0.031, 'grad_norm': 0.5378522872924805, 'learning_rate': 4.907612841769407e-05, 'epoch': 1.78}\n",
      "{'loss': 0.0241, 'grad_norm': 0.19104988873004913, 'learning_rate': 4.8968279259826536e-05, 'epoch': 1.83}\n",
      "{'loss': 0.0451, 'grad_norm': 1.6304316520690918, 'learning_rate': 4.8854609783372014e-05, 'epoch': 1.87}\n",
      "{'loss': 0.0285, 'grad_norm': 0.33911219239234924, 'learning_rate': 4.873514759117004e-05, 'epoch': 1.92}\n",
      "{'loss': 0.0313, 'grad_norm': 1.0076152086257935, 'learning_rate': 4.860992169272982e-05, 'epoch': 1.96}\n",
      "{'loss': 0.0366, 'grad_norm': 0.2830108404159546, 'learning_rate': 4.84789624971857e-05, 'epoch': 2.0}\n",
      "{'loss': 0.0139, 'grad_norm': 0.2529697120189667, 'learning_rate': 4.8342301805912814e-05, 'epoch': 2.05}\n",
      "{'loss': 0.0235, 'grad_norm': 0.41232922673225403, 'learning_rate': 4.819997280480462e-05, 'epoch': 2.09}\n",
      "{'loss': 0.0285, 'grad_norm': 0.27727726101875305, 'learning_rate': 4.805201005621418e-05, 'epoch': 2.14}\n",
      "{'loss': 0.0291, 'grad_norm': 0.3351321220397949, 'learning_rate': 4.789844949056131e-05, 'epoch': 2.18}\n",
      "{'loss': 0.0227, 'grad_norm': 0.8842334747314453, 'learning_rate': 4.77393283976074e-05, 'epoch': 2.23}\n",
      "{'loss': 0.0166, 'grad_norm': 0.27007272839546204, 'learning_rate': 4.757468541740019e-05, 'epoch': 2.27}\n",
      "{'loss': 0.0174, 'grad_norm': 0.5585487484931946, 'learning_rate': 4.740456053089065e-05, 'epoch': 2.32}\n",
      "{'loss': 0.0148, 'grad_norm': 0.10477998107671738, 'learning_rate': 4.7228995050224233e-05, 'epoch': 2.36}\n",
      "{'loss': 0.0252, 'grad_norm': 0.8730276823043823, 'learning_rate': 4.7048031608708876e-05, 'epoch': 2.41}\n",
      "{'loss': 0.0158, 'grad_norm': 0.093831367790699, 'learning_rate': 4.6861714150462166e-05, 'epoch': 2.45}\n",
      "{'loss': 0.0233, 'grad_norm': 0.12259101867675781, 'learning_rate': 4.667008791974022e-05, 'epoch': 2.49}\n",
      "{'loss': 0.0232, 'grad_norm': 0.9305816888809204, 'learning_rate': 4.64731994499508e-05, 'epoch': 2.54}\n",
      "{'loss': 0.0217, 'grad_norm': 0.14640992879867554, 'learning_rate': 4.6271096552353445e-05, 'epoch': 2.58}\n",
      "{'loss': 0.026, 'grad_norm': 0.1572386920452118, 'learning_rate': 4.606382830444924e-05, 'epoch': 2.63}\n",
      "{'loss': 0.0287, 'grad_norm': 0.2936231195926666, 'learning_rate': 4.585144503806312e-05, 'epoch': 2.67}\n",
      "{'loss': 0.0338, 'grad_norm': 0.1670355498790741, 'learning_rate': 4.5633998327121595e-05, 'epoch': 2.72}\n",
      "{'loss': 0.024, 'grad_norm': 0.47804421186447144, 'learning_rate': 4.5411540975128805e-05, 'epoch': 2.76}\n",
      "{'loss': 0.0224, 'grad_norm': 0.3904513120651245, 'learning_rate': 4.518412700234406e-05, 'epoch': 2.81}\n",
      "{'loss': 0.0135, 'grad_norm': 0.21486099064350128, 'learning_rate': 4.4951811632663845e-05, 'epoch': 2.85}\n",
      "{'loss': 0.0194, 'grad_norm': 0.6860736012458801, 'learning_rate': 4.471465128021156e-05, 'epoch': 2.9}\n",
      "{'loss': 0.0245, 'grad_norm': 0.4198627173900604, 'learning_rate': 4.447270353563828e-05, 'epoch': 2.94}\n",
      "{'loss': 0.0207, 'grad_norm': 0.3954783082008362, 'learning_rate': 4.4226027152137736e-05, 'epoch': 2.98}\n",
      "{'loss': 0.0238, 'grad_norm': 1.729914665222168, 'learning_rate': 4.397468203117905e-05, 'epoch': 3.03}\n",
      "{'loss': 0.0133, 'grad_norm': 0.17818892002105713, 'learning_rate': 4.3718729207960586e-05, 'epoch': 3.07}\n",
      "{'loss': 0.0095, 'grad_norm': 0.5891942977905273, 'learning_rate': 4.345823083658855e-05, 'epoch': 3.12}\n",
      "{'loss': 0.0091, 'grad_norm': 0.21745020151138306, 'learning_rate': 4.319325017498379e-05, 'epoch': 3.16}\n",
      "{'loss': 0.0192, 'grad_norm': 0.3902937173843384, 'learning_rate': 4.2923851569520685e-05, 'epoch': 3.21}\n",
      "{'loss': 0.0125, 'grad_norm': 0.40108615159988403, 'learning_rate': 4.265010043940156e-05, 'epoch': 3.25}\n",
      "{'loss': 0.0092, 'grad_norm': 0.17407801747322083, 'learning_rate': 4.2372063260770734e-05, 'epoch': 3.3}\n",
      "{'loss': 0.0099, 'grad_norm': 0.15606413781642914, 'learning_rate': 4.208980755057178e-05, 'epoch': 3.34}\n",
      "{'loss': 0.023, 'grad_norm': 0.040811046957969666, 'learning_rate': 4.180340185015216e-05, 'epoch': 3.39}\n",
      "{'loss': 0.0204, 'grad_norm': 0.2325201779603958, 'learning_rate': 4.151291570861896e-05, 'epoch': 3.43}\n",
      "{'loss': 0.0136, 'grad_norm': 0.3230723738670349, 'learning_rate': 4.1218419665950094e-05, 'epoch': 3.47}\n",
      "{'loss': 0.0127, 'grad_norm': 0.8287957310676575, 'learning_rate': 4.091998523586466e-05, 'epoch': 3.52}\n",
      "{'loss': 0.0194, 'grad_norm': 0.5774535536766052, 'learning_rate': 4.061768488845707e-05, 'epoch': 3.56}\n",
      "{'loss': 0.0139, 'grad_norm': 0.4509657323360443, 'learning_rate': 4.0311592032598754e-05, 'epoch': 3.61}\n",
      "{'loss': 0.0119, 'grad_norm': 0.5782088041305542, 'learning_rate': 4.0001780998112026e-05, 'epoch': 3.65}\n",
      "{'loss': 0.016, 'grad_norm': 0.1160118356347084, 'learning_rate': 3.968832701772022e-05, 'epoch': 3.7}\n",
      "{'loss': 0.0104, 'grad_norm': 0.14655756950378418, 'learning_rate': 3.937130620877863e-05, 'epoch': 3.74}\n",
      "{'loss': 0.0171, 'grad_norm': 0.5683436989784241, 'learning_rate': 3.905079555479062e-05, 'epoch': 3.79}\n",
      "{'loss': 0.0108, 'grad_norm': 0.44645440578460693, 'learning_rate': 3.872687288671335e-05, 'epoch': 3.83}\n",
      "{'loss': 0.0129, 'grad_norm': 0.7451782822608948, 'learning_rate': 3.8399616864057816e-05, 'epoch': 3.88}\n",
      "{'loss': 0.0102, 'grad_norm': 0.08569547533988953, 'learning_rate': 3.8069106955787594e-05, 'epoch': 3.92}\n",
      "{'loss': 0.0134, 'grad_norm': 0.24876540899276733, 'learning_rate': 3.773542342102105e-05, 'epoch': 3.96}\n",
      "{'loss': 0.01, 'grad_norm': 0.49183687567710876, 'learning_rate': 3.73986472895417e-05, 'epoch': 4.01}\n",
      "{'loss': 0.0076, 'grad_norm': 0.06443241238594055, 'learning_rate': 3.705886034212138e-05, 'epoch': 4.05}\n",
      "{'loss': 0.0048, 'grad_norm': 0.02596214972436428, 'learning_rate': 3.6716145090661117e-05, 'epoch': 4.1}\n",
      "{'loss': 0.0032, 'grad_norm': 0.45455554127693176, 'learning_rate': 3.6370584758154366e-05, 'epoch': 4.14}\n",
      "{'loss': 0.0038, 'grad_norm': 0.3580797612667084, 'learning_rate': 3.6022263258477634e-05, 'epoch': 4.19}\n",
      "{'loss': 0.0081, 'grad_norm': 0.14642959833145142, 'learning_rate': 3.567126517601336e-05, 'epoch': 4.23}\n",
      "{'loss': 0.0107, 'grad_norm': 0.26048511266708374, 'learning_rate': 3.5317675745109866e-05, 'epoch': 4.28}\n",
      "{'loss': 0.0049, 'grad_norm': 0.0968487560749054, 'learning_rate': 3.496158082938359e-05, 'epoch': 4.32}\n",
      "{'loss': 0.0053, 'grad_norm': 0.19710780680179596, 'learning_rate': 3.4603066900868424e-05, 'epoch': 4.37}\n",
      "{'loss': 0.0066, 'grad_norm': 0.27066290378570557, 'learning_rate': 3.424222101901738e-05, 'epoch': 4.41}\n",
      "{'loss': 0.0031, 'grad_norm': 0.025652628391981125, 'learning_rate': 3.3879130809561546e-05, 'epoch': 4.45}\n",
      "{'loss': 0.0044, 'grad_norm': 0.2547883093357086, 'learning_rate': 3.3513884443231566e-05, 'epoch': 4.5}\n",
      "{'loss': 0.0136, 'grad_norm': 0.47909072041511536, 'learning_rate': 3.314657061434681e-05, 'epoch': 4.54}\n",
      "{'loss': 0.0053, 'grad_norm': 0.38457709550857544, 'learning_rate': 3.277727851927727e-05, 'epoch': 4.59}\n",
      "{'loss': 0.0052, 'grad_norm': 0.21653050184249878, 'learning_rate': 3.240609783478372e-05, 'epoch': 4.63}\n",
      "{'loss': 0.0134, 'grad_norm': 0.04956575483083725, 'learning_rate': 3.203311869624107e-05, 'epoch': 4.68}\n",
      "{'loss': 0.0101, 'grad_norm': 0.519519567489624, 'learning_rate': 3.1658431675750424e-05, 'epoch': 4.72}\n",
      "{'loss': 0.0078, 'grad_norm': 0.28411948680877686, 'learning_rate': 3.128212776014509e-05, 'epoch': 4.77}\n",
      "{'loss': 0.007, 'grad_norm': 0.5809008479118347, 'learning_rate': 3.090429832889586e-05, 'epoch': 4.81}\n",
      "{'loss': 0.0092, 'grad_norm': 0.5065468549728394, 'learning_rate': 3.052503513192093e-05, 'epoch': 4.86}\n",
      "{'loss': 0.0068, 'grad_norm': 0.24514725804328918, 'learning_rate': 3.0144430267305872e-05, 'epoch': 4.9}\n",
      "{'loss': 0.0093, 'grad_norm': 0.1144232302904129, 'learning_rate': 2.9762576158939125e-05, 'epoch': 4.94}\n",
      "{'loss': 0.004, 'grad_norm': 0.5046910643577576, 'learning_rate': 2.9379565534068242e-05, 'epoch': 4.99}\n",
      "{'loss': 0.0035, 'grad_norm': 0.017972491681575775, 'learning_rate': 2.899549140078256e-05, 'epoch': 5.03}\n",
      "{'loss': 0.005, 'grad_norm': 0.09071888774633408, 'learning_rate': 2.8610447025427683e-05, 'epoch': 5.08}\n",
      "{'loss': 0.003, 'grad_norm': 0.53461092710495, 'learning_rate': 2.8224525909957187e-05, 'epoch': 5.12}\n",
      "{'loss': 0.0036, 'grad_norm': 0.19838476181030273, 'learning_rate': 2.783782176922715e-05, 'epoch': 5.17}\n",
      "{'loss': 0.003, 'grad_norm': 0.1345481425523758, 'learning_rate': 2.7450428508239024e-05, 'epoch': 5.21}\n",
      "{'loss': 0.0042, 'grad_norm': 0.21616244316101074, 'learning_rate': 2.706244019933618e-05, 'epoch': 5.26}\n",
      "{'loss': 0.0036, 'grad_norm': 0.09535852074623108, 'learning_rate': 2.6673951059360037e-05, 'epoch': 5.3}\n",
      "{'loss': 0.0034, 'grad_norm': 0.16452446579933167, 'learning_rate': 2.6285055426770934e-05, 'epoch': 5.35}\n",
      "{'loss': 0.0061, 'grad_norm': 0.11891968548297882, 'learning_rate': 2.5895847738739526e-05, 'epoch': 5.39}\n",
      "{'loss': 0.0056, 'grad_norm': 0.08551493287086487, 'learning_rate': 2.5506422508214206e-05, 'epoch': 5.43}\n",
      "{'loss': 0.0033, 'grad_norm': 0.13655854761600494, 'learning_rate': 2.5116874300970138e-05, 'epoch': 5.48}\n",
      "{'loss': 0.0039, 'grad_norm': 0.3209880292415619, 'learning_rate': 2.4727297712645446e-05, 'epoch': 5.52}\n",
      "{'loss': 0.0032, 'grad_norm': 0.23837810754776, 'learning_rate': 2.433778734577013e-05, 'epoch': 5.57}\n",
      "{'loss': 0.0053, 'grad_norm': 0.06323469430208206, 'learning_rate': 2.3948437786793377e-05, 'epoch': 5.61}\n",
      "{'loss': 0.0048, 'grad_norm': 0.3021242618560791, 'learning_rate': 2.3559343583114707e-05, 'epoch': 5.66}\n",
      "{'loss': 0.0046, 'grad_norm': 0.1861315667629242, 'learning_rate': 2.3170599220124634e-05, 'epoch': 5.7}\n",
      "{'loss': 0.0024, 'grad_norm': 0.24264512956142426, 'learning_rate': 2.278229909826037e-05, 'epoch': 5.75}\n",
      "{'loss': 0.0026, 'grad_norm': 0.005909367930144072, 'learning_rate': 2.239453751008219e-05, 'epoch': 5.79}\n",
      "{'loss': 0.002, 'grad_norm': 0.0347406230866909, 'learning_rate': 2.2007408617375943e-05, 'epoch': 5.84}\n",
      "{'loss': 0.0041, 'grad_norm': 0.7365056872367859, 'learning_rate': 2.162100642828737e-05, 'epoch': 5.88}\n",
      "{'loss': 0.0032, 'grad_norm': 0.1535138487815857, 'learning_rate': 2.1235424774493695e-05, 'epoch': 5.92}\n",
      "{'loss': 0.0033, 'grad_norm': 0.2079765647649765, 'learning_rate': 2.0850757288418103e-05, 'epoch': 5.97}\n",
      "{'loss': 0.0023, 'grad_norm': 0.03870336338877678, 'learning_rate': 2.0467097380492544e-05, 'epoch': 6.01}\n",
      "{'loss': 0.0036, 'grad_norm': 0.2559046745300293, 'learning_rate': 2.0084538216474524e-05, 'epoch': 6.06}\n",
      "{'loss': 0.0014, 'grad_norm': 0.07580548524856567, 'learning_rate': 1.9703172694823242e-05, 'epoch': 6.1}\n",
      "{'loss': 0.0004, 'grad_norm': 0.00230748625472188, 'learning_rate': 1.932309342414067e-05, 'epoch': 6.15}\n",
      "{'loss': 0.0032, 'grad_norm': 0.00046586969983763993, 'learning_rate': 1.894439270068304e-05, 'epoch': 6.19}\n",
      "{'loss': 0.0012, 'grad_norm': 0.194691464304924, 'learning_rate': 1.8567162485948108e-05, 'epoch': 6.24}\n",
      "{'loss': 0.0007, 'grad_norm': 0.03686991706490517, 'learning_rate': 1.81914943843438e-05, 'epoch': 6.28}\n",
      "{'loss': 0.0007, 'grad_norm': 0.11884787678718567, 'learning_rate': 1.7817479620943488e-05, 'epoch': 6.33}\n",
      "{'loss': 0.0005, 'grad_norm': 0.45122846961021423, 'learning_rate': 1.744520901933346e-05, 'epoch': 6.37}\n",
      "{'loss': 0.0034, 'grad_norm': 0.020518431439995766, 'learning_rate': 1.7074772979557802e-05, 'epoch': 6.41}\n",
      "{'loss': 0.0029, 'grad_norm': 0.33695560693740845, 'learning_rate': 1.6706261456166205e-05, 'epoch': 6.46}\n",
      "{'loss': 0.0006, 'grad_norm': 0.0047419387847185135, 'learning_rate': 1.633976393636989e-05, 'epoch': 6.5}\n",
      "{'loss': 0.0017, 'grad_norm': 0.26307472586631775, 'learning_rate': 1.5975369418311112e-05, 'epoch': 6.55}\n",
      "{'loss': 0.0017, 'grad_norm': 0.01050500851124525, 'learning_rate': 1.5613166389451284e-05, 'epoch': 6.59}\n",
      "{'loss': 0.0011, 'grad_norm': 0.006698010489344597, 'learning_rate': 1.5253242805083254e-05, 'epoch': 6.64}\n",
      "{'loss': 0.0023, 'grad_norm': 0.20462526381015778, 'learning_rate': 1.4895686066972703e-05, 'epoch': 6.68}\n",
      "{'loss': 0.0015, 'grad_norm': 0.05746570602059364, 'learning_rate': 1.4540583002134045e-05, 'epoch': 6.73}\n",
      "{'loss': 0.0051, 'grad_norm': 0.01826247200369835, 'learning_rate': 1.4188019841745843e-05, 'epoch': 6.77}\n",
      "{'loss': 0.0008, 'grad_norm': 0.014668325893580914, 'learning_rate': 1.3838082200210931e-05, 'epoch': 6.82}\n",
      "{'loss': 0.0008, 'grad_norm': 0.03494621068239212, 'learning_rate': 1.3490855054366264e-05, 'epoch': 6.86}\n",
      "{'loss': 0.0032, 'grad_norm': 0.12296692281961441, 'learning_rate': 1.3146422722847712e-05, 'epoch': 6.9}\n",
      "{'loss': 0.001, 'grad_norm': 0.0040952665731310844, 'learning_rate': 1.2804868845614525e-05, 'epoch': 6.95}\n",
      "{'loss': 0.0021, 'grad_norm': 0.01460981648415327, 'learning_rate': 1.2466276363638778e-05, 'epoch': 6.99}\n",
      "{'loss': 0.0003, 'grad_norm': 0.0072621917352080345, 'learning_rate': 1.2130727498764354e-05, 'epoch': 7.04}\n",
      "{'loss': 0.0003, 'grad_norm': 0.027642162516713142, 'learning_rate': 1.1798303733740802e-05, 'epoch': 7.08}\n",
      "{'loss': 0.0007, 'grad_norm': 0.01798757165670395, 'learning_rate': 1.1469085792436387e-05, 'epoch': 7.13}\n",
      "{'loss': 0.0002, 'grad_norm': 0.009405196644365788, 'learning_rate': 1.1143153620235705e-05, 'epoch': 7.17}\n",
      "{'loss': 0.0008, 'grad_norm': 0.001436711521819234, 'learning_rate': 1.0820586364626104e-05, 'epoch': 7.22}\n",
      "{'loss': 0.0002, 'grad_norm': 0.03333953768014908, 'learning_rate': 1.0501462355978048e-05, 'epoch': 7.26}\n",
      "{'loss': 0.0014, 'grad_norm': 0.12257906794548035, 'learning_rate': 1.0185859088523747e-05, 'epoch': 7.31}\n",
      "{'loss': 0.0002, 'grad_norm': 0.06234055384993553, 'learning_rate': 9.873853201538971e-06, 'epoch': 7.35}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0067300559021532536, 'learning_rate': 9.56552046073238e-06, 'epoch': 7.39}\n",
      "{'loss': 0.0001, 'grad_norm': 0.001326324767433107, 'learning_rate': 9.260935739846993e-06, 'epoch': 7.44}\n",
      "{'loss': 0.0007, 'grad_norm': 0.004235916305333376, 'learning_rate': 8.960173002478336e-06, 'epoch': 7.48}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0017762143397703767, 'learning_rate': 8.663305284113491e-06, 'epoch': 7.53}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0063967215828597546, 'learning_rate': 8.370404674395631e-06, 'epoch': 7.57}\n",
      "{'loss': 0.0005, 'grad_norm': 0.12605541944503784, 'learning_rate': 8.081542299618139e-06, 'epoch': 7.62}\n",
      "{'loss': 0.0001, 'grad_norm': 0.024669790640473366, 'learning_rate': 7.796788305452776e-06, 'epoch': 7.66}\n",
      "{'loss': 0.0004, 'grad_norm': 0.25742220878601074, 'learning_rate': 7.516211839915821e-06, 'epoch': 7.71}\n",
      "{'loss': 0.0001, 'grad_norm': 0.008350483141839504, 'learning_rate': 7.239881036576651e-06, 'epoch': 7.75}\n",
      "{'loss': 0.0007, 'grad_norm': 0.001219735131599009, 'learning_rate': 6.967862998012509e-06, 'epoch': 7.8}\n",
      "{'loss': 0.0001, 'grad_norm': 0.001364305499009788, 'learning_rate': 6.70022377951377e-06, 'epoch': 7.84}\n",
      "{'loss': 0.0001, 'grad_norm': 0.004817644599825144, 'learning_rate': 6.437028373043386e-06, 'epoch': 7.88}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0004427290987223387, 'learning_rate': 6.1783406914546645e-06, 'epoch': 7.93}\n",
      "{'loss': 0.0001, 'grad_norm': 0.024586142972111702, 'learning_rate': 5.924223552971031e-06, 'epoch': 7.97}\n",
      "{'loss': 0.0002, 'grad_norm': 0.003144994843751192, 'learning_rate': 5.674738665931575e-06, 'epoch': 8.02}\n",
      "{'loss': 0.0, 'grad_norm': 0.0015651753637939692, 'learning_rate': 5.429946613806219e-06, 'epoch': 8.06}\n",
      "{'loss': 0.0002, 'grad_norm': 0.0028325743041932583, 'learning_rate': 5.18990684048391e-06, 'epoch': 8.11}\n",
      "{'loss': 0.0002, 'grad_norm': 0.0009742990368977189, 'learning_rate': 4.954677635837668e-06, 'epoch': 8.15}\n",
      "{'loss': 0.0001, 'grad_norm': 0.01383168064057827, 'learning_rate': 4.72431612156976e-06, 'epoch': 8.2}\n",
      "{'loss': 0.0001, 'grad_norm': 0.000505285628605634, 'learning_rate': 4.498878237340637e-06, 'epoch': 8.24}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0030259673949331045, 'learning_rate': 4.278418727184849e-06, 'epoch': 8.29}\n",
      "{'loss': 0.0003, 'grad_norm': 0.09275072813034058, 'learning_rate': 4.0629911262173056e-06, 'epoch': 8.33}\n",
      "{'loss': 0.0, 'grad_norm': 0.0016620851820334792, 'learning_rate': 3.852647747633156e-06, 'epoch': 8.37}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0018781101098284125, 'learning_rate': 3.6474396700043158e-06, 'epoch': 8.42}\n",
      "{'loss': 0.0, 'grad_norm': 0.0019397999858483672, 'learning_rate': 3.4474167248758654e-06, 'epoch': 8.46}\n",
      "{'loss': 0.0001, 'grad_norm': 0.002437377581372857, 'learning_rate': 3.252627484665241e-06, 'epoch': 8.51}\n",
      "{'loss': 0.0, 'grad_norm': 0.0029447097331285477, 'learning_rate': 3.0631192508671857e-06, 'epoch': 8.55}\n",
      "{'loss': 0.0, 'grad_norm': 0.001468548784032464, 'learning_rate': 2.8789380425673196e-06, 'epoch': 8.6}\n",
      "{'loss': 0.0, 'grad_norm': 0.005041306838393211, 'learning_rate': 2.7001285852671474e-06, 'epoch': 8.64}\n",
      "{'loss': 0.0, 'grad_norm': 0.0020253502298146486, 'learning_rate': 2.526734300023162e-06, 'epoch': 8.69}\n",
      "{'loss': 0.0, 'grad_norm': 0.0011386715341359377, 'learning_rate': 2.358797292902737e-06, 'epoch': 8.73}\n",
      "{'loss': 0.0, 'grad_norm': 0.0018244670936837792, 'learning_rate': 2.1963583447593277e-06, 'epoch': 8.78}\n",
      "{'loss': 0.0, 'grad_norm': 0.00500984862446785, 'learning_rate': 2.039456901329473e-06, 'epoch': 8.82}\n",
      "{'loss': 0.0001, 'grad_norm': 0.016832634806632996, 'learning_rate': 1.8881310636540444e-06, 'epoch': 8.86}\n",
      "{'loss': 0.0004, 'grad_norm': 0.008121874183416367, 'learning_rate': 1.7424175788259777e-06, 'epoch': 8.91}\n",
      "{'loss': 0.0001, 'grad_norm': 0.00892180297523737, 'learning_rate': 1.6023518310668618e-06, 'epoch': 8.95}\n",
      "{'loss': 0.0, 'grad_norm': 0.005174694117158651, 'learning_rate': 1.4679678331343871e-06, 'epoch': 9.0}\n",
      "{'loss': 0.0, 'grad_norm': 0.000544224341865629, 'learning_rate': 1.339298218062937e-06, 'epoch': 9.04}\n",
      "{'loss': 0.0002, 'grad_norm': 0.00021793492487631738, 'learning_rate': 1.216374231239134e-06, 'epoch': 9.09}\n",
      "{'loss': 0.0, 'grad_norm': 0.0006935908459126949, 'learning_rate': 1.0992257228144064e-06, 'epoch': 9.13}\n",
      "{'loss': 0.0, 'grad_norm': 0.007158662658184767, 'learning_rate': 9.878811404563342e-07, 'epoch': 9.18}\n",
      "{'loss': 0.0004, 'grad_norm': 0.000803982897195965, 'learning_rate': 8.823675224406053e-07, 'epoch': 9.22}\n",
      "{'loss': 0.0, 'grad_norm': 0.0006786307785660028, 'learning_rate': 7.82710491085173e-07, 'epoch': 9.27}\n",
      "{'loss': 0.0, 'grad_norm': 0.00044250107021071017, 'learning_rate': 6.889342465283e-07, 'epoch': 9.31}\n",
      "{'loss': 0.0, 'grad_norm': 0.0034061868209391832, 'learning_rate': 6.01061560851926e-07, 'epoch': 9.35}\n",
      "{'loss': 0.0002, 'grad_norm': 0.00035001078504137695, 'learning_rate': 5.191137725518213e-07, 'epoch': 9.4}\n",
      "{'loss': 0.0, 'grad_norm': 0.0070590125396847725, 'learning_rate': 4.4311078135589045e-07, 'epoch': 9.44}\n",
      "{'loss': 0.0001, 'grad_norm': 0.008963889442384243, 'learning_rate': 3.730710433918039e-07, 'epoch': 9.49}\n",
      "{'loss': 0.0001, 'grad_norm': 0.02056817337870598, 'learning_rate': 3.090115667052557e-07, 'epoch': 9.53}\n",
      "{'loss': 0.0, 'grad_norm': 0.00013601637328974903, 'learning_rate': 2.5094790712980323e-07, 'epoch': 9.58}\n",
      "{'loss': 0.0, 'grad_norm': 0.00033398804953321815, 'learning_rate': 1.9889416450938337e-07, 'epoch': 9.62}\n",
      "{'loss': 0.0001, 'grad_norm': 0.00011775863822549582, 'learning_rate': 1.5286297927439575e-07, 'epoch': 9.67}\n",
      "{'loss': 0.0, 'grad_norm': 0.0037179256323724985, 'learning_rate': 1.1286552937216088e-07, 'epoch': 9.71}\n",
      "{'loss': 0.0, 'grad_norm': 0.005282634869217873, 'learning_rate': 7.891152755254428e-08, 'epoch': 9.76}\n",
      "{'loss': 0.0, 'grad_norm': 0.002331953961402178, 'learning_rate': 5.100921900935696e-08, 'epoch': 9.8}\n",
      "{'loss': 0.0, 'grad_norm': 0.003775995457544923, 'learning_rate': 2.9165379378151558e-08, 'epoch': 9.84}\n",
      "{'loss': 0.0, 'grad_norm': 0.0055693271569907665, 'learning_rate': 1.3385313090857887e-08, 'epoch': 9.89}\n",
      "{'loss': 0.0002, 'grad_norm': 0.00010889447730733082, 'learning_rate': 3.672852087691081e-09, 'epoch': 9.93}\n",
      "{'loss': 0.0, 'grad_norm': 0.0007467170362360775, 'learning_rate': 3.035488661262687e-11, 'epoch': 9.98}\n",
      "100%|█████████████████████████████████████| 2240/2240 [2:14:18<00:00,  3.51s/it][INFO|trainer.py:2329] 2024-06-14 16:30:53,694 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 8058.7796, 'train_samples_per_second': 2.229, 'train_steps_per_second': 0.278, 'train_loss': 0.016545564281445227, 'epoch': 9.98}\n",
      "100%|█████████████████████████████████████| 2240/2240 [2:14:18<00:00,  3.60s/it]\n",
      "[INFO|trainer.py:3410] 2024-06-14 16:30:53,718 >> Saving model checkpoint to /Utilisateurs/umushtaq/models/PE_ATC-LI-LTC_paragraph_llama-3-8b-Instruct-bnb-4bit\n",
      "[INFO|configuration_utils.py:733] 2024-06-14 16:30:54,508 >> loading configuration file config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/config.json\n",
      "[INFO|configuration_utils.py:796] 2024-06-14 16:30:54,509 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"_load_in_4bit\": true,\n",
      "    \"_load_in_8bit\": false,\n",
      "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "    \"bnb_4bit_quant_type\": \"nf4\",\n",
      "    \"bnb_4bit_use_double_quant\": true,\n",
      "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "    \"llm_int8_has_fp16_weight\": false,\n",
      "    \"llm_int8_skip_modules\": null,\n",
      "    \"llm_int8_threshold\": 6.0,\n",
      "    \"load_in_4bit\": true,\n",
      "    \"load_in_8bit\": false,\n",
      "    \"quant_method\": \"bitsandbytes\"\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2513] 2024-06-14 16:30:55,790 >> tokenizer config file saved in /Utilisateurs/umushtaq/models/PE_ATC-LI-LTC_paragraph_llama-3-8b-Instruct-bnb-4bit/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2522] 2024-06-14 16:30:55,791 >> Special tokens file saved in /Utilisateurs/umushtaq/models/PE_ATC-LI-LTC_paragraph_llama-3-8b-Instruct-bnb-4bit/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =      9.9777\n",
      "  total_flos               = 294434057GF\n",
      "  train_loss               =      0.0165\n",
      "  train_runtime            =  2:14:18.77\n",
      "  train_samples_per_second =       2.229\n",
      "  train_steps_per_second   =       0.278\n",
      "[INFO|modelcard.py:450] 2024-06-14 16:30:56,001 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 16:30:57,732 >> loading file tokenizer.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 16:30:57,734 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 16:30:57,735 >> loading file special_tokens_map.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 16:30:57,736 >> loading file tokenizer_config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/tokenizer_config.json\n",
      "[WARNING|logging.py:314] 2024-06-14 16:30:57,994 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/14/2024 16:30:57 - INFO - llamafactory.data.template - Replace eos token: <|eot_id|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Utilisateurs/umushtaq/.conda/envs/llama-factory-notebook/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "[INFO|configuration_utils.py:733] 2024-06-14 16:30:58,122 >> loading configuration file config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/config.json\n",
      "[INFO|configuration_utils.py:796] 2024-06-14 16:30:58,125 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"_load_in_4bit\": true,\n",
      "    \"_load_in_8bit\": false,\n",
      "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "    \"bnb_4bit_quant_type\": \"nf4\",\n",
      "    \"bnb_4bit_use_double_quant\": true,\n",
      "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "    \"llm_int8_has_fp16_weight\": false,\n",
      "    \"llm_int8_skip_modules\": null,\n",
      "    \"llm_int8_threshold\": 6.0,\n",
      "    \"load_in_4bit\": true,\n",
      "    \"load_in_8bit\": false,\n",
      "    \"quant_method\": \"bitsandbytes\"\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/14/2024 16:30:58 - INFO - llamafactory.model.utils.quantization - Loading ?-bit BITSANDBYTES-quantized model.\n",
      "06/14/2024 16:30:58 - INFO - llamafactory.model.patcher - Using KV cache for faster generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING|quantization_config.py:393] 2024-06-14 16:30:58,480 >> Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "[INFO|modeling_utils.py:3474] 2024-06-14 16:30:58,486 >> loading weights file model.safetensors from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/model.safetensors\n",
      "[INFO|modeling_utils.py:1519] 2024-06-14 16:30:58,516 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:962] 2024-06-14 16:30:58,521 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:4280] 2024-06-14 16:31:00,724 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4288] 2024-06-14 16:31:00,726 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at unsloth/llama-3-8b-Instruct-bnb-4bit.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:917] 2024-06-14 16:31:00,863 >> loading configuration file generation_config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/generation_config.json\n",
      "[INFO|configuration_utils.py:962] 2024-06-14 16:31:00,865 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128009\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/14/2024 16:31:01 - INFO - llamafactory.model.utils.attention - Using torch SDPA for faster training and inference.\n",
      "06/14/2024 16:31:01 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n",
      "06/14/2024 16:31:01 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n",
      "06/14/2024 16:31:01 - INFO - llamafactory.model.adapter - Loaded adapter(s): /Utilisateurs/umushtaq/models/PE_ATC-LI-LTC_paragraph_llama-3-8b-Instruct-bnb-4bit\n",
      "06/14/2024 16:31:01 - INFO - llamafactory.model.loader - all params: 8051232768\n",
      "/Utilisateurs/umushtaq\n",
      "\n",
      "Running experiment: ['unsloth/llama-3-8b-Instruct-bnb-4bit', 'PE_ATC-LI-LTC_paragraph_wo_tags_train.json', 'PE_ATC-LI-LTC_paragraph_wo_tags_test.json']\n",
      "/Utilisateurs/umushtaq/LLaMA-Factory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/14/2024 16:58:24 - WARNING - llamafactory.hparams.parser - We recommend enable `upcast_layernorm` in quantized training.\n",
      "06/14/2024 16:58:24 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: torch.float16\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 16:58:25,536 >> loading file tokenizer.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 16:58:25,536 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 16:58:25,537 >> loading file special_tokens_map.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 16:58:25,537 >> loading file tokenizer_config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/tokenizer_config.json\n",
      "[WARNING|logging.py:314] 2024-06-14 16:58:25,791 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "06/14/2024 16:58:25 - INFO - llamafactory.data.template - Replace eos token: <|eot_id|>\n",
      "06/14/2024 16:58:25 - INFO - llamafactory.data.loader - Loading dataset /Utilisateurs/umushtaq/datasets/PE_ATC-LI-LTC_paragraph_wo_tags_train.json...\n",
      "Generating train split: 1796 examples [00:00, 18164.38 examples/s]\n",
      "Converting format of dataset: 100%|█| 1796/1796 [00:00<00:00, 14728.08 examples/\n",
      "Running tokenizer on dataset: 100%|█| 1796/1796 [00:01<00:00, 1315.45 examples/s\n",
      "input_ids:\n",
      "[128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 18328, 13, 128009, 128006, 882, 128007, 271, 14711, 1472, 527, 459, 6335, 304, 14138, 26917, 13, 1472, 527, 2728, 264, 14646, 902, 5727, 5811, 6956, 44910, 555, 366, 1741, 1500, 1741, 29, 9681, 13, 4718, 3465, 374, 311, 49229, 279, 5811, 6956, 439, 1664, 439, 311, 10765, 323, 49229, 5811, 4398, 1990, 5811, 6956, 304, 279, 14646, 13, 1789, 1855, 5811, 3777, 11, 1202, 10807, 955, 320, 496, 8, 374, 3060, 330, 35575, 46644, 498, 330, 46644, 1, 477, 330, 42562, 1082, 3343, 1789, 1855, 5811, 12976, 320, 5775, 10807, 320, 396, 705, 2592, 10807, 320, 396, 5850, 1202, 2723, 955, 320, 496, 8, 374, 3060, 330, 8075, 1, 477, 330, 29702, 3343, 1472, 2011, 471, 1403, 11725, 304, 2768, 4823, 3645, 25, 5324, 1638, 24297, 9962, 794, 510, 1741, 955, 320, 496, 705, 61453, 10807, 955, 320, 496, 26090, 330, 1638, 9202, 95321, 8543, 9962, 794, 4416, 5775, 10807, 320, 396, 705, 2592, 10807, 320, 396, 705, 2723, 955, 320, 496, 26090, 61453, 510, 5775, 10807, 320, 396, 705, 2592, 10807, 320, 396, 705, 2723, 955, 320, 496, 8, 5163, 633, 14711, 5810, 374, 279, 14646, 1495, 25, 12540, 4236, 387, 15972, 311, 20874, 477, 311, 47903, 949, 128009, 128006, 78191, 128007, 271, 5018, 1638, 24297, 9962, 794, 10277, 330, 1638, 9202, 95321, 8543, 9962, 794, 3132, 92, 128009]\n",
      "inputs:\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "### You are an expert in Argument Mining. You are given a paragraph which contains argument components enclosed by <AC></AC> tags. Your task is to classify the argument components as well as to identify and classify argument relations between argument components in the paragraph. For each argument component, its AC type (str) is either \"MajorClaim\", \"Claim\" or \"Premise\". For each argument relation (target AC (int), source AC (int)), its link type (str) is either \"Support\" or \"Attack\". You must return two lists in following JSON format: {\"list_component_types\": [AC type (str),..., AC type (str)], \"list_argument_relations_and_types\": [[target AC (int), source AC (int), link type (str)],..., [target AC (int), source AC (int), link type (str)]]}\n",
      "\n",
      "### Here is the paragraph text: Should students be taught to compete or to cooperate?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\"list_component_types\": [], \"list_argument_relations_and_types\": []}<|eot_id|>\n",
      "label_ids:\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 5018, 1638, 24297, 9962, 794, 10277, 330, 1638, 9202, 95321, 8543, 9962, 794, 3132, 92, 128009]\n",
      "labels:\n",
      "{\"list_component_types\": [], \"list_argument_relations_and_types\": []}<|eot_id|>\n",
      "/Utilisateurs/umushtaq/.conda/envs/llama-factory-notebook/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "[INFO|configuration_utils.py:733] 2024-06-14 16:58:28,463 >> loading configuration file config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/config.json\n",
      "[INFO|configuration_utils.py:796] 2024-06-14 16:58:28,464 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"_load_in_4bit\": true,\n",
      "    \"_load_in_8bit\": false,\n",
      "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "    \"bnb_4bit_quant_type\": \"nf4\",\n",
      "    \"bnb_4bit_use_double_quant\": true,\n",
      "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "    \"llm_int8_has_fp16_weight\": false,\n",
      "    \"llm_int8_skip_modules\": null,\n",
      "    \"llm_int8_threshold\": 6.0,\n",
      "    \"load_in_4bit\": true,\n",
      "    \"load_in_8bit\": false,\n",
      "    \"quant_method\": \"bitsandbytes\"\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "06/14/2024 16:58:28 - INFO - llamafactory.model.utils.quantization - Loading ?-bit BITSANDBYTES-quantized model.\n",
      "[WARNING|quantization_config.py:393] 2024-06-14 16:58:28,788 >> Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "[INFO|modeling_utils.py:3474] 2024-06-14 16:58:28,791 >> loading weights file model.safetensors from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/model.safetensors\n",
      "[INFO|modeling_utils.py:1519] 2024-06-14 16:58:28,823 >> Instantiating LlamaForCausalLM model under default dtype torch.float16.\n",
      "[INFO|configuration_utils.py:962] 2024-06-14 16:58:28,827 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:4280] 2024-06-14 16:58:33,272 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4288] 2024-06-14 16:58:33,273 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at unsloth/llama-3-8b-Instruct-bnb-4bit.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:917] 2024-06-14 16:58:33,590 >> loading configuration file generation_config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/generation_config.json\n",
      "[INFO|configuration_utils.py:962] 2024-06-14 16:58:33,590 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128009\n",
      "  ]\n",
      "}\n",
      "\n",
      "06/14/2024 16:58:33 - INFO - llamafactory.model.utils.checkpointing - Gradient checkpointing enabled.\n",
      "06/14/2024 16:58:33 - INFO - llamafactory.model.utils.attention - Using torch SDPA for faster training and inference.\n",
      "06/14/2024 16:58:33 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n",
      "06/14/2024 16:58:33 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n",
      "06/14/2024 16:58:33 - INFO - llamafactory.model.utils.misc - Found linear modules: o_proj,up_proj,k_proj,gate_proj,q_proj,v_proj,down_proj\n",
      "06/14/2024 16:58:34 - INFO - llamafactory.model.loader - trainable params: 20971520 || all params: 8051232768 || trainable%: 0.2605\n",
      "[INFO|trainer.py:641] 2024-06-14 16:58:34,049 >> Using auto half precision backend\n",
      "06/14/2024 16:58:34 - INFO - llamafactory.train.utils - Using LoRA+ optimizer with loraplus lr ratio 16.00.\n",
      "[INFO|trainer.py:2078] 2024-06-14 16:58:34,275 >> ***** Running training *****\n",
      "[INFO|trainer.py:2079] 2024-06-14 16:58:34,275 >>   Num examples = 1,796\n",
      "[INFO|trainer.py:2080] 2024-06-14 16:58:34,276 >>   Num Epochs = 10\n",
      "[INFO|trainer.py:2081] 2024-06-14 16:58:34,276 >>   Instantaneous batch size per device = 2\n",
      "[INFO|trainer.py:2084] 2024-06-14 16:58:34,276 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "[INFO|trainer.py:2085] 2024-06-14 16:58:34,276 >>   Gradient Accumulation steps = 4\n",
      "[INFO|trainer.py:2086] 2024-06-14 16:58:34,276 >>   Total optimization steps = 2,240\n",
      "[INFO|trainer.py:2087] 2024-06-14 16:58:34,279 >>   Number of trainable parameters = 20,971,520\n",
      "{'loss': 0.5301, 'grad_norm': 3.7793631553649902, 'learning_rate': 2.0089285714285715e-06, 'epoch': 0.04}\n",
      "{'loss': 0.1676, 'grad_norm': 1.1737998723983765, 'learning_rate': 4.241071428571429e-06, 'epoch': 0.09}\n",
      "{'loss': 0.1175, 'grad_norm': 0.5593352913856506, 'learning_rate': 6.473214285714287e-06, 'epoch': 0.13}\n",
      "{'loss': 0.0918, 'grad_norm': 0.8286227583885193, 'learning_rate': 8.705357142857143e-06, 'epoch': 0.18}\n",
      "{'loss': 0.0943, 'grad_norm': 0.65000319480896, 'learning_rate': 1.09375e-05, 'epoch': 0.22}\n",
      "{'loss': 0.0692, 'grad_norm': 0.5853977799415588, 'learning_rate': 1.3169642857142858e-05, 'epoch': 0.27}\n",
      "{'loss': 0.0625, 'grad_norm': 0.33108437061309814, 'learning_rate': 1.5401785714285715e-05, 'epoch': 0.31}\n",
      "{'loss': 0.0527, 'grad_norm': 0.5639408230781555, 'learning_rate': 1.7633928571428573e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0548, 'grad_norm': 0.4478449523448944, 'learning_rate': 1.9866071428571427e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0576, 'grad_norm': 0.5692988634109497, 'learning_rate': 2.2098214285714286e-05, 'epoch': 0.45}\n",
      "{'loss': 0.0577, 'grad_norm': 0.35106489062309265, 'learning_rate': 2.4330357142857144e-05, 'epoch': 0.49}\n",
      "{'loss': 0.0495, 'grad_norm': 0.3197095990180969, 'learning_rate': 2.6562500000000002e-05, 'epoch': 0.53}\n",
      "{'loss': 0.041, 'grad_norm': 0.5983635783195496, 'learning_rate': 2.8794642857142857e-05, 'epoch': 0.58}\n",
      "{'loss': 0.0404, 'grad_norm': 0.05907224118709564, 'learning_rate': 3.102678571428572e-05, 'epoch': 0.62}\n",
      "{'loss': 0.0411, 'grad_norm': 0.15334776043891907, 'learning_rate': 3.325892857142857e-05, 'epoch': 0.67}\n",
      "{'loss': 0.056, 'grad_norm': 0.23144981265068054, 'learning_rate': 3.5491071428571435e-05, 'epoch': 0.71}\n",
      "{'loss': 0.0561, 'grad_norm': 0.5493606925010681, 'learning_rate': 3.7723214285714286e-05, 'epoch': 0.76}\n",
      "{'loss': 0.063, 'grad_norm': 0.6880911588668823, 'learning_rate': 3.9955357142857144e-05, 'epoch': 0.8}\n",
      "{'loss': 0.042, 'grad_norm': 0.3770346939563751, 'learning_rate': 4.21875e-05, 'epoch': 0.85}\n",
      "{'loss': 0.0381, 'grad_norm': 0.5578827261924744, 'learning_rate': 4.4419642857142854e-05, 'epoch': 0.89}\n",
      "{'loss': 0.0383, 'grad_norm': 0.6711256504058838, 'learning_rate': 4.665178571428572e-05, 'epoch': 0.94}\n",
      "{'loss': 0.0534, 'grad_norm': 0.5902899503707886, 'learning_rate': 4.888392857142857e-05, 'epoch': 0.98}\n",
      "{'loss': 0.0437, 'grad_norm': 0.3411026895046234, 'learning_rate': 4.9999241131520337e-05, 'epoch': 1.02}\n",
      "{'loss': 0.0341, 'grad_norm': 0.16606205701828003, 'learning_rate': 4.999317046010329e-05, 'epoch': 1.07}\n",
      "{'loss': 0.0222, 'grad_norm': 0.09423906356096268, 'learning_rate': 4.998103059143599e-05, 'epoch': 1.11}\n",
      "{'loss': 0.04, 'grad_norm': 0.6166529655456543, 'learning_rate': 4.996282447349408e-05, 'epoch': 1.16}\n",
      "{'loss': 0.0395, 'grad_norm': 0.11253835260868073, 'learning_rate': 4.9938556527346155e-05, 'epoch': 1.2}\n",
      "{'loss': 0.0419, 'grad_norm': 0.35777097940444946, 'learning_rate': 4.9908232646080166e-05, 'epoch': 1.25}\n",
      "{'loss': 0.0308, 'grad_norm': 0.4534061849117279, 'learning_rate': 4.987186019337242e-05, 'epoch': 1.29}\n",
      "{'loss': 0.0279, 'grad_norm': 0.608824610710144, 'learning_rate': 4.9829448001699384e-05, 'epoch': 1.34}\n",
      "{'loss': 0.0402, 'grad_norm': 0.30816230177879333, 'learning_rate': 4.9781006370192876e-05, 'epoch': 1.38}\n",
      "{'loss': 0.0338, 'grad_norm': 0.4917256534099579, 'learning_rate': 4.972654706213906e-05, 'epoch': 1.43}\n",
      "{'loss': 0.0329, 'grad_norm': 0.5863609313964844, 'learning_rate': 4.966608330212198e-05, 'epoch': 1.47}\n",
      "{'loss': 0.0364, 'grad_norm': 0.4735793471336365, 'learning_rate': 4.9599629772812096e-05, 'epoch': 1.51}\n",
      "{'loss': 0.0458, 'grad_norm': 0.6977025270462036, 'learning_rate': 4.95272026114009e-05, 'epoch': 1.56}\n",
      "{'loss': 0.0414, 'grad_norm': 0.7527362704277039, 'learning_rate': 4.9448819405682193e-05, 'epoch': 1.6}\n",
      "{'loss': 0.0322, 'grad_norm': 0.2336466759443283, 'learning_rate': 4.9364499189781224e-05, 'epoch': 1.65}\n",
      "{'loss': 0.0363, 'grad_norm': 0.18788215517997742, 'learning_rate': 4.927426243953252e-05, 'epoch': 1.69}\n",
      "{'loss': 0.0285, 'grad_norm': 0.2427569031715393, 'learning_rate': 4.9178131067507625e-05, 'epoch': 1.74}\n",
      "{'loss': 0.0269, 'grad_norm': 0.534985363483429, 'learning_rate': 4.907612841769407e-05, 'epoch': 1.78}\n",
      "{'loss': 0.0283, 'grad_norm': 0.7740774750709534, 'learning_rate': 4.8968279259826536e-05, 'epoch': 1.83}\n",
      "{'loss': 0.0486, 'grad_norm': 0.2571839988231659, 'learning_rate': 4.8854609783372014e-05, 'epoch': 1.87}\n",
      "{'loss': 0.03, 'grad_norm': 0.22504353523254395, 'learning_rate': 4.873514759117004e-05, 'epoch': 1.92}\n",
      "{'loss': 0.0288, 'grad_norm': 0.7342774271965027, 'learning_rate': 4.860992169272982e-05, 'epoch': 1.96}\n",
      "{'loss': 0.037, 'grad_norm': 0.2629476487636566, 'learning_rate': 4.84789624971857e-05, 'epoch': 2.0}\n",
      "{'loss': 0.015, 'grad_norm': 0.217779740691185, 'learning_rate': 4.8342301805912814e-05, 'epoch': 2.05}\n",
      "{'loss': 0.0182, 'grad_norm': 0.8253876566886902, 'learning_rate': 4.819997280480462e-05, 'epoch': 2.09}\n",
      "{'loss': 0.0219, 'grad_norm': 0.49495381116867065, 'learning_rate': 4.805201005621418e-05, 'epoch': 2.14}\n",
      "{'loss': 0.0202, 'grad_norm': 0.62841796875, 'learning_rate': 4.789844949056131e-05, 'epoch': 2.18}\n",
      "{'loss': 0.0204, 'grad_norm': 0.3926728665828705, 'learning_rate': 4.77393283976074e-05, 'epoch': 2.23}\n",
      "{'loss': 0.0204, 'grad_norm': 0.42691853642463684, 'learning_rate': 4.757468541740019e-05, 'epoch': 2.27}\n",
      "{'loss': 0.0172, 'grad_norm': 0.5058643817901611, 'learning_rate': 4.740456053089065e-05, 'epoch': 2.32}\n",
      "{'loss': 0.0173, 'grad_norm': 0.33742624521255493, 'learning_rate': 4.7228995050224233e-05, 'epoch': 2.36}\n",
      "{'loss': 0.0295, 'grad_norm': 0.3034924566745758, 'learning_rate': 4.7048031608708876e-05, 'epoch': 2.41}\n",
      "{'loss': 0.0172, 'grad_norm': 0.0923723578453064, 'learning_rate': 4.6861714150462166e-05, 'epoch': 2.45}\n",
      "{'loss': 0.022, 'grad_norm': 0.21455012261867523, 'learning_rate': 4.667008791974022e-05, 'epoch': 2.49}\n",
      "{'loss': 0.0209, 'grad_norm': 0.6859745979309082, 'learning_rate': 4.64731994499508e-05, 'epoch': 2.54}\n",
      "{'loss': 0.0233, 'grad_norm': 0.13808314502239227, 'learning_rate': 4.6271096552353445e-05, 'epoch': 2.58}\n",
      "{'loss': 0.025, 'grad_norm': 0.24595749378204346, 'learning_rate': 4.606382830444924e-05, 'epoch': 2.63}\n",
      "{'loss': 0.0296, 'grad_norm': 0.48608002066612244, 'learning_rate': 4.585144503806312e-05, 'epoch': 2.67}\n",
      "{'loss': 0.0406, 'grad_norm': 0.4616049528121948, 'learning_rate': 4.5633998327121595e-05, 'epoch': 2.72}\n",
      "{'loss': 0.0278, 'grad_norm': 0.628919780254364, 'learning_rate': 4.5411540975128805e-05, 'epoch': 2.76}\n",
      "{'loss': 0.025, 'grad_norm': 0.31311845779418945, 'learning_rate': 4.518412700234406e-05, 'epoch': 2.81}\n",
      "{'loss': 0.0146, 'grad_norm': 0.6864603757858276, 'learning_rate': 4.4951811632663845e-05, 'epoch': 2.85}\n",
      "{'loss': 0.0229, 'grad_norm': 0.3013547658920288, 'learning_rate': 4.471465128021156e-05, 'epoch': 2.9}\n",
      "{'loss': 0.021, 'grad_norm': 0.23426176607608795, 'learning_rate': 4.447270353563828e-05, 'epoch': 2.94}\n",
      "{'loss': 0.0197, 'grad_norm': 0.18868175148963928, 'learning_rate': 4.4226027152137736e-05, 'epoch': 2.98}\n",
      "{'loss': 0.0153, 'grad_norm': 0.2997528314590454, 'learning_rate': 4.397468203117905e-05, 'epoch': 3.03}\n",
      "{'loss': 0.0102, 'grad_norm': 0.14471237361431122, 'learning_rate': 4.3718729207960586e-05, 'epoch': 3.07}\n",
      "{'loss': 0.0156, 'grad_norm': 0.5490742325782776, 'learning_rate': 4.345823083658855e-05, 'epoch': 3.12}\n",
      "{'loss': 0.0113, 'grad_norm': 0.47073960304260254, 'learning_rate': 4.319325017498379e-05, 'epoch': 3.16}\n",
      "{'loss': 0.0115, 'grad_norm': 0.19243919849395752, 'learning_rate': 4.2923851569520685e-05, 'epoch': 3.21}\n",
      "{'loss': 0.0152, 'grad_norm': 0.09715723246335983, 'learning_rate': 4.265010043940156e-05, 'epoch': 3.25}\n",
      "{'loss': 0.0154, 'grad_norm': 0.38360849022865295, 'learning_rate': 4.2372063260770734e-05, 'epoch': 3.3}\n",
      "{'loss': 0.0081, 'grad_norm': 0.3855573236942291, 'learning_rate': 4.208980755057178e-05, 'epoch': 3.34}\n",
      "{'loss': 0.0141, 'grad_norm': 0.06651129573583603, 'learning_rate': 4.180340185015216e-05, 'epoch': 3.39}\n",
      "{'loss': 0.0165, 'grad_norm': 0.7691236734390259, 'learning_rate': 4.151291570861896e-05, 'epoch': 3.43}\n",
      "{'loss': 0.0126, 'grad_norm': 0.23902064561843872, 'learning_rate': 4.1218419665950094e-05, 'epoch': 3.47}\n",
      "{'loss': 0.0148, 'grad_norm': 0.9127764701843262, 'learning_rate': 4.091998523586466e-05, 'epoch': 3.52}\n",
      "{'loss': 0.0171, 'grad_norm': 0.6195741891860962, 'learning_rate': 4.061768488845707e-05, 'epoch': 3.56}\n",
      "{'loss': 0.0115, 'grad_norm': 0.4016612768173218, 'learning_rate': 4.0311592032598754e-05, 'epoch': 3.61}\n",
      "{'loss': 0.0153, 'grad_norm': 0.4553949534893036, 'learning_rate': 4.0001780998112026e-05, 'epoch': 3.65}\n",
      "{'loss': 0.0155, 'grad_norm': 0.13495247066020966, 'learning_rate': 3.968832701772022e-05, 'epoch': 3.7}\n",
      "{'loss': 0.0133, 'grad_norm': 0.3588831126689911, 'learning_rate': 3.937130620877863e-05, 'epoch': 3.74}\n",
      "{'loss': 0.0196, 'grad_norm': 0.388171911239624, 'learning_rate': 3.905079555479062e-05, 'epoch': 3.79}\n",
      "{'loss': 0.0119, 'grad_norm': 0.3899668753147125, 'learning_rate': 3.872687288671335e-05, 'epoch': 3.83}\n",
      "{'loss': 0.0102, 'grad_norm': 0.34256115555763245, 'learning_rate': 3.8399616864057816e-05, 'epoch': 3.88}\n",
      "{'loss': 0.012, 'grad_norm': 0.009451099671423435, 'learning_rate': 3.8069106955787594e-05, 'epoch': 3.92}\n",
      "{'loss': 0.0133, 'grad_norm': 0.2035524845123291, 'learning_rate': 3.773542342102105e-05, 'epoch': 3.96}\n",
      "{'loss': 0.0131, 'grad_norm': 0.5612166523933411, 'learning_rate': 3.73986472895417e-05, 'epoch': 4.01}\n",
      "{'loss': 0.0063, 'grad_norm': 0.29086560010910034, 'learning_rate': 3.705886034212138e-05, 'epoch': 4.05}\n",
      "{'loss': 0.0042, 'grad_norm': 0.019059641286730766, 'learning_rate': 3.6716145090661117e-05, 'epoch': 4.1}\n",
      "{'loss': 0.0037, 'grad_norm': 0.3473632335662842, 'learning_rate': 3.6370584758154366e-05, 'epoch': 4.14}\n",
      "{'loss': 0.005, 'grad_norm': 0.284930944442749, 'learning_rate': 3.6022263258477634e-05, 'epoch': 4.19}\n",
      "{'loss': 0.0069, 'grad_norm': 0.16256149113178253, 'learning_rate': 3.567126517601336e-05, 'epoch': 4.23}\n",
      "{'loss': 0.0142, 'grad_norm': 0.8129692673683167, 'learning_rate': 3.5317675745109866e-05, 'epoch': 4.28}\n",
      "{'loss': 0.0051, 'grad_norm': 0.14526353776454926, 'learning_rate': 3.496158082938359e-05, 'epoch': 4.32}\n",
      "{'loss': 0.0082, 'grad_norm': 0.19011251628398895, 'learning_rate': 3.4603066900868424e-05, 'epoch': 4.37}\n",
      "{'loss': 0.0057, 'grad_norm': 0.40378081798553467, 'learning_rate': 3.424222101901738e-05, 'epoch': 4.41}\n",
      "{'loss': 0.0025, 'grad_norm': 0.033679332584142685, 'learning_rate': 3.3879130809561546e-05, 'epoch': 4.45}\n",
      "{'loss': 0.0065, 'grad_norm': 0.4868108928203583, 'learning_rate': 3.3513884443231566e-05, 'epoch': 4.5}\n",
      "{'loss': 0.0045, 'grad_norm': 0.16418178379535675, 'learning_rate': 3.314657061434681e-05, 'epoch': 4.54}\n",
      "{'loss': 0.008, 'grad_norm': 0.49319735169410706, 'learning_rate': 3.277727851927727e-05, 'epoch': 4.59}\n",
      "{'loss': 0.0071, 'grad_norm': 0.20581196248531342, 'learning_rate': 3.240609783478372e-05, 'epoch': 4.63}\n",
      "{'loss': 0.0109, 'grad_norm': 0.0718843936920166, 'learning_rate': 3.203311869624107e-05, 'epoch': 4.68}\n",
      "{'loss': 0.0075, 'grad_norm': 0.418631374835968, 'learning_rate': 3.1658431675750424e-05, 'epoch': 4.72}\n",
      "{'loss': 0.0046, 'grad_norm': 0.14499270915985107, 'learning_rate': 3.128212776014509e-05, 'epoch': 4.77}\n",
      "{'loss': 0.0075, 'grad_norm': 1.39352285861969, 'learning_rate': 3.090429832889586e-05, 'epoch': 4.81}\n",
      "{'loss': 0.0103, 'grad_norm': 0.42433252930641174, 'learning_rate': 3.052503513192093e-05, 'epoch': 4.86}\n",
      "{'loss': 0.0117, 'grad_norm': 0.7047948241233826, 'learning_rate': 3.0144430267305872e-05, 'epoch': 4.9}\n",
      "{'loss': 0.0082, 'grad_norm': 0.7893269062042236, 'learning_rate': 2.9762576158939125e-05, 'epoch': 4.94}\n",
      "{'loss': 0.0074, 'grad_norm': 0.25741949677467346, 'learning_rate': 2.9379565534068242e-05, 'epoch': 4.99}\n",
      "{'loss': 0.0033, 'grad_norm': 0.002108147367835045, 'learning_rate': 2.899549140078256e-05, 'epoch': 5.03}\n",
      "{'loss': 0.0043, 'grad_norm': 0.011237433180212975, 'learning_rate': 2.8610447025427683e-05, 'epoch': 5.08}\n",
      "{'loss': 0.004, 'grad_norm': 0.1072034016251564, 'learning_rate': 2.8224525909957187e-05, 'epoch': 5.12}\n",
      "{'loss': 0.0031, 'grad_norm': 0.06282652169466019, 'learning_rate': 2.783782176922715e-05, 'epoch': 5.17}\n",
      "{'loss': 0.0017, 'grad_norm': 0.05135870352387428, 'learning_rate': 2.7450428508239024e-05, 'epoch': 5.21}\n",
      "{'loss': 0.0021, 'grad_norm': 0.009412425570189953, 'learning_rate': 2.706244019933618e-05, 'epoch': 5.26}\n",
      "{'loss': 0.0019, 'grad_norm': 0.07089898735284805, 'learning_rate': 2.6673951059360037e-05, 'epoch': 5.3}\n",
      "{'loss': 0.0035, 'grad_norm': 0.0034973390866070986, 'learning_rate': 2.5506422508214206e-05, 'epoch': 5.43}\n",
      "{'loss': 0.0058, 'grad_norm': 0.09696702659130096, 'learning_rate': 2.5116874300970138e-05, 'epoch': 5.48}\n",
      "{'loss': 0.0034, 'grad_norm': 0.023044375702738762, 'learning_rate': 2.4727297712645446e-05, 'epoch': 5.52}\n",
      "{'loss': 0.0036, 'grad_norm': 0.0747862160205841, 'learning_rate': 2.433778734577013e-05, 'epoch': 5.57}\n",
      "{'loss': 0.0043, 'grad_norm': 0.14265981316566467, 'learning_rate': 2.3948437786793377e-05, 'epoch': 5.61}\n",
      "{'loss': 0.0053, 'grad_norm': 0.556611955165863, 'learning_rate': 2.3559343583114707e-05, 'epoch': 5.66}\n",
      "{'loss': 0.0028, 'grad_norm': 0.12800383567810059, 'learning_rate': 2.3170599220124634e-05, 'epoch': 5.7}\n",
      "{'loss': 0.0038, 'grad_norm': 0.25606632232666016, 'learning_rate': 2.278229909826037e-05, 'epoch': 5.75}\n",
      "{'loss': 0.0068, 'grad_norm': 0.8821409940719604, 'learning_rate': 2.239453751008219e-05, 'epoch': 5.79}\n",
      "{'loss': 0.0025, 'grad_norm': 0.27689144015312195, 'learning_rate': 2.2007408617375943e-05, 'epoch': 5.84}\n",
      "{'loss': 0.0058, 'grad_norm': 0.5029561519622803, 'learning_rate': 2.162100642828737e-05, 'epoch': 5.88}\n",
      "{'loss': 0.0072, 'grad_norm': 0.01991024613380432, 'learning_rate': 2.1235424774493695e-05, 'epoch': 5.92}\n",
      "{'loss': 0.0038, 'grad_norm': 0.5323569774627686, 'learning_rate': 2.0850757288418103e-05, 'epoch': 5.97}\n",
      "{'loss': 0.0017, 'grad_norm': 0.03403838723897934, 'learning_rate': 2.0467097380492544e-05, 'epoch': 6.01}\n",
      "{'loss': 0.0015, 'grad_norm': 0.001841594697907567, 'learning_rate': 2.0084538216474524e-05, 'epoch': 6.06}\n",
      "{'loss': 0.001, 'grad_norm': 0.064612478017807, 'learning_rate': 1.9703172694823242e-05, 'epoch': 6.1}\n",
      "{'loss': 0.0012, 'grad_norm': 0.016973093152046204, 'learning_rate': 1.932309342414067e-05, 'epoch': 6.15}\n",
      "{'loss': 0.0013, 'grad_norm': 0.0026082745753228664, 'learning_rate': 1.894439270068304e-05, 'epoch': 6.19}\n",
      "{'loss': 0.0011, 'grad_norm': 0.05632920563220978, 'learning_rate': 1.8567162485948108e-05, 'epoch': 6.24}\n",
      "{'loss': 0.0006, 'grad_norm': 0.032477810978889465, 'learning_rate': 1.81914943843438e-05, 'epoch': 6.28}\n",
      "{'loss': 0.0004, 'grad_norm': 0.019383743405342102, 'learning_rate': 1.7817479620943488e-05, 'epoch': 6.33}\n",
      "{'loss': 0.0008, 'grad_norm': 0.13723164796829224, 'learning_rate': 1.744520901933346e-05, 'epoch': 6.37}\n",
      "{'loss': 0.0004, 'grad_norm': 0.005585169419646263, 'learning_rate': 1.7074772979557802e-05, 'epoch': 6.41}\n",
      "{'loss': 0.0009, 'grad_norm': 0.08893894404172897, 'learning_rate': 1.6706261456166205e-05, 'epoch': 6.46}\n",
      "{'loss': 0.0007, 'grad_norm': 0.02601487748324871, 'learning_rate': 1.633976393636989e-05, 'epoch': 6.5}\n",
      "{'loss': 0.0009, 'grad_norm': 0.17295204102993011, 'learning_rate': 1.5975369418311112e-05, 'epoch': 6.55}\n",
      "{'loss': 0.0037, 'grad_norm': 0.13214190304279327, 'learning_rate': 1.5613166389451284e-05, 'epoch': 6.59}\n",
      "{'loss': 0.0006, 'grad_norm': 0.15859605371952057, 'learning_rate': 1.5253242805083254e-05, 'epoch': 6.64}\n",
      "{'loss': 0.0014, 'grad_norm': 0.002338920719921589, 'learning_rate': 1.4895686066972703e-05, 'epoch': 6.68}\n",
      "{'loss': 0.0004, 'grad_norm': 0.038085103034973145, 'learning_rate': 1.4540583002134045e-05, 'epoch': 6.73}\n",
      "{'loss': 0.003, 'grad_norm': 0.03656884655356407, 'learning_rate': 1.4188019841745843e-05, 'epoch': 6.77}\n",
      "{'loss': 0.0009, 'grad_norm': 0.02411879226565361, 'learning_rate': 1.3838082200210931e-05, 'epoch': 6.82}\n",
      "{'loss': 0.0012, 'grad_norm': 0.27968886494636536, 'learning_rate': 1.3490855054366264e-05, 'epoch': 6.86}\n",
      "{'loss': 0.0036, 'grad_norm': 0.7791032791137695, 'learning_rate': 1.3146422722847712e-05, 'epoch': 6.9}\n",
      "{'loss': 0.0003, 'grad_norm': 0.002012615092098713, 'learning_rate': 1.2804868845614525e-05, 'epoch': 6.95}\n",
      "{'loss': 0.0003, 'grad_norm': 0.009141327813267708, 'learning_rate': 1.2466276363638778e-05, 'epoch': 6.99}\n",
      "{'loss': 0.0002, 'grad_norm': 0.018609412014484406, 'learning_rate': 1.2130727498764354e-05, 'epoch': 7.04}\n",
      "{'loss': 0.0009, 'grad_norm': 0.29644930362701416, 'learning_rate': 1.1798303733740802e-05, 'epoch': 7.08}\n",
      "{'loss': 0.0005, 'grad_norm': 0.04099328815937042, 'learning_rate': 1.1469085792436387e-05, 'epoch': 7.13}\n",
      "{'loss': 0.0001, 'grad_norm': 0.005387485958635807, 'learning_rate': 1.1143153620235705e-05, 'epoch': 7.17}\n",
      "{'loss': 0.0001, 'grad_norm': 0.01378466933965683, 'learning_rate': 1.0820586364626104e-05, 'epoch': 7.22}\n",
      "{'loss': 0.0001, 'grad_norm': 0.1089046373963356, 'learning_rate': 1.0501462355978048e-05, 'epoch': 7.26}\n",
      "{'loss': 0.0006, 'grad_norm': 0.20538483560085297, 'learning_rate': 1.0185859088523747e-05, 'epoch': 7.31}\n",
      "{'loss': 0.0002, 'grad_norm': 0.005565145052969456, 'learning_rate': 9.873853201538971e-06, 'epoch': 7.35}\n",
      "{'loss': 0.0001, 'grad_norm': 0.00124741205945611, 'learning_rate': 9.56552046073238e-06, 'epoch': 7.39}\n",
      "{'loss': 0.0001, 'grad_norm': 0.042716048657894135, 'learning_rate': 9.260935739846993e-06, 'epoch': 7.44}\n",
      "{'loss': 0.0003, 'grad_norm': 0.004463252145797014, 'learning_rate': 8.960173002478336e-06, 'epoch': 7.48}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0006406635511666536, 'learning_rate': 8.663305284113491e-06, 'epoch': 7.53}\n",
      "{'loss': 0.0, 'grad_norm': 0.000390872941352427, 'learning_rate': 8.370404674395631e-06, 'epoch': 7.57}\n",
      "{'loss': 0.0004, 'grad_norm': 0.12281029671430588, 'learning_rate': 8.081542299618139e-06, 'epoch': 7.62}\n",
      "{'loss': 0.0, 'grad_norm': 0.001480727456510067, 'learning_rate': 7.796788305452776e-06, 'epoch': 7.66}\n",
      "{'loss': 0.0, 'grad_norm': 0.003393286606296897, 'learning_rate': 7.516211839915821e-06, 'epoch': 7.71}\n",
      "{'loss': 0.0002, 'grad_norm': 0.17608967423439026, 'learning_rate': 7.239881036576651e-06, 'epoch': 7.75}\n",
      "{'loss': 0.0, 'grad_norm': 0.0024485751055181026, 'learning_rate': 6.967862998012509e-06, 'epoch': 7.8}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0009935878915712237, 'learning_rate': 6.70022377951377e-06, 'epoch': 7.84}\n",
      "{'loss': 0.0, 'grad_norm': 0.006695106625556946, 'learning_rate': 6.437028373043386e-06, 'epoch': 7.88}\n",
      "{'loss': 0.0, 'grad_norm': 0.0001094637336791493, 'learning_rate': 6.1783406914546645e-06, 'epoch': 7.93}\n",
      "{'loss': 0.0, 'grad_norm': 0.043656010180711746, 'learning_rate': 5.924223552971031e-06, 'epoch': 7.97}\n",
      "{'loss': 0.0003, 'grad_norm': 0.0019960172940045595, 'learning_rate': 5.674738665931575e-06, 'epoch': 8.02}\n",
      "{'loss': 0.0, 'grad_norm': 0.0007279913406819105, 'learning_rate': 5.429946613806219e-06, 'epoch': 8.06}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0006902983877807856, 'learning_rate': 5.18990684048391e-06, 'epoch': 8.11}\n",
      "{'loss': 0.0002, 'grad_norm': 0.003713150741532445, 'learning_rate': 4.954677635837668e-06, 'epoch': 8.15}\n",
      "{'loss': 0.0, 'grad_norm': 0.0038962247781455517, 'learning_rate': 4.72431612156976e-06, 'epoch': 8.2}\n",
      "{'loss': 0.0, 'grad_norm': 0.00017331480921711773, 'learning_rate': 4.498878237340637e-06, 'epoch': 8.24}\n",
      "{'loss': 0.0, 'grad_norm': 0.004297731909900904, 'learning_rate': 4.278418727184849e-06, 'epoch': 8.29}\n",
      "{'loss': 0.0006, 'grad_norm': 0.2355937510728836, 'learning_rate': 4.0629911262173056e-06, 'epoch': 8.33}\n",
      "{'loss': 0.0, 'grad_norm': 0.0025142147205770016, 'learning_rate': 3.852647747633156e-06, 'epoch': 8.37}\n",
      "{'loss': 0.0, 'grad_norm': 0.0006197079783305526, 'learning_rate': 3.6474396700043158e-06, 'epoch': 8.42}\n",
      "{'loss': 0.0, 'grad_norm': 0.0006346225272864103, 'learning_rate': 3.4474167248758654e-06, 'epoch': 8.46}\n",
      "{'loss': 0.0, 'grad_norm': 0.0006152878049761057, 'learning_rate': 3.252627484665241e-06, 'epoch': 8.51}\n",
      "{'loss': 0.0, 'grad_norm': 0.004324587993323803, 'learning_rate': 3.0631192508671857e-06, 'epoch': 8.55}\n",
      "{'loss': 0.0004, 'grad_norm': 0.002864051843062043, 'learning_rate': 1.7424175788259777e-06, 'epoch': 8.91}\n",
      "{'loss': 0.0, 'grad_norm': 0.0023441941011697054, 'learning_rate': 1.6023518310668618e-06, 'epoch': 8.95}\n",
      "{'loss': 0.0, 'grad_norm': 0.0009019987192004919, 'learning_rate': 1.4679678331343871e-06, 'epoch': 9.0}\n",
      "{'loss': 0.0, 'grad_norm': 0.00015387110761366785, 'learning_rate': 1.339298218062937e-06, 'epoch': 9.04}\n",
      "{'loss': 0.0002, 'grad_norm': 0.00045301043428480625, 'learning_rate': 1.216374231239134e-06, 'epoch': 9.09}\n",
      "{'loss': 0.0, 'grad_norm': 0.000898233090993017, 'learning_rate': 1.0992257228144064e-06, 'epoch': 9.13}\n",
      "{'loss': 0.0, 'grad_norm': 0.00018244593229610473, 'learning_rate': 9.878811404563342e-07, 'epoch': 9.18}\n",
      "{'loss': 0.0004, 'grad_norm': 0.0006067667854949832, 'learning_rate': 8.823675224406053e-07, 'epoch': 9.22}\n",
      "{'loss': 0.0, 'grad_norm': 0.00019332174269948155, 'learning_rate': 7.82710491085173e-07, 'epoch': 9.27}\n",
      "{'loss': 0.0, 'grad_norm': 0.001123066060245037, 'learning_rate': 6.889342465283e-07, 'epoch': 9.31}\n",
      "{'loss': 0.0, 'grad_norm': 0.0012352749472483993, 'learning_rate': 6.01061560851926e-07, 'epoch': 9.35}\n",
      "{'loss': 0.0001, 'grad_norm': 0.00024353005574084818, 'learning_rate': 5.191137725518213e-07, 'epoch': 9.4}\n",
      "{'loss': 0.0, 'grad_norm': 0.004026675131171942, 'learning_rate': 4.4311078135589045e-07, 'epoch': 9.44}\n",
      "{'loss': 0.0, 'grad_norm': 0.0003473280230537057, 'learning_rate': 3.730710433918039e-07, 'epoch': 9.49}\n",
      "{'loss': 0.0, 'grad_norm': 0.0032365117222070694, 'learning_rate': 3.090115667052557e-07, 'epoch': 9.53}\n",
      "{'loss': 0.0, 'grad_norm': 0.0008598954300396144, 'learning_rate': 2.5094790712980323e-07, 'epoch': 9.58}\n",
      "{'loss': 0.0, 'grad_norm': 0.003689327510073781, 'learning_rate': 1.9889416450938337e-07, 'epoch': 9.62}\n",
      "{'loss': 0.0, 'grad_norm': 0.00015164923388510942, 'learning_rate': 1.5286297927439575e-07, 'epoch': 9.67}\n",
      "{'loss': 0.0, 'grad_norm': 0.00039688427932560444, 'learning_rate': 1.1286552937216088e-07, 'epoch': 9.71}\n",
      "{'loss': 0.0, 'grad_norm': 0.0015586541267111897, 'learning_rate': 7.891152755254428e-08, 'epoch': 9.76}\n",
      "{'loss': 0.0, 'grad_norm': 0.0008381363586522639, 'learning_rate': 5.100921900935696e-08, 'epoch': 9.8}\n",
      "{'loss': 0.0, 'grad_norm': 0.007700600195676088, 'learning_rate': 2.9165379378151558e-08, 'epoch': 9.84}\n",
      "{'loss': 0.0, 'grad_norm': 0.0008329038391821086, 'learning_rate': 1.3385313090857887e-08, 'epoch': 9.89}\n",
      "{'loss': 0.0003, 'grad_norm': 0.00012461436563171446, 'learning_rate': 3.672852087691081e-09, 'epoch': 9.93}\n",
      "{'loss': 0.0, 'grad_norm': 0.00030763077666051686, 'learning_rate': 3.035488661262687e-11, 'epoch': 9.98}\n",
      "100%|█████████████████████████████████████| 2240/2240 [2:12:11<00:00,  3.47s/it][INFO|trainer.py:2329] 2024-06-14 19:10:45,543 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 7931.2639, 'train_samples_per_second': 2.264, 'train_steps_per_second': 0.282, 'train_loss': 0.01678896903511031, 'epoch': 9.98}\n",
      "100%|█████████████████████████████████████| 2240/2240 [2:12:11<00:00,  3.54s/it]\n",
      "[INFO|trainer.py:3410] 2024-06-14 19:10:45,563 >> Saving model checkpoint to /Utilisateurs/umushtaq/models/PE_ATC-LI-LTC_paragraph_wo_tags_llama-3-8b-Instruct-bnb-4bit\n",
      "[INFO|configuration_utils.py:733] 2024-06-14 19:10:45,903 >> loading configuration file config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/config.json\n",
      "[INFO|configuration_utils.py:796] 2024-06-14 19:10:45,904 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"_load_in_4bit\": true,\n",
      "    \"_load_in_8bit\": false,\n",
      "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "    \"bnb_4bit_quant_type\": \"nf4\",\n",
      "    \"bnb_4bit_use_double_quant\": true,\n",
      "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "    \"llm_int8_has_fp16_weight\": false,\n",
      "    \"llm_int8_skip_modules\": null,\n",
      "    \"llm_int8_threshold\": 6.0,\n",
      "    \"load_in_4bit\": true,\n",
      "    \"load_in_8bit\": false,\n",
      "    \"quant_method\": \"bitsandbytes\"\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2513] 2024-06-14 19:10:46,869 >> tokenizer config file saved in /Utilisateurs/umushtaq/models/PE_ATC-LI-LTC_paragraph_wo_tags_llama-3-8b-Instruct-bnb-4bit/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2522] 2024-06-14 19:10:46,870 >> Special tokens file saved in /Utilisateurs/umushtaq/models/PE_ATC-LI-LTC_paragraph_wo_tags_llama-3-8b-Instruct-bnb-4bit/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =      9.9777\n",
      "  total_flos               = 288068057GF\n",
      "  train_loss               =      0.0168\n",
      "  train_runtime            =  2:12:11.26\n",
      "  train_samples_per_second =       2.264\n",
      "  train_steps_per_second   =       0.282\n",
      "[INFO|modelcard.py:450] 2024-06-14 19:10:47,198 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 19:10:48,925 >> loading file tokenizer.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 19:10:48,928 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 19:10:48,930 >> loading file special_tokens_map.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 19:10:48,931 >> loading file tokenizer_config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/tokenizer_config.json\n",
      "[WARNING|logging.py:314] 2024-06-14 19:10:49,183 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/14/2024 19:10:49 - INFO - llamafactory.data.template - Replace eos token: <|eot_id|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:733] 2024-06-14 19:10:49,541 >> loading configuration file config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/config.json\n",
      "[INFO|configuration_utils.py:796] 2024-06-14 19:10:49,544 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"_load_in_4bit\": true,\n",
      "    \"_load_in_8bit\": false,\n",
      "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "    \"bnb_4bit_quant_type\": \"nf4\",\n",
      "    \"bnb_4bit_use_double_quant\": true,\n",
      "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "    \"llm_int8_has_fp16_weight\": false,\n",
      "    \"llm_int8_skip_modules\": null,\n",
      "    \"llm_int8_threshold\": 6.0,\n",
      "    \"load_in_4bit\": true,\n",
      "    \"load_in_8bit\": false,\n",
      "    \"quant_method\": \"bitsandbytes\"\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/14/2024 19:10:49 - INFO - llamafactory.model.utils.quantization - Loading ?-bit BITSANDBYTES-quantized model.\n",
      "06/14/2024 19:10:49 - INFO - llamafactory.model.patcher - Using KV cache for faster generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING|quantization_config.py:393] 2024-06-14 19:10:49,549 >> Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "[INFO|modeling_utils.py:3474] 2024-06-14 19:10:49,554 >> loading weights file model.safetensors from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/model.safetensors\n",
      "[INFO|modeling_utils.py:1519] 2024-06-14 19:10:49,584 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:962] 2024-06-14 19:10:49,590 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:4280] 2024-06-14 19:10:52,328 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4288] 2024-06-14 19:10:52,330 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at unsloth/llama-3-8b-Instruct-bnb-4bit.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:917] 2024-06-14 19:10:52,447 >> loading configuration file generation_config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/generation_config.json\n",
      "[INFO|configuration_utils.py:962] 2024-06-14 19:10:52,449 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128009\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/14/2024 19:10:52 - INFO - llamafactory.model.utils.attention - Using torch SDPA for faster training and inference.\n",
      "06/14/2024 19:10:52 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n",
      "06/14/2024 19:10:52 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n",
      "06/14/2024 19:10:53 - INFO - llamafactory.model.adapter - Loaded adapter(s): /Utilisateurs/umushtaq/models/PE_ATC-LI-LTC_paragraph_wo_tags_llama-3-8b-Instruct-bnb-4bit\n",
      "06/14/2024 19:10:53 - INFO - llamafactory.model.loader - all params: 8051232768\n"
     ]
    }
   ],
   "source": [
    "for model_instance in model_names: # 3 models\n",
    "\n",
    "    for dataset in dataset_names:\n",
    "\n",
    "        l = [model_instance] + dataset\n",
    "        \n",
    "        with open(\"tmp.pkl\", \"wb\") as fh:\n",
    "            \n",
    "            pickle.dump(l, fh)\n",
    "        \n",
    "        print(f\"\\nRunning experiment: {l}\")\n",
    "        \n",
    "        \n",
    "        %run ./PE_ATC-LI-LTC_finetune.ipynb\n",
    "        %cd /Utilisateurs/umushtaq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
