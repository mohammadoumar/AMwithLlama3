{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "671272c9-0c9d-4265-a75b-480471345729",
   "metadata": {},
   "source": [
    "# Run Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1165cbdc-bb7a-48d3-b17d-442687c00173",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3de7add-5182-4d9f-af93-5446726c9d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e11ea0-ff3f-44eb-9577-5eedba91e3cc",
   "metadata": {},
   "source": [
    "## Run notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d31e870a-6452-42fb-9206-19e4e4da5e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"unsloth/llama-3-8b-Instruct-bnb-4bit\", \n",
    "    \"unsloth/llama-3-8b-Instruct\", \n",
    "    # \"unsloth/llama-3-70b-Instruct-bnb-4bit\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73d02aa6-1840-4b3e-a5c3-a283f3884c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\n",
    "    # [\"PE_LI_paragraph_train.json\", \"PE_LI_paragraph_test.json\"],\n",
    "    #[\"PE_LI_paragraph_wo_tags_train.json\", \"PE_LI_paragraph_wo_tags_test.json\"],\n",
    "    # [\"PE_LI_essay_train.json\", \"PE_LI_essay_test.json\"],\n",
    "    # [\"PE_LI_essay_wo_tags_train.json\", \"PE_LI_essay_wo_tags_test.json\"],\n",
    "    #[\"PE_LI_paragraph_wo_tags_wo_comptypes_train.json\", \"PE_LI_paragraph_wo_tags_wo_comptypes_test.json\"]\n",
    "    [\"PE_LI_paragraph_wo_comptypes_train.json\", \"PE_LI_paragraph_wo_comptypes_test.json\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd041309-0821-4132-ad90-94835c839690",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running experiment: ['unsloth/llama-3-8b-Instruct-bnb-4bit', 'PE_LI_paragraph_wo_comptypes_train.json', 'PE_LI_paragraph_wo_comptypes_test.json']\n",
      "/Utilisateurs/umushtaq/LLaMA-Factory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Utilisateurs/umushtaq/.conda/envs/llama-factory-notebook/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/14/2024 14:26:18 - WARNING - llamafactory.hparams.parser - We recommend enable `upcast_layernorm` in quantized training.\n",
      "06/14/2024 14:26:18 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: torch.float16\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 14:26:18,308 >> loading file tokenizer.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 14:26:18,308 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 14:26:18,308 >> loading file special_tokens_map.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 14:26:18,308 >> loading file tokenizer_config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/tokenizer_config.json\n",
      "[WARNING|logging.py:314] 2024-06-14 14:26:18,561 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "06/14/2024 14:26:18 - INFO - llamafactory.data.template - Replace eos token: <|eot_id|>\n",
      "06/14/2024 14:26:18 - INFO - llamafactory.data.loader - Loading dataset /Utilisateurs/umushtaq/datasets/PE_LI_paragraph_wo_comptypes_train.json...\n",
      "input_ids:\n",
      "[128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 18328, 13, 128009, 128006, 882, 128007, 271, 14711, 1472, 527, 459, 6335, 304, 14138, 26917, 13, 1472, 527, 2728, 264, 14646, 902, 5727, 5811, 6956, 44910, 555, 366, 1741, 1500, 1741, 29, 9681, 13, 4718, 3465, 374, 311, 10765, 5811, 4398, 1990, 5811, 6956, 304, 279, 14646, 13, 1472, 2011, 471, 264, 1160, 315, 5811, 3777, 13840, 304, 2768, 4823, 3645, 25, 5324, 1638, 9202, 95321, 794, 4416, 5775, 10807, 320, 396, 705, 2592, 10807, 320, 396, 26090, 61453, 510, 5775, 10807, 320, 396, 705, 2592, 10807, 320, 396, 8, 5163, 633, 14711, 5810, 374, 279, 14646, 1495, 25, 366, 16816, 29, 12540, 4236, 387, 15972, 311, 20874, 477, 311, 47903, 949, 694, 16816, 29, 128009, 128006, 78191, 128007, 271, 5018, 1638, 9202, 95321, 794, 3132, 92, 128009]\n",
      "inputs:\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "### You are an expert in Argument Mining. You are given a paragraph which contains argument components enclosed by <AC></AC> tags. Your task is to identify argument relations between argument components in the paragraph. You must return a list of argument component pairs in following JSON format: {\"list_argument_relations\": [[target AC (int), source AC (int)],..., [target AC (int), source AC (int)]]}\n",
      "\n",
      "### Here is the paragraph text: <topic> Should students be taught to compete or to cooperate? </topic><|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\"list_argument_relations\": []}<|eot_id|>\n",
      "label_ids:\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 5018, 1638, 9202, 95321, 794, 3132, 92, 128009]\n",
      "labels:\n",
      "{\"list_argument_relations\": []}<|eot_id|>\n",
      "/Utilisateurs/umushtaq/.conda/envs/llama-factory-notebook/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "[INFO|configuration_utils.py:733] 2024-06-14 14:26:19,518 >> loading configuration file config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/config.json\n",
      "[INFO|configuration_utils.py:796] 2024-06-14 14:26:19,519 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"_load_in_4bit\": true,\n",
      "    \"_load_in_8bit\": false,\n",
      "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "    \"bnb_4bit_quant_type\": \"nf4\",\n",
      "    \"bnb_4bit_use_double_quant\": true,\n",
      "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "    \"llm_int8_has_fp16_weight\": false,\n",
      "    \"llm_int8_skip_modules\": null,\n",
      "    \"llm_int8_threshold\": 6.0,\n",
      "    \"load_in_4bit\": true,\n",
      "    \"load_in_8bit\": false,\n",
      "    \"quant_method\": \"bitsandbytes\"\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "06/14/2024 14:26:19 - INFO - llamafactory.model.utils.quantization - Loading ?-bit BITSANDBYTES-quantized model.\n",
      "[WARNING|quantization_config.py:393] 2024-06-14 14:26:19,970 >> Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "[INFO|modeling_utils.py:3474] 2024-06-14 14:26:19,973 >> loading weights file model.safetensors from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/model.safetensors\n",
      "[INFO|modeling_utils.py:1519] 2024-06-14 14:26:20,003 >> Instantiating LlamaForCausalLM model under default dtype torch.float16.\n",
      "[INFO|configuration_utils.py:962] 2024-06-14 14:26:20,007 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:4280] 2024-06-14 14:26:22,870 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4288] 2024-06-14 14:26:22,870 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at unsloth/llama-3-8b-Instruct-bnb-4bit.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:917] 2024-06-14 14:26:22,975 >> loading configuration file generation_config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/generation_config.json\n",
      "[INFO|configuration_utils.py:962] 2024-06-14 14:26:22,976 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128009\n",
      "  ]\n",
      "}\n",
      "\n",
      "06/14/2024 14:26:23 - INFO - llamafactory.model.utils.checkpointing - Gradient checkpointing enabled.\n",
      "06/14/2024 14:26:23 - INFO - llamafactory.model.utils.attention - Using torch SDPA for faster training and inference.\n",
      "06/14/2024 14:26:23 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n",
      "06/14/2024 14:26:23 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n",
      "06/14/2024 14:26:23 - INFO - llamafactory.model.utils.misc - Found linear modules: v_proj,k_proj,o_proj,up_proj,q_proj,down_proj,gate_proj\n",
      "06/14/2024 14:26:23 - INFO - llamafactory.model.loader - trainable params: 20971520 || all params: 8051232768 || trainable%: 0.2605\n",
      "[INFO|trainer.py:641] 2024-06-14 14:26:23,415 >> Using auto half precision backend\n",
      "06/14/2024 14:26:23 - INFO - llamafactory.train.utils - Using LoRA+ optimizer with loraplus lr ratio 16.00.\n",
      "[INFO|trainer.py:2078] 2024-06-14 14:26:23,627 >> ***** Running training *****\n",
      "[INFO|trainer.py:2079] 2024-06-14 14:26:23,627 >>   Num examples = 1,796\n",
      "[INFO|trainer.py:2080] 2024-06-14 14:26:23,627 >>   Num Epochs = 10\n",
      "[INFO|trainer.py:2081] 2024-06-14 14:26:23,627 >>   Instantaneous batch size per device = 2\n",
      "[INFO|trainer.py:2084] 2024-06-14 14:26:23,627 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "[INFO|trainer.py:2085] 2024-06-14 14:26:23,627 >>   Gradient Accumulation steps = 4\n",
      "[INFO|trainer.py:2086] 2024-06-14 14:26:23,627 >>   Total optimization steps = 2,240\n",
      "[INFO|trainer.py:2087] 2024-06-14 14:26:23,630 >>   Number of trainable parameters = 20,971,520\n",
      "{'loss': 1.0847, 'grad_norm': 7.297872066497803, 'learning_rate': 1.7857142857142857e-06, 'epoch': 0.04}\n",
      "{'loss': 0.2364, 'grad_norm': 1.173977017402649, 'learning_rate': 4.017857142857143e-06, 'epoch': 0.09}\n",
      "{'loss': 0.156, 'grad_norm': 0.7368801236152649, 'learning_rate': 6.25e-06, 'epoch': 0.13}\n",
      "{'loss': 0.0993, 'grad_norm': 0.5906097888946533, 'learning_rate': 8.482142857142858e-06, 'epoch': 0.18}\n",
      "{'loss': 0.1204, 'grad_norm': 1.023564100265503, 'learning_rate': 1.0714285714285714e-05, 'epoch': 0.22}\n",
      "{'loss': 0.0864, 'grad_norm': 0.7779461741447449, 'learning_rate': 1.2946428571428574e-05, 'epoch': 0.27}\n",
      "{'loss': 0.0784, 'grad_norm': 0.41860589385032654, 'learning_rate': 1.5178571428571429e-05, 'epoch': 0.31}\n",
      "{'loss': 0.0749, 'grad_norm': 0.5105197429656982, 'learning_rate': 1.7410714285714287e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0682, 'grad_norm': 0.2912063002586365, 'learning_rate': 1.9642857142857145e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0719, 'grad_norm': 1.0486806631088257, 'learning_rate': 2.1875e-05, 'epoch': 0.45}\n",
      "{'loss': 0.0896, 'grad_norm': 0.22128567099571228, 'learning_rate': 2.4107142857142858e-05, 'epoch': 0.49}\n",
      "{'loss': 0.0907, 'grad_norm': 0.39092740416526794, 'learning_rate': 2.6339285714285716e-05, 'epoch': 0.53}\n",
      "{'loss': 0.0707, 'grad_norm': 1.4452064037322998, 'learning_rate': 2.857142857142857e-05, 'epoch': 0.58}\n",
      "{'loss': 0.0697, 'grad_norm': 0.20532122254371643, 'learning_rate': 3.080357142857143e-05, 'epoch': 0.62}\n",
      "{'loss': 0.0649, 'grad_norm': 1.0211907625198364, 'learning_rate': 3.303571428571429e-05, 'epoch': 0.67}\n",
      "{'loss': 0.1032, 'grad_norm': 0.49068042635917664, 'learning_rate': 3.5267857142857145e-05, 'epoch': 0.71}\n",
      "{'loss': 0.0935, 'grad_norm': 0.6979406476020813, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.76}\n",
      "{'loss': 0.1048, 'grad_norm': 0.486186683177948, 'learning_rate': 3.9732142857142855e-05, 'epoch': 0.8}\n",
      "{'loss': 0.0652, 'grad_norm': 1.1184605360031128, 'learning_rate': 4.196428571428572e-05, 'epoch': 0.85}\n",
      "{'loss': 0.0678, 'grad_norm': 1.8681275844573975, 'learning_rate': 4.419642857142857e-05, 'epoch': 0.89}\n",
      "{'loss': 0.0819, 'grad_norm': 0.6910600066184998, 'learning_rate': 4.642857142857143e-05, 'epoch': 0.94}\n",
      "{'loss': 0.0817, 'grad_norm': 0.5364624857902527, 'learning_rate': 4.866071428571429e-05, 'epoch': 0.98}\n",
      "{'loss': 0.0787, 'grad_norm': 0.7919948697090149, 'learning_rate': 4.9999514323288454e-05, 'epoch': 1.02}\n",
      "{'loss': 0.0621, 'grad_norm': 0.5773120522499084, 'learning_rate': 4.999405067699773e-05, 'epoch': 1.07}\n",
      "{'loss': 0.0418, 'grad_norm': 0.24357536435127258, 'learning_rate': 4.998251761970997e-05, 'epoch': 1.11}\n",
      "{'loss': 0.0466, 'grad_norm': 0.39936232566833496, 'learning_rate': 4.996491795204623e-05, 'epoch': 1.16}\n",
      "{'loss': 0.063, 'grad_norm': 0.6347748041152954, 'learning_rate': 4.9941255947808224e-05, 'epoch': 1.2}\n",
      "{'loss': 0.0644, 'grad_norm': 0.282687246799469, 'learning_rate': 4.991153735294049e-05, 'epoch': 1.25}\n",
      "{'loss': 0.0459, 'grad_norm': 0.7362882494926453, 'learning_rate': 4.987576938413504e-05, 'epoch': 1.29}\n",
      "{'loss': 0.0483, 'grad_norm': 0.4361443519592285, 'learning_rate': 4.9838413145893615e-05, 'epoch': 1.34}\n",
      "{'loss': 0.0599, 'grad_norm': 0.3556797504425049, 'learning_rate': 4.979117650810495e-05, 'epoch': 1.38}\n",
      "{'loss': 0.066, 'grad_norm': 0.7366155385971069, 'learning_rate': 4.973791972411141e-05, 'epoch': 1.43}\n",
      "{'loss': 0.0575, 'grad_norm': 0.3779875934123993, 'learning_rate': 4.9678655726483014e-05, 'epoch': 1.47}\n",
      "{'loss': 0.0682, 'grad_norm': 0.42565882205963135, 'learning_rate': 4.961339890654685e-05, 'epoch': 1.51}\n",
      "{'loss': 0.0727, 'grad_norm': 0.5469765663146973, 'learning_rate': 4.9542165110892414e-05, 'epoch': 1.56}\n",
      "{'loss': 0.0807, 'grad_norm': 0.7399115562438965, 'learning_rate': 4.946497163752346e-05, 'epoch': 1.6}\n",
      "{'loss': 0.0623, 'grad_norm': 0.3653072416782379, 'learning_rate': 4.93818372316575e-05, 'epoch': 1.65}\n",
      "{'loss': 0.062, 'grad_norm': 0.4373577833175659, 'learning_rate': 4.929278208117378e-05, 'epoch': 1.69}\n",
      "{'loss': 0.0821, 'grad_norm': 0.4455150365829468, 'learning_rate': 4.919782781171101e-05, 'epoch': 1.74}\n",
      "{'loss': 0.0652, 'grad_norm': 1.021269679069519, 'learning_rate': 4.9096997481415885e-05, 'epoch': 1.78}\n",
      "{'loss': 0.0433, 'grad_norm': 0.44795486330986023, 'learning_rate': 4.899031557534383e-05, 'epoch': 1.83}\n",
      "{'loss': 0.0829, 'grad_norm': 0.9393372535705566, 'learning_rate': 4.88778079995131e-05, 'epoch': 1.87}\n",
      "{'loss': 0.0573, 'grad_norm': 0.24513530731201172, 'learning_rate': 4.8759502074614026e-05, 'epoch': 1.92}\n",
      "{'loss': 0.0598, 'grad_norm': 1.176405668258667, 'learning_rate': 4.863542652937453e-05, 'epoch': 1.96}\n",
      "{'loss': 0.0813, 'grad_norm': 0.5091997385025024, 'learning_rate': 4.8505611493583814e-05, 'epoch': 2.0}\n",
      "{'loss': 0.0305, 'grad_norm': 0.3769644498825073, 'learning_rate': 4.837008849077588e-05, 'epoch': 2.05}\n",
      "{'loss': 0.0337, 'grad_norm': 0.5800701379776001, 'learning_rate': 4.822889043057446e-05, 'epoch': 2.09}\n",
      "{'loss': 0.0349, 'grad_norm': 1.523342251777649, 'learning_rate': 4.808205160070147e-05, 'epoch': 2.14}\n",
      "{'loss': 0.0539, 'grad_norm': 0.4220997393131256, 'learning_rate': 4.79296076586508e-05, 'epoch': 2.18}\n",
      "{'loss': 0.0361, 'grad_norm': 0.36578038334846497, 'learning_rate': 4.7771595623029394e-05, 'epoch': 2.23}\n",
      "{'loss': 0.0424, 'grad_norm': 0.9326308369636536, 'learning_rate': 4.7608053864567926e-05, 'epoch': 2.27}\n",
      "{'loss': 0.0289, 'grad_norm': 1.0197561979293823, 'learning_rate': 4.743902209680302e-05, 'epoch': 2.32}\n",
      "{'loss': 0.0276, 'grad_norm': 0.23878376185894012, 'learning_rate': 4.7264541366433494e-05, 'epoch': 2.36}\n",
      "{'loss': 0.0604, 'grad_norm': 1.2587740421295166, 'learning_rate': 4.708465404335277e-05, 'epoch': 2.41}\n",
      "{'loss': 0.0309, 'grad_norm': 0.527328610420227, 'learning_rate': 4.6899403810360055e-05, 'epoch': 2.45}\n",
      "{'loss': 0.0432, 'grad_norm': 0.39296388626098633, 'learning_rate': 4.670883565255264e-05, 'epoch': 2.49}\n",
      "{'loss': 0.0523, 'grad_norm': 1.8643789291381836, 'learning_rate': 4.6512995846401975e-05, 'epoch': 2.54}\n",
      "{'loss': 0.0271, 'grad_norm': 0.41386812925338745, 'learning_rate': 4.631193194851617e-05, 'epoch': 2.58}\n",
      "{'loss': 0.0534, 'grad_norm': 0.3622496426105499, 'learning_rate': 4.6105692784091636e-05, 'epoch': 2.63}\n",
      "{'loss': 0.0581, 'grad_norm': 0.8252023458480835, 'learning_rate': 4.589432843505659e-05, 'epoch': 2.67}\n",
      "{'loss': 0.0492, 'grad_norm': 0.30164259672164917, 'learning_rate': 4.567789022790953e-05, 'epoch': 2.72}\n",
      "{'loss': 0.0339, 'grad_norm': 0.7029628157615662, 'learning_rate': 4.545643072125538e-05, 'epoch': 2.76}\n",
      "{'loss': 0.0427, 'grad_norm': 0.42329373955726624, 'learning_rate': 4.523000369304243e-05, 'epoch': 2.81}\n",
      "{'loss': 0.0307, 'grad_norm': 0.833856463432312, 'learning_rate': 4.499866412750324e-05, 'epoch': 2.85}\n",
      "{'loss': 0.0359, 'grad_norm': 0.39904841780662537, 'learning_rate': 4.476246820180259e-05, 'epoch': 2.9}\n",
      "{'loss': 0.0392, 'grad_norm': 0.4412919282913208, 'learning_rate': 4.452147327239571e-05, 'epoch': 2.94}\n",
      "{'loss': 0.0331, 'grad_norm': 1.1315892934799194, 'learning_rate': 4.4275737861100194e-05, 'epoch': 2.98}\n",
      "{'loss': 0.0374, 'grad_norm': 0.39096200466156006, 'learning_rate': 4.4025321640884905e-05, 'epoch': 3.03}\n",
      "{'loss': 0.0157, 'grad_norm': 0.03437335789203644, 'learning_rate': 4.3770285421379324e-05, 'epoch': 3.07}\n",
      "{'loss': 0.0259, 'grad_norm': 0.49938908219337463, 'learning_rate': 4.351069113410688e-05, 'epoch': 3.12}\n",
      "{'loss': 0.025, 'grad_norm': 0.6547386646270752, 'learning_rate': 4.324660181744589e-05, 'epoch': 3.16}\n",
      "{'loss': 0.0321, 'grad_norm': 0.5113311409950256, 'learning_rate': 4.297808160132165e-05, 'epoch': 3.21}\n",
      "{'loss': 0.0163, 'grad_norm': 0.06706878542900085, 'learning_rate': 4.270519569163348e-05, 'epoch': 3.25}\n",
      "{'loss': 0.026, 'grad_norm': 0.7574459910392761, 'learning_rate': 4.242801035442058e-05, 'epoch': 3.3}\n",
      "{'loss': 0.0279, 'grad_norm': 0.20183148980140686, 'learning_rate': 4.214659289977027e-05, 'epoch': 3.34}\n",
      "{'loss': 0.0242, 'grad_norm': 0.14797890186309814, 'learning_rate': 4.186101166547286e-05, 'epoch': 3.39}\n",
      "{'loss': 0.0421, 'grad_norm': 1.2076586484909058, 'learning_rate': 4.157133600042686e-05, 'epoch': 3.43}\n",
      "{'loss': 0.0178, 'grad_norm': 0.5127634406089783, 'learning_rate': 4.127763624779873e-05, 'epoch': 3.47}\n",
      "{'loss': 0.0144, 'grad_norm': 0.7237257361412048, 'learning_rate': 4.0979983727941115e-05, 'epoch': 3.52}\n",
      "{'loss': 0.0286, 'grad_norm': 0.8956849575042725, 'learning_rate': 4.067845072107383e-05, 'epoch': 3.56}\n",
      "{'loss': 0.026, 'grad_norm': 0.4948299825191498, 'learning_rate': 4.03731104497318e-05, 'epoch': 3.61}\n",
      "{'loss': 0.0167, 'grad_norm': 0.5653029680252075, 'learning_rate': 4.0064037060984017e-05, 'epoch': 3.65}\n",
      "{'loss': 0.0273, 'grad_norm': 0.6604352593421936, 'learning_rate': 3.9751305608428205e-05, 'epoch': 3.7}\n",
      "{'loss': 0.0301, 'grad_norm': 0.33407703042030334, 'learning_rate': 3.943499203396517e-05, 'epoch': 3.74}\n",
      "{'loss': 0.0279, 'grad_norm': 0.7852070331573486, 'learning_rate': 3.911517314935752e-05, 'epoch': 3.79}\n",
      "{'loss': 0.0217, 'grad_norm': 0.9598233699798584, 'learning_rate': 3.8791926617577144e-05, 'epoch': 3.83}\n",
      "{'loss': 0.0264, 'grad_norm': 1.1314343214035034, 'learning_rate': 3.846533093394601e-05, 'epoch': 3.88}\n",
      "{'loss': 0.0187, 'grad_norm': 0.10320654511451721, 'learning_rate': 3.8135465407074756e-05, 'epoch': 3.92}\n",
      "{'loss': 0.0271, 'grad_norm': 0.3647598624229431, 'learning_rate': 3.780241013960391e-05, 'epoch': 3.96}\n",
      "{'loss': 0.0252, 'grad_norm': 0.5027962923049927, 'learning_rate': 3.746624600875216e-05, 'epoch': 4.01}\n",
      "{'loss': 0.0138, 'grad_norm': 1.1354008913040161, 'learning_rate': 3.712705464667667e-05, 'epoch': 4.05}\n",
      "{'loss': 0.0158, 'grad_norm': 0.05020046979188919, 'learning_rate': 3.678491842064995e-05, 'epoch': 4.1}\n",
      "{'loss': 0.007, 'grad_norm': 0.4084474444389343, 'learning_rate': 3.6439920413058244e-05, 'epoch': 4.14}\n",
      "{'loss': 0.007, 'grad_norm': 0.9632817506790161, 'learning_rate': 3.609214440122635e-05, 'epoch': 4.19}\n",
      "{'loss': 0.0152, 'grad_norm': 0.9525646567344666, 'learning_rate': 3.574167483707356e-05, 'epoch': 4.23}\n",
      "{'loss': 0.0134, 'grad_norm': 0.5040090680122375, 'learning_rate': 3.5388596826605885e-05, 'epoch': 4.28}\n",
      "{'loss': 0.0123, 'grad_norm': 0.5677099823951721, 'learning_rate': 3.503299610924935e-05, 'epoch': 4.32}\n",
      "{'loss': 0.0079, 'grad_norm': 0.1699989289045334, 'learning_rate': 3.4674959037029594e-05, 'epoch': 4.37}\n",
      "{'loss': 0.0092, 'grad_norm': 0.8247305154800415, 'learning_rate': 3.4314572553602576e-05, 'epoch': 4.41}\n",
      "{'loss': 0.0037, 'grad_norm': 0.09206452965736389, 'learning_rate': 3.3951924173141735e-05, 'epoch': 4.45}\n",
      "{'loss': 0.0115, 'grad_norm': 1.0313462018966675, 'learning_rate': 3.358710195908653e-05, 'epoch': 4.5}\n",
      "{'loss': 0.0135, 'grad_norm': 1.1283725500106812, 'learning_rate': 3.32201945027576e-05, 'epoch': 4.54}\n",
      "{'loss': 0.0065, 'grad_norm': 0.24020305275917053, 'learning_rate': 3.2851290901843807e-05, 'epoch': 4.59}\n",
      "{'loss': 0.0056, 'grad_norm': 0.2186453938484192, 'learning_rate': 3.248048073876622e-05, 'epoch': 4.63}\n",
      "{'loss': 0.0112, 'grad_norm': 1.8689186573028564, 'learning_rate': 3.210785405892448e-05, 'epoch': 4.68}\n",
      "{'loss': 0.0139, 'grad_norm': 1.225500464439392, 'learning_rate': 3.173350134883066e-05, 'epoch': 4.72}\n",
      "{'loss': 0.0183, 'grad_norm': 0.055434100329875946, 'learning_rate': 3.1357513514136044e-05, 'epoch': 4.77}\n",
      "{'loss': 0.01, 'grad_norm': 0.7709784507751465, 'learning_rate': 3.097998185755618e-05, 'epoch': 4.81}\n",
      "{'loss': 0.0153, 'grad_norm': 1.1206494569778442, 'learning_rate': 3.0600998056699364e-05, 'epoch': 4.86}\n",
      "{'loss': 0.0101, 'grad_norm': 0.5573444962501526, 'learning_rate': 3.022065414180425e-05, 'epoch': 4.9}\n",
      "{'loss': 0.0173, 'grad_norm': 1.4618958234786987, 'learning_rate': 2.983904247339173e-05, 'epoch': 4.94}\n",
      "{'loss': 0.0089, 'grad_norm': 0.9072751998901367, 'learning_rate': 2.9456255719836644e-05, 'epoch': 4.99}\n",
      "{'loss': 0.0065, 'grad_norm': 0.0017316057346761227, 'learning_rate': 2.9072386834864724e-05, 'epoch': 5.03}\n",
      "{'loss': 0.007, 'grad_norm': 0.021861650049686432, 'learning_rate': 2.8687529034980244e-05, 'epoch': 5.08}\n",
      "{'loss': 0.0021, 'grad_norm': 0.048342205584049225, 'learning_rate': 2.8301775776829876e-05, 'epoch': 5.12}\n",
      "{'loss': 0.0058, 'grad_norm': 0.02653946541249752, 'learning_rate': 2.791522073450819e-05, 'epoch': 5.17}\n",
      "{'loss': 0.0078, 'grad_norm': 0.019243301823735237, 'learning_rate': 2.752795777681043e-05, 'epoch': 5.21}\n",
      "{'loss': 0.0018, 'grad_norm': 0.01228444091975689, 'learning_rate': 2.71400809444379e-05, 'epoch': 5.26}\n",
      "{'loss': 0.0034, 'grad_norm': 0.04036032781004906, 'learning_rate': 2.6751684427161683e-05, 'epoch': 5.3}\n",
      "{'loss': 0.0046, 'grad_norm': 0.005290308501571417, 'learning_rate': 2.6362862540950162e-05, 'epoch': 5.35}\n",
      "{'loss': 0.0032, 'grad_norm': 0.29026564955711365, 'learning_rate': 2.5973709705065834e-05, 'epoch': 5.39}\n",
      "{'loss': 0.0054, 'grad_norm': 1.650230884552002, 'learning_rate': 2.5584320419137127e-05, 'epoch': 5.43}\n",
      "{'loss': 0.0026, 'grad_norm': 0.4062325954437256, 'learning_rate': 2.519478924021062e-05, 'epoch': 5.48}\n",
      "{'loss': 0.0043, 'grad_norm': 0.06094023957848549, 'learning_rate': 2.4805210759789382e-05, 'epoch': 5.52}\n",
      "{'loss': 0.0007, 'grad_norm': 0.00452069565653801, 'learning_rate': 2.441567958086288e-05, 'epoch': 5.57}\n",
      "{'loss': 0.0045, 'grad_norm': 0.3654347360134125, 'learning_rate': 2.4026290294934175e-05, 'epoch': 5.61}\n",
      "{'loss': 0.0063, 'grad_norm': 1.379103660583496, 'learning_rate': 2.363713745904984e-05, 'epoch': 5.66}\n",
      "{'loss': 0.0083, 'grad_norm': 0.08596259355545044, 'learning_rate': 2.3248315572838316e-05, 'epoch': 5.7}\n",
      "{'loss': 0.0054, 'grad_norm': 0.22690148651599884, 'learning_rate': 2.2859919055562105e-05, 'epoch': 5.75}\n",
      "{'loss': 0.0102, 'grad_norm': 1.3927212953567505, 'learning_rate': 2.2472042223189572e-05, 'epoch': 5.79}\n",
      "{'loss': 0.0053, 'grad_norm': 0.9230027198791504, 'learning_rate': 2.2084779265491813e-05, 'epoch': 5.84}\n",
      "{'loss': 0.0059, 'grad_norm': 1.056772232055664, 'learning_rate': 2.169822422317014e-05, 'epoch': 5.88}\n",
      "{'loss': 0.0024, 'grad_norm': 0.010692880488932133, 'learning_rate': 2.1312470965019762e-05, 'epoch': 5.92}\n",
      "{'loss': 0.0044, 'grad_norm': 0.3631038963794708, 'learning_rate': 2.0927613165135285e-05, 'epoch': 5.97}\n",
      "{'loss': 0.0028, 'grad_norm': 0.018954241648316383, 'learning_rate': 2.0543744280163362e-05, 'epoch': 6.01}\n",
      "{'loss': 0.0069, 'grad_norm': 0.005280369892716408, 'learning_rate': 2.0160957526608276e-05, 'epoch': 6.06}\n",
      "{'loss': 0.0015, 'grad_norm': 0.3481135964393616, 'learning_rate': 1.977934585819576e-05, 'epoch': 6.1}\n",
      "{'loss': 0.0004, 'grad_norm': 0.08939743787050247, 'learning_rate': 1.9399001943300645e-05, 'epoch': 6.15}\n",
      "{'loss': 0.0022, 'grad_norm': 0.0009323503472842276, 'learning_rate': 1.9020018142443833e-05, 'epoch': 6.19}\n",
      "{'loss': 0.0012, 'grad_norm': 0.10679825395345688, 'learning_rate': 1.864248648586395e-05, 'epoch': 6.24}\n",
      "{'loss': 0.0033, 'grad_norm': 0.5250513553619385, 'learning_rate': 1.826649865116935e-05, 'epoch': 6.28}\n",
      "{'loss': 0.0028, 'grad_norm': 0.10798316448926926, 'learning_rate': 1.7892145941075526e-05, 'epoch': 6.33}\n",
      "{'loss': 0.0021, 'grad_norm': 0.19826582074165344, 'learning_rate': 1.7519519261233786e-05, 'epoch': 6.37}\n",
      "{'loss': 0.0062, 'grad_norm': 0.04046659544110298, 'learning_rate': 1.7148709098156203e-05, 'epoch': 6.41}\n",
      "{'loss': 0.0005, 'grad_norm': 0.039320219308137894, 'learning_rate': 1.6779805497242406e-05, 'epoch': 6.46}\n",
      "{'loss': 0.0002, 'grad_norm': 0.008314164355397224, 'learning_rate': 1.641289804091347e-05, 'epoch': 6.5}\n",
      "{'loss': 0.0008, 'grad_norm': 0.21296045184135437, 'learning_rate': 1.6048075826858264e-05, 'epoch': 6.55}\n",
      "{'loss': 0.0003, 'grad_norm': 0.04842454567551613, 'learning_rate': 1.5685427446397427e-05, 'epoch': 6.59}\n",
      "{'loss': 0.003, 'grad_norm': 0.00816369242966175, 'learning_rate': 1.5325040962970415e-05, 'epoch': 6.64}\n",
      "{'loss': 0.0002, 'grad_norm': 0.001673891325481236, 'learning_rate': 1.4967003890750656e-05, 'epoch': 6.68}\n",
      "{'loss': 0.0016, 'grad_norm': 0.00889293197542429, 'learning_rate': 1.4611403173394126e-05, 'epoch': 6.73}\n",
      "{'loss': 0.003, 'grad_norm': 0.17620891332626343, 'learning_rate': 1.4258325162926442e-05, 'epoch': 6.77}\n",
      "{'loss': 0.0009, 'grad_norm': 0.23726138472557068, 'learning_rate': 1.3907855598773653e-05, 'epoch': 6.82}\n",
      "{'loss': 0.0066, 'grad_norm': 0.02200392261147499, 'learning_rate': 1.3560079586941765e-05, 'epoch': 6.86}\n",
      "{'loss': 0.0015, 'grad_norm': 0.799780547618866, 'learning_rate': 1.3215081579350058e-05, 'epoch': 6.9}\n",
      "{'loss': 0.0002, 'grad_norm': 0.00044031577999703586, 'learning_rate': 1.2872945353323334e-05, 'epoch': 6.95}\n",
      "{'loss': 0.0009, 'grad_norm': 0.05170619115233421, 'learning_rate': 1.2533753991247843e-05, 'epoch': 6.99}\n",
      "{'loss': 0.0003, 'grad_norm': 0.009039001539349556, 'learning_rate': 1.2197589860396108e-05, 'epoch': 7.04}\n",
      "{'loss': 0.0011, 'grad_norm': 0.2877408564090729, 'learning_rate': 1.1864534592925253e-05, 'epoch': 7.08}\n",
      "{'loss': 0.0007, 'grad_norm': 0.016275309026241302, 'learning_rate': 1.1534669066054e-05, 'epoch': 7.13}\n",
      "{'loss': 0.0001, 'grad_norm': 0.01001753844320774, 'learning_rate': 1.1208073382422865e-05, 'epoch': 7.17}\n",
      "{'loss': 0.0001, 'grad_norm': 0.003172697266563773, 'learning_rate': 1.088482685064249e-05, 'epoch': 7.22}\n",
      "{'loss': 0.0, 'grad_norm': 0.003987442702054977, 'learning_rate': 1.0565007966034843e-05, 'epoch': 7.26}\n",
      "{'loss': 0.0001, 'grad_norm': 0.007276550401002169, 'learning_rate': 1.0248694391571801e-05, 'epoch': 7.31}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0027564263436943293, 'learning_rate': 9.935962939015982e-06, 'epoch': 7.35}\n",
      "{'loss': 0.0002, 'grad_norm': 0.001287932158447802, 'learning_rate': 9.626889550268202e-06, 'epoch': 7.39}\n",
      "{'loss': 0.0003, 'grad_norm': 0.0012687565758824348, 'learning_rate': 9.32154927892617e-06, 'epoch': 7.44}\n",
      "{'loss': 0.0006, 'grad_norm': 0.009288073517382145, 'learning_rate': 9.02001627205889e-06, 'epoch': 7.48}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0015303399413824081, 'learning_rate': 8.722363752201277e-06, 'epoch': 7.53}\n",
      "{'loss': 0.0001, 'grad_norm': 0.00022969843121245503, 'learning_rate': 8.428663999573142e-06, 'epoch': 7.57}\n",
      "{'loss': 0.0004, 'grad_norm': 0.09065567702054977, 'learning_rate': 8.138988334527143e-06, 'epoch': 7.62}\n",
      "{'loss': 0.0001, 'grad_norm': 0.01754247024655342, 'learning_rate': 7.853407100229731e-06, 'epoch': 7.66}\n",
      "{'loss': 0.0, 'grad_norm': 0.0019014562712982297, 'learning_rate': 7.571989645579419e-06, 'epoch': 7.71}\n",
      "{'loss': 0.0001, 'grad_norm': 0.01324135810136795, 'learning_rate': 7.294804308366524e-06, 'epoch': 7.75}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0004873730940744281, 'learning_rate': 7.0219183986783596e-06, 'epoch': 7.8}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0038098650984466076, 'learning_rate': 6.753398182554116e-06, 'epoch': 7.84}\n",
      "{'loss': 0.0, 'grad_norm': 0.0001721245498629287, 'learning_rate': 6.489308865893121e-06, 'epoch': 7.88}\n",
      "{'loss': 0.0001, 'grad_norm': 0.13798657059669495, 'learning_rate': 6.2297145786206795e-06, 'epoch': 7.93}\n",
      "{'loss': 0.0, 'grad_norm': 0.020777756348252296, 'learning_rate': 5.974678359115094e-06, 'epoch': 7.97}\n",
      "{'loss': 0.0007, 'grad_norm': 0.0010507373372092843, 'learning_rate': 5.724262138899813e-06, 'epoch': 8.02}\n",
      "{'loss': 0.0, 'grad_norm': 0.0038487473502755165, 'learning_rate': 5.478526727604296e-06, 'epoch': 8.06}\n",
      "{'loss': 0.0004, 'grad_norm': 0.005164610221982002, 'learning_rate': 5.237531798197415e-06, 'epoch': 8.11}\n",
      "{'loss': 0.0002, 'grad_norm': 0.000508401426486671, 'learning_rate': 5.00133587249676e-06, 'epoch': 8.15}\n",
      "{'loss': 0.0001, 'grad_norm': 0.009826608933508396, 'learning_rate': 4.769996306957569e-06, 'epoch': 8.2}\n",
      "{'loss': 0.0, 'grad_norm': 0.0009464302565902472, 'learning_rate': 4.543569278744625e-06, 'epoch': 8.24}\n",
      "{'loss': 0.0, 'grad_norm': 0.00299524306319654, 'learning_rate': 4.3221097720904716e-06, 'epoch': 8.29}\n",
      "{'loss': 0.0008, 'grad_norm': 0.23969992995262146, 'learning_rate': 4.1056715649434195e-06, 'epoch': 8.33}\n",
      "{'loss': 0.0, 'grad_norm': 0.003963582217693329, 'learning_rate': 3.894307215908371e-06, 'epoch': 8.37}\n",
      "{'loss': 0.0004, 'grad_norm': 0.016545305028557777, 'learning_rate': 3.6880680514838283e-06, 'epoch': 8.42}\n",
      "{'loss': 0.0, 'grad_norm': 0.0022696377709507942, 'learning_rate': 3.487004153598028e-06, 'epoch': 8.46}\n",
      "{'loss': 0.0, 'grad_norm': 0.008672963827848434, 'learning_rate': 3.2911643474473646e-06, 'epoch': 8.51}\n",
      "{'loss': 0.0, 'grad_norm': 0.003801973070949316, 'learning_rate': 3.1005961896399538e-06, 'epoch': 8.55}\n",
      "{'loss': 0.0, 'grad_norm': 0.002334685530513525, 'learning_rate': 2.915345956647239e-06, 'epoch': 8.6}\n",
      "{'loss': 0.0, 'grad_norm': 0.0050383517518639565, 'learning_rate': 2.7354586335665207e-06, 'epoch': 8.64}\n",
      "{'loss': 0.0, 'grad_norm': 0.00040527849341742694, 'learning_rate': 2.560977903196987e-06, 'epoch': 8.69}\n",
      "{'loss': 0.0, 'grad_norm': 0.0007619542884640396, 'learning_rate': 2.39194613543208e-06, 'epoch': 8.73}\n",
      "{'loss': 0.0, 'grad_norm': 0.001816176692955196, 'learning_rate': 2.2284043769706027e-06, 'epoch': 8.78}\n",
      "{'loss': 0.0, 'grad_norm': 0.008356686681509018, 'learning_rate': 2.070392341349203e-06, 'epoch': 8.82}\n",
      "{'loss': 0.0, 'grad_norm': 0.00018533915863372386, 'learning_rate': 1.9179483992985277e-06, 'epoch': 8.86}\n",
      "{'loss': 0.0013, 'grad_norm': 0.00678770849481225, 'learning_rate': 1.771109569425547e-06, 'epoch': 8.91}\n",
      "{'loss': 0.0, 'grad_norm': 0.000608544098213315, 'learning_rate': 1.6299115092241247e-06, 'epoch': 8.95}\n",
      "{'loss': 0.0, 'grad_norm': 0.0005050154286436737, 'learning_rate': 1.4943885064161889e-06, 'epoch': 9.0}\n",
      "{'loss': 0.0, 'grad_norm': 0.0003792507923208177, 'learning_rate': 1.364573470625477e-06, 'epoch': 9.04}\n",
      "{'loss': 0.0009, 'grad_norm': 0.007795087527483702, 'learning_rate': 1.2404979253859722e-06, 'epoch': 9.09}\n",
      "{'loss': 0.0, 'grad_norm': 0.0007220698753371835, 'learning_rate': 1.1221920004868991e-06, 'epoch': 9.13}\n",
      "{'loss': 0.0, 'grad_norm': 7.694922533119097e-05, 'learning_rate': 1.0096844246561794e-06, 'epoch': 9.18}\n",
      "{'loss': 0.0005, 'grad_norm': 0.0009087308426387608, 'learning_rate': 9.030025185841173e-07, 'epoch': 9.22}\n",
      "{'loss': 0.0, 'grad_norm': 0.000559960026293993, 'learning_rate': 8.021721882889993e-07, 'epoch': 9.27}\n",
      "{'loss': 0.0, 'grad_norm': 0.001847388339228928, 'learning_rate': 7.072179188262251e-07, 'epoch': 9.31}\n",
      "{'loss': 0.0, 'grad_norm': 0.002592855365946889, 'learning_rate': 6.181627683425061e-07, 'epoch': 9.35}\n",
      "{'loss': 0.0006, 'grad_norm': 0.00192054093349725, 'learning_rate': 5.350283624765417e-07, 'epoch': 9.4}\n",
      "{'loss': 0.0, 'grad_norm': 0.002391909947618842, 'learning_rate': 4.57834889107589e-07, 'epoch': 9.44}\n",
      "{'loss': 0.0, 'grad_norm': 0.0011490389006212354, 'learning_rate': 3.866010934531511e-07, 'epoch': 9.49}\n",
      "{'loss': 0.0, 'grad_norm': 0.002997088711708784, 'learning_rate': 3.2134427351699083e-07, 'epoch': 9.53}\n",
      "{'loss': 0.0, 'grad_norm': 0.00023272415273822844, 'learning_rate': 2.620802758885876e-07, 'epoch': 9.58}\n",
      "{'loss': 0.0, 'grad_norm': 0.001087315147742629, 'learning_rate': 2.0882349189504936e-07, 'epoch': 9.62}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0003611572028603405, 'learning_rate': 1.6158685410639086e-07, 'epoch': 9.67}\n",
      "{'loss': 0.0, 'grad_norm': 0.0002313357254024595, 'learning_rate': 1.2038183319507955e-07, 'epoch': 9.71}\n",
      "{'loss': 0.0, 'grad_norm': 0.00523372320458293, 'learning_rate': 8.521843515054694e-08, 'epoch': 9.76}\n",
      "{'loss': 0.0, 'grad_norm': 0.0011931407498195767, 'learning_rate': 5.61051988494099e-08, 'epoch': 9.8}\n",
      "{'loss': 0.0, 'grad_norm': 0.0032255547121167183, 'learning_rate': 3.304919398192663e-08, 'epoch': 9.84}\n",
      "{'loss': 0.0, 'grad_norm': 0.005690511781722307, 'learning_rate': 1.605601933523104e-08, 'epoch': 9.89}\n",
      "{'loss': 0.0003, 'grad_norm': 0.0001534840848762542, 'learning_rate': 5.129801433775838e-09, 'epoch': 9.93}\n",
      "{'loss': 0.0, 'grad_norm': 0.0029646987095475197, 'learning_rate': 2.7319353723964656e-10, 'epoch': 9.98}\n",
      "100%|█████████████████████████████████████| 2240/2240 [1:47:18<00:00,  2.81s/it][INFO|trainer.py:2329] 2024-06-14 16:13:42,583 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 6438.9525, 'train_samples_per_second': 2.789, 'train_steps_per_second': 0.348, 'train_loss': 0.02851595352203081, 'epoch': 9.98}\n",
      "100%|█████████████████████████████████████| 2240/2240 [1:47:18<00:00,  2.87s/it]\n",
      "[INFO|trainer.py:3410] 2024-06-14 16:13:42,599 >> Saving model checkpoint to /Utilisateurs/umushtaq/models/PE_LI_paragraph_wo_comptypes_llama-3-8b-Instruct-bnb-4bit\n",
      "[INFO|configuration_utils.py:733] 2024-06-14 16:13:42,970 >> loading configuration file config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/config.json\n",
      "[INFO|configuration_utils.py:796] 2024-06-14 16:13:42,971 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"_load_in_4bit\": true,\n",
      "    \"_load_in_8bit\": false,\n",
      "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "    \"bnb_4bit_quant_type\": \"nf4\",\n",
      "    \"bnb_4bit_use_double_quant\": true,\n",
      "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "    \"llm_int8_has_fp16_weight\": false,\n",
      "    \"llm_int8_skip_modules\": null,\n",
      "    \"llm_int8_threshold\": 6.0,\n",
      "    \"load_in_4bit\": true,\n",
      "    \"load_in_8bit\": false,\n",
      "    \"quant_method\": \"bitsandbytes\"\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2513] 2024-06-14 16:13:44,596 >> tokenizer config file saved in /Utilisateurs/umushtaq/models/PE_LI_paragraph_wo_comptypes_llama-3-8b-Instruct-bnb-4bit/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2522] 2024-06-14 16:13:44,605 >> Special tokens file saved in /Utilisateurs/umushtaq/models/PE_LI_paragraph_wo_comptypes_llama-3-8b-Instruct-bnb-4bit/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =      9.9777\n",
      "  total_flos               = 203661532GF\n",
      "  train_loss               =      0.0285\n",
      "  train_runtime            =  1:47:18.95\n",
      "  train_samples_per_second =       2.789\n",
      "  train_steps_per_second   =       0.348\n",
      "[INFO|modelcard.py:450] 2024-06-14 16:13:44,924 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 16:13:46,387 >> loading file tokenizer.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 16:13:46,388 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 16:13:46,390 >> loading file special_tokens_map.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 16:13:46,391 >> loading file tokenizer_config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/tokenizer_config.json\n",
      "[WARNING|logging.py:314] 2024-06-14 16:13:46,637 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/14/2024 16:13:46 - INFO - llamafactory.data.template - Replace eos token: <|eot_id|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Utilisateurs/umushtaq/.conda/envs/llama-factory-notebook/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "[INFO|configuration_utils.py:733] 2024-06-14 16:13:46,746 >> loading configuration file config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/config.json\n",
      "[INFO|configuration_utils.py:796] 2024-06-14 16:13:46,748 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"_load_in_4bit\": true,\n",
      "    \"_load_in_8bit\": false,\n",
      "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "    \"bnb_4bit_quant_type\": \"nf4\",\n",
      "    \"bnb_4bit_use_double_quant\": true,\n",
      "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "    \"llm_int8_has_fp16_weight\": false,\n",
      "    \"llm_int8_skip_modules\": null,\n",
      "    \"llm_int8_threshold\": 6.0,\n",
      "    \"load_in_4bit\": true,\n",
      "    \"load_in_8bit\": false,\n",
      "    \"quant_method\": \"bitsandbytes\"\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/14/2024 16:13:46 - INFO - llamafactory.model.utils.quantization - Loading ?-bit BITSANDBYTES-quantized model.\n",
      "06/14/2024 16:13:46 - INFO - llamafactory.model.patcher - Using KV cache for faster generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING|quantization_config.py:393] 2024-06-14 16:13:47,169 >> Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "[INFO|modeling_utils.py:3474] 2024-06-14 16:13:47,177 >> loading weights file model.safetensors from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/model.safetensors\n",
      "[INFO|modeling_utils.py:1519] 2024-06-14 16:13:47,209 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:962] 2024-06-14 16:13:47,214 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:4280] 2024-06-14 16:13:49,162 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4288] 2024-06-14 16:13:49,164 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at unsloth/llama-3-8b-Instruct-bnb-4bit.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:917] 2024-06-14 16:13:49,272 >> loading configuration file generation_config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct-bnb-4bit/snapshots/2950abc9d0b34ddd43fd52bbf0d7dca82807ce96/generation_config.json\n",
      "[INFO|configuration_utils.py:962] 2024-06-14 16:13:49,274 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128009\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/14/2024 16:13:49 - INFO - llamafactory.model.utils.attention - Using torch SDPA for faster training and inference.\n",
      "06/14/2024 16:13:49 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n",
      "06/14/2024 16:13:49 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n",
      "06/14/2024 16:13:49 - INFO - llamafactory.model.adapter - Loaded adapter(s): /Utilisateurs/umushtaq/models/PE_LI_paragraph_wo_comptypes_llama-3-8b-Instruct-bnb-4bit\n",
      "06/14/2024 16:13:49 - INFO - llamafactory.model.loader - all params: 8051232768\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7935e11af9a42f7b1db82d22ff5fd82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/439 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Utilisateurs/umushtaq\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       N-Rel      0.942     0.941     0.942      3384\n",
      "         Rel      0.726     0.731     0.728       724\n",
      "\n",
      "    accuracy                          0.904      4108\n",
      "   macro avg      0.834     0.836     0.835      4108\n",
      "weighted avg      0.904     0.904     0.904      4108\n",
      "\n",
      "/Utilisateurs/umushtaq\n",
      "\n",
      "Running experiment: ['unsloth/llama-3-8b-Instruct', 'PE_LI_paragraph_wo_comptypes_train.json', 'PE_LI_paragraph_wo_comptypes_test.json']\n",
      "/Utilisateurs/umushtaq/LLaMA-Factory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Utilisateurs/umushtaq/.conda/envs/llama-factory-notebook/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/14/2024 16:26:35 - WARNING - llamafactory.hparams.parser - We recommend enable `upcast_layernorm` in quantized training.\n",
      "06/14/2024 16:26:35 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: torch.float16\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 16:26:35,878 >> loading file tokenizer.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 16:26:35,878 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 16:26:35,878 >> loading file special_tokens_map.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 16:26:35,878 >> loading file tokenizer_config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/tokenizer_config.json\n",
      "[WARNING|logging.py:314] 2024-06-14 16:26:36,133 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "06/14/2024 16:26:36 - INFO - llamafactory.data.template - Replace eos token: <|eot_id|>\n",
      "06/14/2024 16:26:36 - INFO - llamafactory.data.loader - Loading dataset /Utilisateurs/umushtaq/datasets/PE_LI_paragraph_wo_comptypes_train.json...\n",
      "Running tokenizer on dataset: 100%|█| 1796/1796 [00:00<00:00, 1898.06 examples/s\n",
      "input_ids:\n",
      "[128000, 128006, 9125, 128007, 271, 2675, 527, 264, 11190, 18328, 13, 128009, 128006, 882, 128007, 271, 14711, 1472, 527, 459, 6335, 304, 14138, 26917, 13, 1472, 527, 2728, 264, 14646, 902, 5727, 5811, 6956, 44910, 555, 366, 1741, 1500, 1741, 29, 9681, 13, 4718, 3465, 374, 311, 10765, 5811, 4398, 1990, 5811, 6956, 304, 279, 14646, 13, 1472, 2011, 471, 264, 1160, 315, 5811, 3777, 13840, 304, 2768, 4823, 3645, 25, 5324, 1638, 9202, 95321, 794, 4416, 5775, 10807, 320, 396, 705, 2592, 10807, 320, 396, 26090, 61453, 510, 5775, 10807, 320, 396, 705, 2592, 10807, 320, 396, 8, 5163, 633, 14711, 5810, 374, 279, 14646, 1495, 25, 366, 16816, 29, 12540, 4236, 387, 15972, 311, 20874, 477, 311, 47903, 949, 694, 16816, 29, 128009, 128006, 78191, 128007, 271, 5018, 1638, 9202, 95321, 794, 3132, 92, 128009]\n",
      "inputs:\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "### You are an expert in Argument Mining. You are given a paragraph which contains argument components enclosed by <AC></AC> tags. Your task is to identify argument relations between argument components in the paragraph. You must return a list of argument component pairs in following JSON format: {\"list_argument_relations\": [[target AC (int), source AC (int)],..., [target AC (int), source AC (int)]]}\n",
      "\n",
      "### Here is the paragraph text: <topic> Should students be taught to compete or to cooperate? </topic><|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\"list_argument_relations\": []}<|eot_id|>\n",
      "label_ids:\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 5018, 1638, 9202, 95321, 794, 3132, 92, 128009]\n",
      "labels:\n",
      "{\"list_argument_relations\": []}<|eot_id|>\n",
      "/Utilisateurs/umushtaq/.conda/envs/llama-factory-notebook/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "[INFO|configuration_utils.py:733] 2024-06-14 16:26:37,872 >> loading configuration file config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/config.json\n",
      "[INFO|configuration_utils.py:796] 2024-06-14 16:26:37,873 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"unsloth/llama-3-8b-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "06/14/2024 16:26:37 - INFO - llamafactory.model.utils.quantization - Quantizing model to 4 bit.\n",
      "[INFO|modeling_utils.py:3474] 2024-06-14 16:26:37,950 >> loading weights file model.safetensors from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1519] 2024-06-14 16:26:37,955 >> Instantiating LlamaForCausalLM model under default dtype torch.float16.\n",
      "[INFO|configuration_utils.py:962] 2024-06-14 16:26:37,956 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009\n",
      "}\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:09<00:00,  2.43s/it]\n",
      "[INFO|modeling_utils.py:4280] 2024-06-14 16:26:48,174 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4288] 2024-06-14 16:26:48,175 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at unsloth/llama-3-8b-Instruct.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:917] 2024-06-14 16:26:48,341 >> loading configuration file generation_config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/generation_config.json\n",
      "[INFO|configuration_utils.py:962] 2024-06-14 16:26:48,341 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128009\n",
      "  ]\n",
      "}\n",
      "\n",
      "06/14/2024 16:26:48 - INFO - llamafactory.model.utils.checkpointing - Gradient checkpointing enabled.\n",
      "06/14/2024 16:26:48 - INFO - llamafactory.model.utils.attention - Using torch SDPA for faster training and inference.\n",
      "06/14/2024 16:26:48 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n",
      "06/14/2024 16:26:48 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n",
      "06/14/2024 16:26:48 - INFO - llamafactory.model.utils.misc - Found linear modules: o_proj,gate_proj,k_proj,down_proj,v_proj,q_proj,up_proj\n",
      "06/14/2024 16:26:48 - INFO - llamafactory.model.loader - trainable params: 20971520 || all params: 8051232768 || trainable%: 0.2605\n",
      "[INFO|trainer.py:641] 2024-06-14 16:26:48,813 >> Using auto half precision backend\n",
      "06/14/2024 16:26:49 - INFO - llamafactory.train.utils - Using LoRA+ optimizer with loraplus lr ratio 16.00.\n",
      "[INFO|trainer.py:2078] 2024-06-14 16:26:49,038 >> ***** Running training *****\n",
      "[INFO|trainer.py:2079] 2024-06-14 16:26:49,038 >>   Num examples = 1,796\n",
      "[INFO|trainer.py:2080] 2024-06-14 16:26:49,038 >>   Num Epochs = 10\n",
      "[INFO|trainer.py:2081] 2024-06-14 16:26:49,038 >>   Instantaneous batch size per device = 2\n",
      "[INFO|trainer.py:2084] 2024-06-14 16:26:49,038 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "[INFO|trainer.py:2085] 2024-06-14 16:26:49,038 >>   Gradient Accumulation steps = 4\n",
      "[INFO|trainer.py:2086] 2024-06-14 16:26:49,038 >>   Total optimization steps = 2,240\n",
      "[INFO|trainer.py:2087] 2024-06-14 16:26:49,042 >>   Number of trainable parameters = 20,971,520\n",
      "{'loss': 1.0847, 'grad_norm': 7.30536413192749, 'learning_rate': 1.7857142857142857e-06, 'epoch': 0.04}\n",
      "{'loss': 0.2357, 'grad_norm': 1.164759635925293, 'learning_rate': 4.017857142857143e-06, 'epoch': 0.09}\n",
      "{'loss': 0.156, 'grad_norm': 0.7428515553474426, 'learning_rate': 6.25e-06, 'epoch': 0.13}\n",
      "{'loss': 0.0994, 'grad_norm': 0.5814028382301331, 'learning_rate': 8.482142857142858e-06, 'epoch': 0.18}\n",
      "{'loss': 0.1206, 'grad_norm': 1.02629554271698, 'learning_rate': 1.0714285714285714e-05, 'epoch': 0.22}\n",
      "{'loss': 0.0863, 'grad_norm': 0.7799770832061768, 'learning_rate': 1.2946428571428574e-05, 'epoch': 0.27}\n",
      "{'loss': 0.0784, 'grad_norm': 0.41476932168006897, 'learning_rate': 1.5178571428571429e-05, 'epoch': 0.31}\n",
      "{'loss': 0.075, 'grad_norm': 0.49789959192276, 'learning_rate': 1.7410714285714287e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0685, 'grad_norm': 0.295152485370636, 'learning_rate': 1.9642857142857145e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0711, 'grad_norm': 1.0201655626296997, 'learning_rate': 2.1875e-05, 'epoch': 0.45}\n",
      "{'loss': 0.0878, 'grad_norm': 0.2834166884422302, 'learning_rate': 2.4107142857142858e-05, 'epoch': 0.49}\n",
      "{'loss': 0.0931, 'grad_norm': 0.3749699890613556, 'learning_rate': 2.6339285714285716e-05, 'epoch': 0.53}\n",
      "{'loss': 0.0695, 'grad_norm': 1.3282419443130493, 'learning_rate': 2.857142857142857e-05, 'epoch': 0.58}\n",
      "{'loss': 0.0709, 'grad_norm': 0.21090099215507507, 'learning_rate': 3.080357142857143e-05, 'epoch': 0.62}\n",
      "{'loss': 0.0659, 'grad_norm': 0.9885131120681763, 'learning_rate': 3.303571428571429e-05, 'epoch': 0.67}\n",
      "{'loss': 0.092, 'grad_norm': 0.3318861424922943, 'learning_rate': 3.5267857142857145e-05, 'epoch': 0.71}\n",
      "{'loss': 0.0932, 'grad_norm': 0.7709627151489258, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.76}\n",
      "{'loss': 0.1085, 'grad_norm': 0.5725685358047485, 'learning_rate': 3.9732142857142855e-05, 'epoch': 0.8}\n",
      "{'loss': 0.0746, 'grad_norm': 1.150352120399475, 'learning_rate': 4.196428571428572e-05, 'epoch': 0.85}\n",
      "{'loss': 0.0635, 'grad_norm': 0.974276602268219, 'learning_rate': 4.419642857142857e-05, 'epoch': 0.89}\n",
      "{'loss': 0.0777, 'grad_norm': 1.2608013153076172, 'learning_rate': 4.642857142857143e-05, 'epoch': 0.94}\n",
      "{'loss': 0.084, 'grad_norm': 0.5220907330513, 'learning_rate': 4.866071428571429e-05, 'epoch': 0.98}\n",
      "{'loss': 0.072, 'grad_norm': 0.7643123865127563, 'learning_rate': 4.9999514323288454e-05, 'epoch': 1.02}\n",
      "{'loss': 0.0568, 'grad_norm': 0.29785221815109253, 'learning_rate': 4.999405067699773e-05, 'epoch': 1.07}\n",
      "{'loss': 0.0452, 'grad_norm': 0.2031375914812088, 'learning_rate': 4.998251761970997e-05, 'epoch': 1.11}\n",
      "{'loss': 0.0443, 'grad_norm': 0.6265203356742859, 'learning_rate': 4.996491795204623e-05, 'epoch': 1.16}\n",
      "{'loss': 0.0638, 'grad_norm': 1.068518042564392, 'learning_rate': 4.9941255947808224e-05, 'epoch': 1.2}\n",
      "{'loss': 0.0637, 'grad_norm': 0.21726225316524506, 'learning_rate': 4.991153735294049e-05, 'epoch': 1.25}\n",
      "{'loss': 0.0407, 'grad_norm': 0.31472206115722656, 'learning_rate': 4.987576938413504e-05, 'epoch': 1.29}\n",
      "{'loss': 0.0469, 'grad_norm': 0.5359375476837158, 'learning_rate': 4.9833960727078975e-05, 'epoch': 1.34}\n",
      "{'loss': 0.0638, 'grad_norm': 0.339347779750824, 'learning_rate': 4.9786121534345265e-05, 'epoch': 1.38}\n",
      "{'loss': 0.0566, 'grad_norm': 0.3874751627445221, 'learning_rate': 4.9732263422927315e-05, 'epoch': 1.43}\n",
      "{'loss': 0.0568, 'grad_norm': 0.3166593015193939, 'learning_rate': 4.967239947141803e-05, 'epoch': 1.47}\n",
      "{'loss': 0.0727, 'grad_norm': 0.9465693831443787, 'learning_rate': 4.960654421683386e-05, 'epoch': 1.51}\n",
      "{'loss': 0.0693, 'grad_norm': 0.6147971153259277, 'learning_rate': 4.9534713651084696e-05, 'epoch': 1.56}\n",
      "{'loss': 0.0878, 'grad_norm': 0.9882805943489075, 'learning_rate': 4.94569252170905e-05, 'epoch': 1.6}\n",
      "{'loss': 0.0734, 'grad_norm': 0.5270976424217224, 'learning_rate': 4.937319780454559e-05, 'epoch': 1.65}\n",
      "{'loss': 0.0658, 'grad_norm': 0.18681783974170685, 'learning_rate': 4.9283551745331534e-05, 'epoch': 1.69}\n",
      "{'loss': 0.0723, 'grad_norm': 0.49065282940864563, 'learning_rate': 4.9188008808579914e-05, 'epoch': 1.74}\n",
      "{'loss': 0.0637, 'grad_norm': 0.952411413192749, 'learning_rate': 4.9086592195385974e-05, 'epoch': 1.78}\n",
      "{'loss': 0.0519, 'grad_norm': 0.5235846638679504, 'learning_rate': 4.89793265331747e-05, 'epoch': 1.83}\n",
      "{'loss': 0.061, 'grad_norm': 0.9536451101303101, 'learning_rate': 4.886623786972033e-05, 'epoch': 1.87}\n",
      "{'loss': 0.0493, 'grad_norm': 0.36341196298599243, 'learning_rate': 4.874735366682115e-05, 'epoch': 1.92}\n",
      "{'loss': 0.0472, 'grad_norm': 0.8364275097846985, 'learning_rate': 4.8622702793630756e-05, 'epoch': 1.96}\n",
      "{'loss': 0.0761, 'grad_norm': 0.8878505825996399, 'learning_rate': 4.849231551964771e-05, 'epoch': 2.0}\n",
      "{'loss': 0.0313, 'grad_norm': 0.4304981231689453, 'learning_rate': 4.8356223507364996e-05, 'epoch': 2.05}\n",
      "{'loss': 0.0401, 'grad_norm': 0.5191323161125183, 'learning_rate': 4.821445980458134e-05, 'epoch': 2.09}\n",
      "{'loss': 0.0379, 'grad_norm': 0.41499823331832886, 'learning_rate': 4.8067058836376044e-05, 'epoch': 2.14}\n",
      "{'loss': 0.0391, 'grad_norm': 0.6785207986831665, 'learning_rate': 4.791405639674941e-05, 'epoch': 2.18}\n",
      "{'loss': 0.0311, 'grad_norm': 0.6801945567131042, 'learning_rate': 4.775548963993072e-05, 'epoch': 2.23}\n",
      "{'loss': 0.0382, 'grad_norm': 1.0357006788253784, 'learning_rate': 4.759139707135592e-05, 'epoch': 2.27}\n",
      "{'loss': 0.0255, 'grad_norm': 0.7667295932769775, 'learning_rate': 4.742181853831721e-05, 'epoch': 2.32}\n",
      "{'loss': 0.0277, 'grad_norm': 0.4165341258049011, 'learning_rate': 4.724679522028672e-05, 'epoch': 2.36}\n",
      "{'loss': 0.0535, 'grad_norm': 1.6316946744918823, 'learning_rate': 4.706636961891673e-05, 'epoch': 2.41}\n",
      "{'loss': 0.0386, 'grad_norm': 0.21849334239959717, 'learning_rate': 4.6880585547718845e-05, 'epoch': 2.45}\n",
      "{'loss': 0.0431, 'grad_norm': 0.3708895742893219, 'learning_rate': 4.668948812142453e-05, 'epoch': 2.49}\n",
      "{'loss': 0.0486, 'grad_norm': 2.774331569671631, 'learning_rate': 4.649312374502976e-05, 'epoch': 2.54}\n",
      "{'loss': 0.0238, 'grad_norm': 0.6463547945022583, 'learning_rate': 4.6291540102526235e-05, 'epoch': 2.58}\n",
      "{'loss': 0.0459, 'grad_norm': 0.3866129517555237, 'learning_rate': 4.608478614532215e-05, 'epoch': 2.63}\n",
      "{'loss': 0.0559, 'grad_norm': 0.6896400451660156, 'learning_rate': 4.587291208035503e-05, 'epoch': 2.67}\n",
      "{'loss': 0.045, 'grad_norm': 0.2769867181777954, 'learning_rate': 4.5655969357899874e-05, 'epoch': 2.72}\n",
      "{'loss': 0.0411, 'grad_norm': 0.6261977553367615, 'learning_rate': 4.543401065907516e-05, 'epoch': 2.76}\n",
      "{'loss': 0.0402, 'grad_norm': 0.37766170501708984, 'learning_rate': 4.5207089883050136e-05, 'epoch': 2.81}\n",
      "{'loss': 0.0331, 'grad_norm': 0.8637810945510864, 'learning_rate': 4.497526213395623e-05, 'epoch': 2.85}\n",
      "{'loss': 0.0304, 'grad_norm': 0.5870565176010132, 'learning_rate': 4.4738583707505885e-05, 'epoch': 2.9}\n",
      "{'loss': 0.0396, 'grad_norm': 0.35455140471458435, 'learning_rate': 4.4497112077322044e-05, 'epoch': 2.94}\n",
      "{'loss': 0.0337, 'grad_norm': 1.1690396070480347, 'learning_rate': 4.4250905880981574e-05, 'epoch': 2.98}\n",
      "{'loss': 0.0419, 'grad_norm': 0.4013325572013855, 'learning_rate': 4.400002490577604e-05, 'epoch': 3.03}\n",
      "{'loss': 0.0104, 'grad_norm': 0.3267877399921417, 'learning_rate': 4.374453007419336e-05, 'epoch': 3.07}\n",
      "{'loss': 0.0211, 'grad_norm': 0.3405627906322479, 'learning_rate': 4.3484483429123656e-05, 'epoch': 3.12}\n",
      "{'loss': 0.0134, 'grad_norm': 0.24067391455173492, 'learning_rate': 4.3219948118793214e-05, 'epoch': 3.16}\n",
      "{'loss': 0.037, 'grad_norm': 0.7563381195068359, 'learning_rate': 4.295098838142985e-05, 'epoch': 3.21}\n",
      "{'loss': 0.0258, 'grad_norm': 0.07153009623289108, 'learning_rate': 4.267766952966369e-05, 'epoch': 3.25}\n",
      "{'loss': 0.0213, 'grad_norm': 0.751056969165802, 'learning_rate': 4.240005793466709e-05, 'epoch': 3.3}\n",
      "{'loss': 0.0131, 'grad_norm': 0.7414270639419556, 'learning_rate': 4.211822101003734e-05, 'epoch': 3.34}\n",
      "{'loss': 0.028, 'grad_norm': 0.21180319786071777, 'learning_rate': 4.183222719542643e-05, 'epoch': 3.39}\n",
      "{'loss': 0.0327, 'grad_norm': 1.0997395515441895, 'learning_rate': 4.154214593992149e-05, 'epoch': 3.43}\n",
      "{'loss': 0.0147, 'grad_norm': 2.0851967334747314, 'learning_rate': 4.1248047685180215e-05, 'epoch': 3.47}\n",
      "{'loss': 0.0242, 'grad_norm': 0.6006365418434143, 'learning_rate': 4.095000384832522e-05, 'epoch': 3.52}\n",
      "{'loss': 0.0307, 'grad_norm': 3.2707338333129883, 'learning_rate': 4.064808680460148e-05, 'epoch': 3.56}\n",
      "{'loss': 0.019, 'grad_norm': 0.3772895038127899, 'learning_rate': 4.034236986980119e-05, 'epoch': 3.61}\n",
      "{'loss': 0.0253, 'grad_norm': 0.6717656850814819, 'learning_rate': 4.0032927282460146e-05, 'epoch': 3.65}\n",
      "{'loss': 0.0265, 'grad_norm': 0.26235952973365784, 'learning_rate': 3.9719834185830116e-05, 'epoch': 3.7}\n",
      "{'loss': 0.0268, 'grad_norm': 0.8336212635040283, 'learning_rate': 3.940316660963147e-05, 'epoch': 3.74}\n",
      "{'loss': 0.0293, 'grad_norm': 1.0381118059158325, 'learning_rate': 3.908300145159055e-05, 'epoch': 3.79}\n",
      "{'loss': 0.0175, 'grad_norm': 0.41549575328826904, 'learning_rate': 3.875941645876631e-05, 'epoch': 3.83}\n",
      "{'loss': 0.0287, 'grad_norm': 1.0142136812210083, 'learning_rate': 3.84324902086706e-05, 'epoch': 3.88}\n",
      "{'loss': 0.0234, 'grad_norm': 0.18805822730064392, 'learning_rate': 3.810230209018694e-05, 'epoch': 3.92}\n",
      "{'loss': 0.0284, 'grad_norm': 0.37495294213294983, 'learning_rate': 3.7768932284292146e-05, 'epoch': 3.96}\n",
      "{'loss': 0.0255, 'grad_norm': 0.5511509776115417, 'learning_rate': 3.74324617445856e-05, 'epoch': 4.01}\n",
      "{'loss': 0.0075, 'grad_norm': 0.29771995544433594, 'learning_rate': 3.7092972177631e-05, 'epoch': 4.05}\n",
      "{'loss': 0.0124, 'grad_norm': 0.03347165137529373, 'learning_rate': 3.6750546023115216e-05, 'epoch': 4.1}\n",
      "{'loss': 0.0145, 'grad_norm': 1.8828433752059937, 'learning_rate': 3.6405266433829075e-05, 'epoch': 4.14}\n",
      "{'loss': 0.0101, 'grad_norm': 0.49912554025650024, 'learning_rate': 3.6057217255475034e-05, 'epoch': 4.19}\n",
      "{'loss': 0.0169, 'grad_norm': 0.27184879779815674, 'learning_rate': 3.570648300630657e-05, 'epoch': 4.23}\n",
      "{'loss': 0.0163, 'grad_norm': 0.07097017765045166, 'learning_rate': 3.535314885660426e-05, 'epoch': 4.28}\n",
      "{'loss': 0.0103, 'grad_norm': 0.36605513095855713, 'learning_rate': 3.499730060799352e-05, 'epoch': 4.32}\n",
      "{'loss': 0.0143, 'grad_norm': 0.7607961893081665, 'learning_rate': 3.463902467260905e-05, 'epoch': 4.37}\n",
      "{'loss': 0.0133, 'grad_norm': 0.7880668640136719, 'learning_rate': 3.4278408052110946e-05, 'epoch': 4.41}\n",
      "{'loss': 0.0029, 'grad_norm': 0.1526562124490738, 'learning_rate': 3.391553831655782e-05, 'epoch': 4.45}\n",
      "{'loss': 0.0145, 'grad_norm': 0.7999840974807739, 'learning_rate': 3.355050358314172e-05, 'epoch': 4.5}\n",
      "{'loss': 0.0206, 'grad_norm': 0.6834039688110352, 'learning_rate': 3.318339249479026e-05, 'epoch': 4.54}\n",
      "{'loss': 0.0059, 'grad_norm': 0.5039457082748413, 'learning_rate': 3.281429419864112e-05, 'epoch': 4.59}\n",
      "{'loss': 0.0046, 'grad_norm': 0.1502181887626648, 'learning_rate': 3.244329832439404e-05, 'epoch': 4.63}\n",
      "{'loss': 0.015, 'grad_norm': 1.035050630569458, 'learning_rate': 3.207049496254569e-05, 'epoch': 4.68}\n",
      "{'loss': 0.0125, 'grad_norm': 0.3927563428878784, 'learning_rate': 3.1695974642512585e-05, 'epoch': 4.72}\n",
      "{'loss': 0.0185, 'grad_norm': 0.05791778489947319, 'learning_rate': 3.131982831064744e-05, 'epoch': 4.77}\n",
      "{'loss': 0.0117, 'grad_norm': 0.6063570976257324, 'learning_rate': 3.094214730815433e-05, 'epoch': 4.81}\n",
      "{'loss': 0.015, 'grad_norm': 0.920928418636322, 'learning_rate': 3.056302334890786e-05, 'epoch': 4.86}\n",
      "{'loss': 0.0114, 'grad_norm': 0.6970657110214233, 'learning_rate': 3.0182548497181946e-05, 'epoch': 4.9}\n",
      "{'loss': 0.007, 'grad_norm': 0.11788345873355865, 'learning_rate': 2.980081514529341e-05, 'epoch': 4.94}\n",
      "{'loss': 0.0052, 'grad_norm': 0.79317307472229, 'learning_rate': 2.9417915991166008e-05, 'epoch': 4.99}\n",
      "{'loss': 0.0057, 'grad_norm': 0.010312121361494064, 'learning_rate': 2.903394401582017e-05, 'epoch': 5.03}\n",
      "{'loss': 0.0093, 'grad_norm': 0.13985411822795868, 'learning_rate': 2.8648992460794056e-05, 'epoch': 5.08}\n",
      "{'loss': 0.0087, 'grad_norm': 0.031227244064211845, 'learning_rate': 2.8263154805501297e-05, 'epoch': 5.12}\n",
      "{'loss': 0.0046, 'grad_norm': 0.02156311646103859, 'learning_rate': 2.787652474453097e-05, 'epoch': 5.17}\n",
      "{'loss': 0.0031, 'grad_norm': 0.12180068343877792, 'learning_rate': 2.748919616489542e-05, 'epoch': 5.21}\n",
      "{'loss': 0.0034, 'grad_norm': 0.004890180192887783, 'learning_rate': 2.710126312323119e-05, 'epoch': 5.26}\n",
      "{'loss': 0.01, 'grad_norm': 0.16034488379955292, 'learning_rate': 2.6712819822958917e-05, 'epoch': 5.3}\n",
      "{'loss': 0.0105, 'grad_norm': 0.011512688361108303, 'learning_rate': 2.632396059140749e-05, 'epoch': 5.35}\n",
      "{'loss': 0.0038, 'grad_norm': 0.013063959777355194, 'learning_rate': 2.593477985690815e-05, 'epoch': 5.39}\n",
      "{'loss': 0.0026, 'grad_norm': 0.01509141456335783, 'learning_rate': 2.5545372125864032e-05, 'epoch': 5.43}\n",
      "{'loss': 0.0035, 'grad_norm': 0.4205155074596405, 'learning_rate': 2.515583195980084e-05, 'epoch': 5.48}\n",
      "{'loss': 0.0053, 'grad_norm': 0.005296383984386921, 'learning_rate': 2.4766253952404024e-05, 'epoch': 5.52}\n",
      "{'loss': 0.0074, 'grad_norm': 0.012969676405191422, 'learning_rate': 2.4376732706548183e-05, 'epoch': 5.57}\n",
      "{'loss': 0.0056, 'grad_norm': 0.4588286876678467, 'learning_rate': 2.3987362811324298e-05, 'epoch': 5.61}\n",
      "{'loss': 0.005, 'grad_norm': 0.1724511682987213, 'learning_rate': 2.3598238819070202e-05, 'epoch': 5.66}\n",
      "{'loss': 0.0033, 'grad_norm': 0.4076901972293854, 'learning_rate': 2.3209455222410122e-05, 'epoch': 5.7}\n",
      "{'loss': 0.005, 'grad_norm': 0.3191545903682709, 'learning_rate': 2.2821106431308544e-05, 'epoch': 5.75}\n",
      "{'loss': 0.0027, 'grad_norm': 0.007131561171263456, 'learning_rate': 2.2433286750144293e-05, 'epoch': 5.79}\n",
      "{'loss': 0.0072, 'grad_norm': 0.8492775559425354, 'learning_rate': 2.204609035481018e-05, 'epoch': 5.84}\n",
      "{'loss': 0.0134, 'grad_norm': 0.6396737098693848, 'learning_rate': 2.1659611269843906e-05, 'epoch': 5.88}\n",
      "{'loss': 0.005, 'grad_norm': 0.0790947899222374, 'learning_rate': 2.1273943345595637e-05, 'epoch': 5.92}\n",
      "{'loss': 0.0071, 'grad_norm': 0.17324413359165192, 'learning_rate': 2.0889180235437976e-05, 'epoch': 5.97}\n",
      "{'loss': 0.0048, 'grad_norm': 0.03363202512264252, 'learning_rate': 2.0505415373023684e-05, 'epoch': 6.01}\n",
      "{'loss': 0.0022, 'grad_norm': 0.00912680383771658, 'learning_rate': 2.0122741949596797e-05, 'epoch': 6.06}\n",
      "{'loss': 0.0005, 'grad_norm': 0.07775072753429413, 'learning_rate': 1.9741252891362612e-05, 'epoch': 6.1}\n",
      "{'loss': 0.0006, 'grad_norm': 0.0021250408608466387, 'learning_rate': 1.936104083692202e-05, 'epoch': 6.15}\n",
      "{'loss': 0.0026, 'grad_norm': 0.0014403937384486198, 'learning_rate': 1.8982198114775682e-05, 'epoch': 6.19}\n",
      "{'loss': 0.0037, 'grad_norm': 0.01178684551268816, 'learning_rate': 1.86048167209035e-05, 'epoch': 6.24}\n",
      "{'loss': 0.0021, 'grad_norm': 0.024928275495767593, 'learning_rate': 1.8228988296424877e-05, 'epoch': 6.28}\n",
      "{'loss': 0.0039, 'grad_norm': 0.002593872370198369, 'learning_rate': 1.7854804105345062e-05, 'epoch': 6.33}\n",
      "{'loss': 0.0025, 'grad_norm': 0.38215798139572144, 'learning_rate': 1.7482355012393177e-05, 'epoch': 6.37}\n",
      "{'loss': 0.0023, 'grad_norm': 0.003122315974906087, 'learning_rate': 1.711173146095712e-05, 'epoch': 6.41}\n",
      "{'loss': 0.0003, 'grad_norm': 0.3024515211582184, 'learning_rate': 1.6743023451120832e-05, 'epoch': 6.46}\n",
      "{'loss': 0.0005, 'grad_norm': 0.014778394252061844, 'learning_rate': 1.637632051780917e-05, 'epoch': 6.5}\n",
      "{'loss': 0.0008, 'grad_norm': 0.017310738563537598, 'learning_rate': 1.6011711709045813e-05, 'epoch': 6.55}\n",
      "{'loss': 0.0008, 'grad_norm': 0.004740745760500431, 'learning_rate': 1.5649285564329296e-05, 'epoch': 6.59}\n",
      "{'loss': 0.0011, 'grad_norm': 0.01558556780219078, 'learning_rate': 1.5289130093132632e-05, 'epoch': 6.64}\n",
      "{'loss': 0.0002, 'grad_norm': 0.015628058463335037, 'learning_rate': 1.4931332753531574e-05, 'epoch': 6.68}\n",
      "{'loss': 0.0002, 'grad_norm': 0.008974126540124416, 'learning_rate': 1.4575980430966807e-05, 'epoch': 6.73}\n",
      "{'loss': 0.0049, 'grad_norm': 0.0318576879799366, 'learning_rate': 1.4223159417145179e-05, 'epoch': 6.77}\n",
      "{'loss': 0.001, 'grad_norm': 0.008222739212214947, 'learning_rate': 1.387295538908519e-05, 'epoch': 6.82}\n",
      "{'loss': 0.0005, 'grad_norm': 0.017223376780748367, 'learning_rate': 1.3525453388311554e-05, 'epoch': 6.86}\n",
      "{'loss': 0.0006, 'grad_norm': 0.0030149577651172876, 'learning_rate': 1.318073780020433e-05, 'epoch': 6.9}\n",
      "{'loss': 0.0003, 'grad_norm': 0.001587813487276435, 'learning_rate': 1.2838892333507154e-05, 'epoch': 6.95}\n",
      "{'loss': 0.0005, 'grad_norm': 0.023725952953100204, 'learning_rate': 1.2500000000000006e-05, 'epoch': 6.99}\n",
      "{'loss': 0.0001, 'grad_norm': 0.04459008201956749, 'learning_rate': 1.2164143094340993e-05, 'epoch': 7.04}\n",
      "{'loss': 0.001, 'grad_norm': 0.15148276090621948, 'learning_rate': 1.183140317408248e-05, 'epoch': 7.08}\n",
      "{'loss': 0.0005, 'grad_norm': 0.0045666941441595554, 'learning_rate': 1.1501861039866094e-05, 'epoch': 7.13}\n",
      "{'loss': 0.0003, 'grad_norm': 0.002957697492092848, 'learning_rate': 1.1175596715801515e-05, 'epoch': 7.17}\n",
      "{'loss': 0.0002, 'grad_norm': 0.002490269485861063, 'learning_rate': 1.0852689430033972e-05, 'epoch': 7.22}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0023933688644319773, 'learning_rate': 1.0533217595504858e-05, 'epoch': 7.26}\n",
      "{'loss': 0.0007, 'grad_norm': 0.043878600001335144, 'learning_rate': 1.0217258790910448e-05, 'epoch': 7.31}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0009358178940601647, 'learning_rate': 9.90488974186306e-06, 'epoch': 7.35}\n",
      "{'loss': 0.0, 'grad_norm': 0.003647082019597292, 'learning_rate': 9.596186302259563e-06, 'epoch': 7.39}\n",
      "{'loss': 0.0001, 'grad_norm': 0.005001050420105457, 'learning_rate': 9.291223435861318e-06, 'epoch': 7.44}\n",
      "{'loss': 0.0023, 'grad_norm': 0.022696929052472115, 'learning_rate': 8.99007519809053e-06, 'epoch': 7.48}\n",
      "{'loss': 0.0, 'grad_norm': 0.002334014978259802, 'learning_rate': 8.69281471804698e-06, 'epoch': 7.53}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0001630061597097665, 'learning_rate': 8.399514180749795e-06, 'epoch': 7.57}\n",
      "{'loss': 0.0003, 'grad_norm': 0.05663759261369705, 'learning_rate': 8.110244809608495e-06, 'epoch': 7.62}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0035771147813647985, 'learning_rate': 7.825076849127458e-06, 'epoch': 7.66}\n",
      "{'loss': 0.0, 'grad_norm': 0.0031240733806043863, 'learning_rate': 7.5440795478481815e-06, 'epoch': 7.71}\n",
      "{'loss': 0.0002, 'grad_norm': 0.07648365944623947, 'learning_rate': 7.26732114153334e-06, 'epoch': 7.75}\n",
      "{'loss': 0.0001, 'grad_norm': 0.030668945983052254, 'learning_rate': 6.99486883659684e-06, 'epoch': 7.8}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0027367370203137398, 'learning_rate': 6.72678879378377e-06, 'epoch': 7.84}\n",
      "{'loss': 0.0001, 'grad_norm': 0.00022444993373937905, 'learning_rate': 6.463146112104332e-06, 'epoch': 7.88}\n",
      "{'loss': 0.0, 'grad_norm': 0.00041196029633283615, 'learning_rate': 6.204004813025568e-06, 'epoch': 7.93}\n",
      "{'loss': 0.0001, 'grad_norm': 0.03660058230161667, 'learning_rate': 5.949427824924731e-06, 'epoch': 7.97}\n",
      "{'loss': 0.0003, 'grad_norm': 0.0009209653362631798, 'learning_rate': 5.699476967808168e-06, 'epoch': 8.02}\n",
      "{'loss': 0.0, 'grad_norm': 0.0014014133485034108, 'learning_rate': 5.454212938299255e-06, 'epoch': 8.06}\n",
      "{'loss': 0.0004, 'grad_norm': 0.0006947183283045888, 'learning_rate': 5.2136952948992346e-06, 'epoch': 8.11}\n",
      "{'loss': 0.0002, 'grad_norm': 0.003171609714627266, 'learning_rate': 4.977982443524304e-06, 'epoch': 8.15}\n",
      "{'loss': 0.0001, 'grad_norm': 0.007365130819380283, 'learning_rate': 4.747131623322737e-06, 'epoch': 8.2}\n",
      "{'loss': 0.0, 'grad_norm': 0.000861986365634948, 'learning_rate': 4.521198892775203e-06, 'epoch': 8.24}\n",
      "{'loss': 0.0, 'grad_norm': 0.0012264668475836515, 'learning_rate': 4.3002391160818775e-06, 'epoch': 8.29}\n",
      "{'loss': 0.0006, 'grad_norm': 0.16952396929264069, 'learning_rate': 4.0843059498395065e-06, 'epoch': 8.33}\n",
      "{'loss': 0.0, 'grad_norm': 0.0009846827015280724, 'learning_rate': 3.873451830011795e-06, 'epoch': 8.37}\n",
      "{'loss': 0.0001, 'grad_norm': 0.019185250625014305, 'learning_rate': 3.66772795919611e-06, 'epoch': 8.42}\n",
      "{'loss': 0.0, 'grad_norm': 0.0025469751562923193, 'learning_rate': 3.4671842941897765e-06, 'epoch': 8.46}\n",
      "{'loss': 0.0, 'grad_norm': 0.018324920907616615, 'learning_rate': 3.27186953385884e-06, 'epoch': 8.51}\n",
      "{'loss': 0.0, 'grad_norm': 0.0020132893696427345, 'learning_rate': 3.081831107312308e-06, 'epoch': 8.55}\n",
      "{'loss': 0.0, 'grad_norm': 0.0003746975853573531, 'learning_rate': 2.8971151623847587e-06, 'epoch': 8.6}\n",
      "{'loss': 0.0, 'grad_norm': 0.004205507691949606, 'learning_rate': 2.717766554430043e-06, 'epoch': 8.64}\n",
      "{'loss': 0.0016, 'grad_norm': 0.000688718690071255, 'learning_rate': 2.543828835428899e-06, 'epoch': 8.69}\n",
      "{'loss': 0.0, 'grad_norm': 0.0012399074621498585, 'learning_rate': 2.3753442434129997e-06, 'epoch': 8.73}\n",
      "{'loss': 0.0, 'grad_norm': 0.0054382155649363995, 'learning_rate': 2.212353692208172e-06, 'epoch': 8.78}\n",
      "{'loss': 0.0, 'grad_norm': 0.000340550031978637, 'learning_rate': 2.0548967614990507e-06, 'epoch': 8.82}\n",
      "{'loss': 0.0, 'grad_norm': 0.001895874971523881, 'learning_rate': 1.9030116872178316e-06, 'epoch': 8.86}\n",
      "{'loss': 0.0012, 'grad_norm': 0.004113242495805025, 'learning_rate': 1.7567353522592477e-06, 'epoch': 8.91}\n",
      "{'loss': 0.0, 'grad_norm': 0.010481349192559719, 'learning_rate': 1.6161032775241503e-06, 'epoch': 8.95}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0019955639727413654, 'learning_rate': 1.4811496132938196e-06, 'epoch': 9.0}\n",
      "{'loss': 0.0, 'grad_norm': 0.00011582118895603344, 'learning_rate': 1.3519071309370996e-06, 'epoch': 9.04}\n",
      "{'loss': 0.001, 'grad_norm': 0.004690435715019703, 'learning_rate': 1.2284072149524094e-06, 'epoch': 9.09}\n",
      "{'loss': 0.0, 'grad_norm': 0.009279237128794193, 'learning_rate': 1.1106798553464804e-06, 'epoch': 9.13}\n",
      "{'loss': 0.0, 'grad_norm': 0.0009650118299759924, 'learning_rate': 9.98753640351785e-07, 'epoch': 9.18}\n",
      "{'loss': 0.0004, 'grad_norm': 0.0017782844370231032, 'learning_rate': 8.926557494843085e-07, 'epoch': 9.22}\n",
      "{'loss': 0.0, 'grad_norm': 0.00012768867600243539, 'learning_rate': 7.924119469434665e-07, 'epoch': 9.27}\n",
      "{'loss': 0.0, 'grad_norm': 0.0003151655837427825, 'learning_rate': 6.980465753556376e-07, 'epoch': 9.31}\n",
      "{'loss': 0.0, 'grad_norm': 0.005587512161582708, 'learning_rate': 6.095825498629692e-07, 'epoch': 9.35}\n",
      "{'loss': 0.0005, 'grad_norm': 0.001710068783722818, 'learning_rate': 5.270413525587909e-07, 'epoch': 9.4}\n",
      "{'loss': 0.0, 'grad_norm': 0.013041343539953232, 'learning_rate': 4.5044302727100806e-07, 'epoch': 9.44}\n",
      "{'loss': 0.0, 'grad_norm': 0.001287495600990951, 'learning_rate': 3.7980617469479953e-07, 'epoch': 9.49}\n",
      "{'loss': 0.0001, 'grad_norm': 0.0014559546252712607, 'learning_rate': 3.1514794787571854e-07, 'epoch': 9.53}\n",
      "{'loss': 0.0, 'grad_norm': 0.00026841959333978593, 'learning_rate': 2.564840480443503e-07, 'epoch': 9.58}\n",
      "{'loss': 0.0, 'grad_norm': 0.0026367276441305876, 'learning_rate': 2.0382872080351166e-07, 'epoch': 9.62}\n",
      "{'loss': 0.0, 'grad_norm': 0.0028387613128870726, 'learning_rate': 1.571947526689349e-07, 'epoch': 9.67}\n",
      "{'loss': 0.0, 'grad_norm': 0.0002639052108861506, 'learning_rate': 1.1659346796426551e-07, 'epoch': 9.71}\n",
      "{'loss': 0.0, 'grad_norm': 0.010203645564615726, 'learning_rate': 8.203472607112295e-08, 'epoch': 9.76}\n",
      "{'loss': 0.0, 'grad_norm': 0.0020207695197314024, 'learning_rate': 5.352691903491303e-08, 'epoch': 9.8}\n",
      "{'loss': 0.0, 'grad_norm': 0.01273319125175476, 'learning_rate': 3.107696952694139e-08, 'epoch': 9.84}\n",
      "{'loss': 0.0, 'grad_norm': 0.004969801753759384, 'learning_rate': 1.4690329163363769e-08, 'epoch': 9.89}\n",
      "{'loss': 0.0004, 'grad_norm': 0.0012409585760906339, 'learning_rate': 4.370977181339386e-09, 'epoch': 9.93}\n",
      "{'loss': 0.0, 'grad_norm': 0.00021130008099135011, 'learning_rate': 1.214194727400253e-10, 'epoch': 9.98}\n",
      "100%|█████████████████████████████████████| 2240/2240 [1:24:51<00:00,  2.21s/it][INFO|trainer.py:2329] 2024-06-14 17:51:40,755 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 5091.7136, 'train_samples_per_second': 3.527, 'train_steps_per_second': 0.44, 'train_loss': 0.028165362878527438, 'epoch': 9.98}\n",
      "100%|█████████████████████████████████████| 2240/2240 [1:24:51<00:00,  2.27s/it]\n",
      "[INFO|trainer.py:3410] 2024-06-14 17:51:40,757 >> Saving model checkpoint to /Utilisateurs/umushtaq/models/PE_LI_paragraph_wo_comptypes_llama-3-8b-Instruct\n",
      "[INFO|configuration_utils.py:733] 2024-06-14 17:51:41,104 >> loading configuration file config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/config.json\n",
      "[INFO|configuration_utils.py:796] 2024-06-14 17:51:41,105 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2513] 2024-06-14 17:51:42,002 >> tokenizer config file saved in /Utilisateurs/umushtaq/models/PE_LI_paragraph_wo_comptypes_llama-3-8b-Instruct/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2522] 2024-06-14 17:51:42,003 >> Special tokens file saved in /Utilisateurs/umushtaq/models/PE_LI_paragraph_wo_comptypes_llama-3-8b-Instruct/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =      9.9777\n",
      "  total_flos               = 203661532GF\n",
      "  train_loss               =      0.0282\n",
      "  train_runtime            =  1:24:51.71\n",
      "  train_samples_per_second =       3.527\n",
      "  train_steps_per_second   =        0.44\n",
      "[INFO|modelcard.py:450] 2024-06-14 17:51:42,230 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 17:51:43,867 >> loading file tokenizer.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 17:51:43,869 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 17:51:43,870 >> loading file special_tokens_map.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2108] 2024-06-14 17:51:43,871 >> loading file tokenizer_config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/tokenizer_config.json\n",
      "[WARNING|logging.py:314] 2024-06-14 17:51:44,140 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/14/2024 17:51:44 - INFO - llamafactory.data.template - Replace eos token: <|eot_id|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Utilisateurs/umushtaq/.conda/envs/llama-factory-notebook/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "[INFO|configuration_utils.py:733] 2024-06-14 17:51:44,457 >> loading configuration file config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/config.json\n",
      "[INFO|configuration_utils.py:796] 2024-06-14 17:51:44,459 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"unsloth/llama-3-8b-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/14/2024 17:51:44 - INFO - llamafactory.model.utils.quantization - Quantizing model to 4 bit.\n",
      "06/14/2024 17:51:44 - INFO - llamafactory.model.patcher - Using KV cache for faster generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:3474] 2024-06-14 17:51:44,470 >> loading weights file model.safetensors from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1519] 2024-06-14 17:51:44,476 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:962] 2024-06-14 17:51:44,478 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c237d5959f5483db11790adf659637e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:4280] 2024-06-14 17:51:55,952 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4288] 2024-06-14 17:51:55,953 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at unsloth/llama-3-8b-Instruct.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:917] 2024-06-14 17:51:56,082 >> loading configuration file generation_config.json from cache at /Utilisateurs/umushtaq/.cache/huggingface/hub/models--unsloth--llama-3-8b-Instruct/snapshots/f77838872cca586fcbafa67efc77fb7d3afe775d/generation_config.json\n",
      "[INFO|configuration_utils.py:962] 2024-06-14 17:51:56,084 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128009\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/14/2024 17:51:56 - INFO - llamafactory.model.utils.attention - Using torch SDPA for faster training and inference.\n",
      "06/14/2024 17:51:56 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n",
      "06/14/2024 17:51:56 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n",
      "06/14/2024 17:51:56 - INFO - llamafactory.model.adapter - Loaded adapter(s): /Utilisateurs/umushtaq/models/PE_LI_paragraph_wo_comptypes_llama-3-8b-Instruct\n",
      "06/14/2024 17:51:56 - INFO - llamafactory.model.loader - all params: 8051232768\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90e5d3033e74ba28488a77c49a0ffc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/439 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Utilisateurs/umushtaq\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       N-Rel      0.941     0.939     0.940      3384\n",
      "         Rel      0.718     0.722     0.720       724\n",
      "\n",
      "    accuracy                          0.901      4108\n",
      "   macro avg      0.829     0.831     0.830      4108\n",
      "weighted avg      0.901     0.901     0.901      4108\n",
      "\n",
      "/Utilisateurs/umushtaq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Utilisateurs/umushtaq/.conda/envs/llama-factory-notebook/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "for model_instance in model_names: # 3 models\n",
    "\n",
    "    for dataset in dataset_names:\n",
    "\n",
    "        l = [model_instance] + dataset\n",
    "        \n",
    "        with open(\"tmp.pkl\", \"wb\") as fh:\n",
    "            \n",
    "            pickle.dump(l, fh)\n",
    "        \n",
    "        print(f\"\\nRunning experiment: {l}\")\n",
    "        \n",
    "        \n",
    "        %run ./PE_LI_finetune_v2.ipynb\n",
    "        %cd /Utilisateurs/umushtaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9afc00d2-8785-4576-9efd-b5398ccd9307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f0c17d7-eaf4-4ffb-81a4-2d3288cd2bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../models/PE_LI_llama-3-8b-Instruct-bnb-4bit/classification_report.pickle\", 'rb') as fh:\n",
    "#     x = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dabb5489-9fbb-4111-a86b-4557d68e68eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f890218-9867-4b70-a989-923d895fc6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../models/PE_LI_llama-3-8b-Instruct/classification_report.pickle\", 'rb') as fh:\n",
    "#     x = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "540c6c25-d094-49dc-9b62-f0b201fcdddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
