{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b092f16-851d-4a47-ae4f-2a85603d6c77",
   "metadata": {},
   "source": [
    "# Prepare dataset (jsonl file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8798ef15",
   "metadata": {},
   "source": [
    "- Prepare PE datasets for llama factory.\n",
    "\n",
    "- Paragraph level link identification-link type classificaiton (LI-LTC joint), with/without paragraph tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdfbf4b-663f-41af-85a1-266a48239c9e",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "872238e4-5235-4176-bd84-4cc384bca8d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "738bf52f-6876-40e0-b3cf-57026242db4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af75678-bbcc-4cfa-9b81-c9a66d170182",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0da5ee17-0803-41cc-91c9-1cec32f672d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.getcwd(), \"datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54f71f0d-b9eb-499d-b9a4-fd010bc6d874",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pe_df = pd.read_csv(os.path.join(data_dir, \"PE_data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7931292a-fd5c-4f8e-a9e8-24b5f5a16d4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pe_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6718a38d-9608-475c-9584-0976b928ea30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>para_id</th>\n",
       "      <th>para_types</th>\n",
       "      <th>para_text</th>\n",
       "      <th>adu_spans</th>\n",
       "      <th>ac_spans</th>\n",
       "      <th>ai_spans</th>\n",
       "      <th>AC_types</th>\n",
       "      <th>AR_pairs</th>\n",
       "      <th>AR_types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>prompt</td>\n",
       "      <td>&lt;prompt&gt; Should students be taught to compete ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>intro</td>\n",
       "      <td>&lt;para-intro&gt; It is always said that competitio...</td>\n",
       "      <td>[(76, 97)]</td>\n",
       "      <td>[(86, 97)]</td>\n",
       "      <td>[(76, 85)]</td>\n",
       "      <td>['MajorClaim']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>body</td>\n",
       "      <td>&lt;para-body&gt; First of all , &lt;AC&gt; through cooper...</td>\n",
       "      <td>[(1, 25), (26, 55), (56, 99), (100, 123)]</td>\n",
       "      <td>[(5, 25), (27, 55), (57, 99), (101, 123)]</td>\n",
       "      <td>[(1, 4), (26, 26), (56, 56), (100, 100)]</td>\n",
       "      <td>['Claim', 'Premise', 'Premise', 'Premise']</td>\n",
       "      <td>[(0, 1), (0, 2), (0, 3)]</td>\n",
       "      <td>['Support', 'Support', 'Support']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>body</td>\n",
       "      <td>&lt;para-body&gt; On the other hand , &lt;AC&gt; the signi...</td>\n",
       "      <td>[(1, 22), (24, 37), (39, 63), (76, 139), (155,...</td>\n",
       "      <td>[(6, 22), (30, 37), (41, 63), (77, 139), (156,...</td>\n",
       "      <td>[(1, 5), (24, 29), (39, 40), (76, 76), (155, 1...</td>\n",
       "      <td>['Premise', 'Claim', 'Premise', 'Premise', 'Cl...</td>\n",
       "      <td>[(1, 0), (4, 2), (4, 3)]</td>\n",
       "      <td>['Support', 'Support', 'Support']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>conclusion</td>\n",
       "      <td>&lt;para-conclusion&gt; Consequently , no matter fro...</td>\n",
       "      <td>[(1, 40)]</td>\n",
       "      <td>[(25, 40)]</td>\n",
       "      <td>[(1, 24)]</td>\n",
       "      <td>['MajorClaim']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>401</td>\n",
       "      <td>2230</td>\n",
       "      <td>prompt</td>\n",
       "      <td>&lt;prompt&gt; A greater proportion of the budget sh...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>401</td>\n",
       "      <td>2231</td>\n",
       "      <td>intro</td>\n",
       "      <td>&lt;para-intro&gt; In today ' s world , the concept ...</td>\n",
       "      <td>[(26, 51)]</td>\n",
       "      <td>[(33, 51)]</td>\n",
       "      <td>[(26, 32)]</td>\n",
       "      <td>['MajorClaim']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>401</td>\n",
       "      <td>2232</td>\n",
       "      <td>body</td>\n",
       "      <td>&lt;para-body&gt; &lt;AC&gt; The first reason why educatio...</td>\n",
       "      <td>[(0, 22), (24, 56), (58, 71), (72, 98)]</td>\n",
       "      <td>[(1, 22), (27, 56), (60, 71), (74, 98)]</td>\n",
       "      <td>[(0, 0), (24, 26), (58, 59), (72, 73)]</td>\n",
       "      <td>['Premise', 'Premise', 'Claim', 'Premise']</td>\n",
       "      <td>[(2, 0), (2, 1), (2, 3)]</td>\n",
       "      <td>['Support', 'Support', 'Support']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>401</td>\n",
       "      <td>2233</td>\n",
       "      <td>body</td>\n",
       "      <td>&lt;para-body&gt; The second reason why &lt;AC&gt; governm...</td>\n",
       "      <td>[(1, 25), (27, 53), (55, 88), (90, 128)]</td>\n",
       "      <td>[(5, 25), (31, 53), (57, 88), (93, 128)]</td>\n",
       "      <td>[(1, 4), (27, 30), (55, 56), (90, 92)]</td>\n",
       "      <td>['Claim', 'Premise', 'Premise', 'Premise']</td>\n",
       "      <td>[(2, 1), (0, 2), (2, 3)]</td>\n",
       "      <td>['Support', 'Support', 'Support']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>401</td>\n",
       "      <td>2234</td>\n",
       "      <td>conclusion</td>\n",
       "      <td>&lt;para-conclusion&gt; In conclusion , &lt;AC&gt; a great...</td>\n",
       "      <td>[(1, 37)]</td>\n",
       "      <td>[(4, 37)]</td>\n",
       "      <td>[(1, 3)]</td>\n",
       "      <td>['MajorClaim']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2235 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id  para_id  para_types  \\\n",
       "0            0        0      prompt   \n",
       "1            0        1       intro   \n",
       "2            0        2        body   \n",
       "3            0        3        body   \n",
       "4            0        4  conclusion   \n",
       "...        ...      ...         ...   \n",
       "2230       401     2230      prompt   \n",
       "2231       401     2231       intro   \n",
       "2232       401     2232        body   \n",
       "2233       401     2233        body   \n",
       "2234       401     2234  conclusion   \n",
       "\n",
       "                                              para_text  \\\n",
       "0     <prompt> Should students be taught to compete ...   \n",
       "1     <para-intro> It is always said that competitio...   \n",
       "2     <para-body> First of all , <AC> through cooper...   \n",
       "3     <para-body> On the other hand , <AC> the signi...   \n",
       "4     <para-conclusion> Consequently , no matter fro...   \n",
       "...                                                 ...   \n",
       "2230  <prompt> A greater proportion of the budget sh...   \n",
       "2231  <para-intro> In today ' s world , the concept ...   \n",
       "2232  <para-body> <AC> The first reason why educatio...   \n",
       "2233  <para-body> The second reason why <AC> governm...   \n",
       "2234  <para-conclusion> In conclusion , <AC> a great...   \n",
       "\n",
       "                                              adu_spans  \\\n",
       "0                                                    []   \n",
       "1                                            [(76, 97)]   \n",
       "2             [(1, 25), (26, 55), (56, 99), (100, 123)]   \n",
       "3     [(1, 22), (24, 37), (39, 63), (76, 139), (155,...   \n",
       "4                                             [(1, 40)]   \n",
       "...                                                 ...   \n",
       "2230                                                 []   \n",
       "2231                                         [(26, 51)]   \n",
       "2232            [(0, 22), (24, 56), (58, 71), (72, 98)]   \n",
       "2233           [(1, 25), (27, 53), (55, 88), (90, 128)]   \n",
       "2234                                          [(1, 37)]   \n",
       "\n",
       "                                               ac_spans  \\\n",
       "0                                                    []   \n",
       "1                                            [(86, 97)]   \n",
       "2             [(5, 25), (27, 55), (57, 99), (101, 123)]   \n",
       "3     [(6, 22), (30, 37), (41, 63), (77, 139), (156,...   \n",
       "4                                            [(25, 40)]   \n",
       "...                                                 ...   \n",
       "2230                                                 []   \n",
       "2231                                         [(33, 51)]   \n",
       "2232            [(1, 22), (27, 56), (60, 71), (74, 98)]   \n",
       "2233           [(5, 25), (31, 53), (57, 88), (93, 128)]   \n",
       "2234                                          [(4, 37)]   \n",
       "\n",
       "                                               ai_spans  \\\n",
       "0                                                    []   \n",
       "1                                            [(76, 85)]   \n",
       "2              [(1, 4), (26, 26), (56, 56), (100, 100)]   \n",
       "3     [(1, 5), (24, 29), (39, 40), (76, 76), (155, 1...   \n",
       "4                                             [(1, 24)]   \n",
       "...                                                 ...   \n",
       "2230                                                 []   \n",
       "2231                                         [(26, 32)]   \n",
       "2232             [(0, 0), (24, 26), (58, 59), (72, 73)]   \n",
       "2233             [(1, 4), (27, 30), (55, 56), (90, 92)]   \n",
       "2234                                           [(1, 3)]   \n",
       "\n",
       "                                               AC_types  \\\n",
       "0                                                    []   \n",
       "1                                        ['MajorClaim']   \n",
       "2            ['Claim', 'Premise', 'Premise', 'Premise']   \n",
       "3     ['Premise', 'Claim', 'Premise', 'Premise', 'Cl...   \n",
       "4                                        ['MajorClaim']   \n",
       "...                                                 ...   \n",
       "2230                                                 []   \n",
       "2231                                     ['MajorClaim']   \n",
       "2232         ['Premise', 'Premise', 'Claim', 'Premise']   \n",
       "2233         ['Claim', 'Premise', 'Premise', 'Premise']   \n",
       "2234                                     ['MajorClaim']   \n",
       "\n",
       "                      AR_pairs                           AR_types  \n",
       "0                           []                                 []  \n",
       "1                           []                                 []  \n",
       "2     [(0, 1), (0, 2), (0, 3)]  ['Support', 'Support', 'Support']  \n",
       "3     [(1, 0), (4, 2), (4, 3)]  ['Support', 'Support', 'Support']  \n",
       "4                           []                                 []  \n",
       "...                        ...                                ...  \n",
       "2230                        []                                 []  \n",
       "2231                        []                                 []  \n",
       "2232  [(2, 0), (2, 1), (2, 3)]  ['Support', 'Support', 'Support']  \n",
       "2233  [(2, 1), (0, 2), (2, 3)]  ['Support', 'Support', 'Support']  \n",
       "2234                        []                                 []  \n",
       "\n",
       "[2235 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41d9b63e-7645-4cb1-a59e-67c3b65585d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"['Claim', 'Claim', 'Claim', 'MajorClaim']\",\n",
       " \"['Claim', 'Claim', 'MajorClaim']\",\n",
       " \"['Claim', 'Claim', 'Premise', 'Claim', 'Premise']\",\n",
       " \"['Claim', 'Claim', 'Premise', 'MajorClaim']\",\n",
       " \"['Claim', 'Claim', 'Premise', 'Premise', 'Premise']\",\n",
       " \"['Claim', 'Claim', 'Premise', 'Premise']\",\n",
       " \"['Claim', 'Claim', 'Premise']\",\n",
       " \"['Claim', 'Claim']\",\n",
       " \"['Claim', 'MajorClaim', 'Claim', 'Claim']\",\n",
       " \"['Claim', 'MajorClaim', 'Claim']\",\n",
       " \"['Claim', 'MajorClaim']\",\n",
       " \"['Claim', 'Premise', 'Claim', 'Claim', 'MajorClaim']\",\n",
       " \"['Claim', 'Premise', 'Claim', 'Premise', 'MajorClaim']\",\n",
       " \"['Claim', 'Premise', 'Claim', 'Premise', 'Premise', 'Premise']\",\n",
       " \"['Claim', 'Premise', 'Claim', 'Premise', 'Premise']\",\n",
       " \"['Claim', 'Premise', 'Claim']\",\n",
       " \"['Claim', 'Premise', 'MajorClaim']\",\n",
       " \"['Claim', 'Premise', 'Premise', 'Claim', 'Premise', 'Claim']\",\n",
       " \"['Claim', 'Premise', 'Premise', 'Claim', 'Premise', 'Premise', 'Premise']\",\n",
       " \"['Claim', 'Premise', 'Premise', 'Claim', 'Premise', 'Premise']\",\n",
       " \"['Claim', 'Premise', 'Premise', 'Claim', 'Premise']\",\n",
       " \"['Claim', 'Premise', 'Premise', 'Claim']\",\n",
       " \"['Claim', 'Premise', 'Premise', 'MajorClaim']\",\n",
       " \"['Claim', 'Premise', 'Premise', 'Premise', 'Claim', 'Premise']\",\n",
       " \"['Claim', 'Premise', 'Premise', 'Premise', 'Claim']\",\n",
       " \"['Claim', 'Premise', 'Premise', 'Premise', 'MajorClaim']\",\n",
       " \"['Claim', 'Premise', 'Premise', 'Premise', 'Premise', 'Claim', 'Claim', 'Premise', 'Claim', 'Premise']\",\n",
       " \"['Claim', 'Premise', 'Premise', 'Premise', 'Premise', 'Claim', 'Premise', 'Premise']\",\n",
       " \"['Claim', 'Premise', 'Premise', 'Premise', 'Premise', 'Claim', 'Premise']\",\n",
       " \"['Claim', 'Premise', 'Premise', 'Premise', 'Premise', 'Claim']\",\n",
       " \"['Claim', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Claim', 'Premise']\",\n",
       " \"['Claim', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Claim']\",\n",
       " \"['Claim', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise']\",\n",
       " \"['Claim', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise']\",\n",
       " \"['Claim', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise']\",\n",
       " \"['Claim', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise']\",\n",
       " \"['Claim', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise']\",\n",
       " \"['Claim', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise']\",\n",
       " \"['Claim', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise']\",\n",
       " \"['Claim', 'Premise', 'Premise', 'Premise', 'Premise']\",\n",
       " \"['Claim', 'Premise', 'Premise', 'Premise']\",\n",
       " \"['Claim', 'Premise', 'Premise']\",\n",
       " \"['Claim', 'Premise']\",\n",
       " \"['Claim']\",\n",
       " \"['MajorClaim', 'Claim', 'Claim', 'Claim']\",\n",
       " \"['MajorClaim', 'Claim', 'Claim', 'MajorClaim']\",\n",
       " \"['MajorClaim', 'Claim', 'Claim', 'Premise', 'Premise', 'MajorClaim']\",\n",
       " \"['MajorClaim', 'Claim', 'Claim', 'Premise']\",\n",
       " \"['MajorClaim', 'Claim', 'Claim']\",\n",
       " \"['MajorClaim', 'Claim', 'MajorClaim', 'Claim', 'Claim']\",\n",
       " \"['MajorClaim', 'Claim', 'MajorClaim']\",\n",
       " \"['MajorClaim', 'Claim', 'Premise', 'Premise', 'Claim']\",\n",
       " \"['MajorClaim', 'Claim', 'Premise', 'Premise', 'Premise']\",\n",
       " \"['MajorClaim', 'Claim', 'Premise', 'Premise']\",\n",
       " \"['MajorClaim', 'Claim', 'Premise']\",\n",
       " \"['MajorClaim', 'Claim']\",\n",
       " \"['MajorClaim', 'MajorClaim', 'Claim', 'Premise']\",\n",
       " \"['MajorClaim', 'MajorClaim', 'Claim']\",\n",
       " \"['MajorClaim', 'MajorClaim']\",\n",
       " \"['MajorClaim', 'Premise', 'Claim']\",\n",
       " \"['MajorClaim', 'Premise', 'Premise', 'Premise', 'Claim', 'MajorClaim']\",\n",
       " \"['MajorClaim', 'Premise', 'Premise', 'Premise', 'Claim']\",\n",
       " \"['MajorClaim']\",\n",
       " \"['Premise', 'Claim', 'Claim', 'Premise', 'Premise']\",\n",
       " \"['Premise', 'Claim', 'MajorClaim', 'Claim']\",\n",
       " \"['Premise', 'Claim', 'MajorClaim']\",\n",
       " \"['Premise', 'Claim', 'Premise', 'Claim', 'Premise', 'Premise']\",\n",
       " \"['Premise', 'Claim', 'Premise', 'Claim']\",\n",
       " \"['Premise', 'Claim', 'Premise', 'Premise', 'Claim', 'Premise', 'Premise']\",\n",
       " \"['Premise', 'Claim', 'Premise', 'Premise', 'Claim', 'Premise']\",\n",
       " \"['Premise', 'Claim', 'Premise', 'Premise', 'Claim']\",\n",
       " \"['Premise', 'Claim', 'Premise', 'Premise', 'Premise', 'Claim', 'Premise']\",\n",
       " \"['Premise', 'Claim', 'Premise', 'Premise', 'Premise', 'Premise', 'Claim']\",\n",
       " \"['Premise', 'Claim', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise']\",\n",
       " \"['Premise', 'Claim', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise']\",\n",
       " \"['Premise', 'Claim', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise']\",\n",
       " \"['Premise', 'Claim', 'Premise', 'Premise', 'Premise', 'Premise']\",\n",
       " \"['Premise', 'Claim', 'Premise', 'Premise', 'Premise']\",\n",
       " \"['Premise', 'Claim', 'Premise', 'Premise']\",\n",
       " \"['Premise', 'Claim', 'Premise']\",\n",
       " \"['Premise', 'Claim']\",\n",
       " \"['Premise', 'Premise', 'Claim', 'Claim', 'Premise', 'Premise']\",\n",
       " \"['Premise', 'Premise', 'Claim', 'Claim', 'Premise']\",\n",
       " \"['Premise', 'Premise', 'Claim', 'Claim']\",\n",
       " \"['Premise', 'Premise', 'Claim', 'MajorClaim', 'Claim', 'Claim']\",\n",
       " \"['Premise', 'Premise', 'Claim', 'MajorClaim']\",\n",
       " \"['Premise', 'Premise', 'Claim', 'Premise', 'Claim', 'Claim']\",\n",
       " \"['Premise', 'Premise', 'Claim', 'Premise', 'Claim']\",\n",
       " \"['Premise', 'Premise', 'Claim', 'Premise', 'Premise', 'Claim', 'Premise', 'Premise']\",\n",
       " \"['Premise', 'Premise', 'Claim', 'Premise', 'Premise', 'Premise', 'Claim']\",\n",
       " \"['Premise', 'Premise', 'Claim', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise']\",\n",
       " \"['Premise', 'Premise', 'Claim', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise']\",\n",
       " \"['Premise', 'Premise', 'Claim', 'Premise', 'Premise', 'Premise', 'Premise']\",\n",
       " \"['Premise', 'Premise', 'Claim', 'Premise', 'Premise', 'Premise']\",\n",
       " \"['Premise', 'Premise', 'Claim', 'Premise', 'Premise']\",\n",
       " \"['Premise', 'Premise', 'Claim', 'Premise']\",\n",
       " \"['Premise', 'Premise', 'Claim']\",\n",
       " \"['Premise', 'Premise', 'Premise', 'Claim', 'Claim', 'Premise']\",\n",
       " \"['Premise', 'Premise', 'Premise', 'Claim', 'Premise', 'Claim']\",\n",
       " \"['Premise', 'Premise', 'Premise', 'Claim', 'Premise', 'Premise', 'Premise', 'Premise']\",\n",
       " \"['Premise', 'Premise', 'Premise', 'Claim', 'Premise', 'Premise']\",\n",
       " \"['Premise', 'Premise', 'Premise', 'Claim', 'Premise']\",\n",
       " \"['Premise', 'Premise', 'Premise', 'Claim']\",\n",
       " \"['Premise', 'Premise', 'Premise', 'Premise', 'Claim', 'Premise', 'Premise', 'Premise']\",\n",
       " \"['Premise', 'Premise', 'Premise', 'Premise', 'Claim', 'Premise', 'Premise']\",\n",
       " \"['Premise', 'Premise', 'Premise', 'Premise', 'Claim', 'Premise']\",\n",
       " \"['Premise', 'Premise', 'Premise', 'Premise', 'Claim']\",\n",
       " \"['Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Claim', 'Premise']\",\n",
       " \"['Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Claim']\",\n",
       " \"['Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Claim']\",\n",
       " \"['Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Claim']\",\n",
       " \"['Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Claim']\",\n",
       " \"['Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Premise', 'Claim']\",\n",
       " '[]'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(pe_df.AC_types.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135d6f22-441c-45dd-a453-741496b4dbef",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load train-test-split CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12d532d9-a611-45c1-8c31-81af94d4e5bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_split = pd.read_csv(\"datasets/train-test-split.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a90f8367-50c5-4580-b2f7-e9ffa71b5cf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d032851-ca72-46eb-b2e6-17575519512e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pe_df['split'] = pe_df['essay_id'].map(df_split['SET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7396ee97-9e99-4ed7-9366-a332f1fb2dbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8213da70-a6dd-4fce-9b52-ed2381f9064b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_ac_count(x):\n",
    "\n",
    "    return len(ast.literal_eval(x.AC_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4be6b766-a09f-4d3a-b357-1aeafe3789a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pe_df[\"AC_count\"] = pe_df.apply(lambda x: get_ac_count(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "019b0b8b-98e5-4f3b-ac90-a56450167293",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09719142-9932-494b-9310-a304dfd22590",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "TRAIN    1796\n",
       "TEST      439\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe_df.split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55a8bf0a-aad8-4d55-8e72-b0cba87a5b22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove paragraphs with 0 ACs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b987324e-6687-4b7a-aee2-51e0e6da35ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pe_df = pe_df[pe_df.AC_count > 0].reset_index() \n",
    "# we want model to learn that when there are 0 ACs, there should be 0 ARs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ed75aef-fb0c-4905-b8c2-cf9288fed0ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e06a175-4f49-4a4d-881c-95a6b1bda7b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "TRAIN    1796\n",
       "TEST      439\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe_df.split.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a578e2-63f5-4860-965c-ef5e659149a7",
   "metadata": {},
   "source": [
    "## Prepare prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f02ffd05-4249-4830-9752-5b96c2d48d27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def formatting_fct(instruction=\"\", input=\"\", output=\"\", mode=\"train\"):\n",
    "    \n",
    "    prompt_d ={\n",
    "            \n",
    "        \"instruction\": f\"{instruction}\",\n",
    "        \"input\": f\"{input}\",\n",
    "        \"output\": f\"{output if mode=='train' else ''}\"\n",
    "            \n",
    "        }\n",
    "    \n",
    "    return prompt_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bfdca2a-db4f-4e74-8ac7-24aeeacc7712",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"### You are an expert in Argument Mining. You are given a paragraph which contains argument components enclosed by <AC></AC> tags. Your task is to classify the argument components as well as to identify and classify argument relations between argument components in the paragraph. For each argument component, its AC type (str) is either \"MajorClaim\", \"Claim\" or \"Premise\". For each argument relation (target AC (int), source AC (int)), its link type (str) is either \"Support\" or \"Attack\". You must return two lists in following JSON format: {\"list_component_types\": [AC type (str), ..., AC type (str)], \"list_argument_relations_and_types\": [[target AC (int), source AC (int), link type (str)], ..., [target AC (int), source AC (int), link type (str)]]}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d3f085d-1921-4e57-adbd-dbfd8bd2d386",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### You are an expert in Argument Mining. You are given a paragraph which contains argument components enclosed by <AC></AC> tags. Your task is to classify the argument components as well as to identify and classify argument relations between argument components in the paragraph. For each argument component, its AC type (str) is either \"MajorClaim\", \"Claim\" or \"Premise\". For each argument relation (target AC (int), source AC (int)), its link type (str) is either \"Support\" or \"Attack\". You must return two lists in following JSON format: {\"list_component_types\": [AC type (str), ..., AC type (str)], \"list_argument_relations_and_types\": [[target AC (int), source AC (int), link type (str)], ..., [target AC (int), source AC (int), link type (str)]]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3aeb77b7-4b31-4e97-8d3f-b5d436496372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def replace_substring_with_position(main_string, substring, ac_types):\n",
    "    result = \"\"\n",
    "    start = 0\n",
    "    current_index = 0\n",
    "    position = 0  # Initialize position counter\n",
    "    \n",
    "    while current_index < len(main_string):\n",
    "        current_index = main_string.find(substring, current_index)\n",
    "        if current_index == -1:\n",
    "            break\n",
    "        \n",
    "        # Append part of the string before the current match\n",
    "        result += main_string[start:current_index]\n",
    "        \n",
    "        # Append the replacement\n",
    "        sstring = substring[:-1]\n",
    "        ac_type = ac_types[position]\n",
    "        \n",
    "        # result += f\"{sstring}{position}, {ac_type}>\" \n",
    "        result += f\"{sstring}{position}>\" \n",
    "        \n",
    "        # Update the start to be the end of the current match\n",
    "        start = current_index + len(substring)\n",
    "        current_index = start\n",
    "        \n",
    "        # Increment the position counter\n",
    "        position += 1\n",
    "    \n",
    "    # Append any remaining part of the string\n",
    "    result += main_string[start:]\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f659f403-2aca-41a6-af45-44145a84591a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_input(paragraph, ac_types):\n",
    "\n",
    "    paragraph = paragraph.replace(\"<prompt> \", \"<topic> \")\n",
    "    paragraph = paragraph.replace(\" </prompt>\", \" </topic>\") \n",
    "    # HUGO: comment the next 8 lines for paragraph tags. Leave as is for no paragraph tags.\n",
    "    paragraph = paragraph.replace(\"<topic> \", \"\")\n",
    "    paragraph = paragraph.replace(\" </topic>\", \"\") \n",
    "    paragraph = paragraph.replace(\"<para-intro> \", \"\")\n",
    "    paragraph = paragraph.replace(\" </para-intro>\", \"\")\n",
    "    paragraph = paragraph.replace(\"<para-body> \", \"\")\n",
    "    paragraph = paragraph.replace(\" </para-body>\", \"\")\n",
    "    paragraph = paragraph.replace(\"<para-conclusion> \", \"\")\n",
    "    paragraph = paragraph.replace(\" </para-conclusion>\", \"\")\n",
    "    \n",
    "    \n",
    "    paragraph = replace_substring_with_position(paragraph, \"<AC>\", ast.literal_eval(ac_types))\n",
    "    paragraph = replace_substring_with_position(paragraph, \"</AC>\", ast.literal_eval(ac_types))\n",
    "\n",
    "    \n",
    "    question = f\"\"\"### Here is the paragraph text: {paragraph}\"\"\"\n",
    "    \n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cbf4933-227b-4895-8fc4-b07020d3b66b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_answer(ac_types, ar_pairs, ar_types):\n",
    "    answer_2 = [[x[0], x[1], y] for x,y in zip(ast.literal_eval(ar_pairs), ast.literal_eval(ar_types))]\n",
    "    answer_1 = [x for x in ast.literal_eval(ac_types)]\n",
    "    return json.dumps({\"list_component_types\": answer_1, \"list_argument_relations_and_types\": answer_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "919a1870-1ae1-4491-a06e-c90ebb2aaad4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(formatting_fct(instruction, question, answer, mode=\"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "673ae0a3-7e4b-4811-86eb-9ee46fe70aed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "TRAIN    1796\n",
       "TEST      439\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe_df.split.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9056fd22-4718-436e-bfc3-42a433d5bf3f",
   "metadata": {},
   "source": [
    "## Prepare data files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0baac15-666a-4181-b5c4-af9f7ab668b9",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9c0f082-2f50-4543-abcd-7a64726ad7ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_file_train = []\n",
    "\n",
    "for i, _ in pe_df[pe_df[\"split\"] == \"TRAIN\"].iterrows():\n",
    "    \n",
    "    question = build_input(pe_df.iloc[i].para_text, pe_df.iloc[i].AC_types)\n",
    "    answer = build_answer(pe_df.iloc[i].AC_types, pe_df.iloc[i].AR_pairs, pe_df.iloc[i].AR_types)\n",
    "    \n",
    "    data_file_train.append( formatting_fct(instruction, question, answer, mode=\"train\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52f56e72-44f2-44e9-8a91-dc4023de5dde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1796"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_file_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6597503e-a445-49fc-b190-87825192ace1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': '### You are an expert in Argument Mining. You are given a paragraph which contains argument components enclosed by <AC></AC> tags. Your task is to classify the argument components as well as to identify and classify argument relations between argument components in the paragraph. For each argument component, its AC type (str) is either \"MajorClaim\", \"Claim\" or \"Premise\". For each argument relation (target AC (int), source AC (int)), its link type (str) is either \"Support\" or \"Attack\". You must return two lists in following JSON format: {\"list_component_types\": [AC type (str), ..., AC type (str)], \"list_argument_relations_and_types\": [[target AC (int), source AC (int), link type (str)], ..., [target AC (int), source AC (int), link type (str)]]}\\n', 'input': '### Here is the paragraph text: Should students be taught to compete or to cooperate ?', 'output': '{\"list_component_types\": [], \"list_argument_relations_and_types\": []}'}\n",
      "\n",
      "{'instruction': '### You are an expert in Argument Mining. You are given a paragraph which contains argument components enclosed by <AC></AC> tags. Your task is to classify the argument components as well as to identify and classify argument relations between argument components in the paragraph. For each argument component, its AC type (str) is either \"MajorClaim\", \"Claim\" or \"Premise\". For each argument relation (target AC (int), source AC (int)), its link type (str) is either \"Support\" or \"Attack\". You must return two lists in following JSON format: {\"list_component_types\": [AC type (str), ..., AC type (str)], \"list_argument_relations_and_types\": [[target AC (int), source AC (int), link type (str)], ..., [target AC (int), source AC (int), link type (str)]]}\\n', 'input': \"### Here is the paragraph text: It is always said that competition can effectively promote the development of economy . In order to survive in the competition , companies continue to improve their products and service , and as a result , the whole society prospers . However , when we discuss the issue of competition or cooperation , what we are concerned about is not the whole society , but the development of an individual ' s whole life . From this point of view , I firmly believe that <AC0> we should attach more importance to cooperation during primary education </AC0> .\", 'output': '{\"list_component_types\": [\"MajorClaim\"], \"list_argument_relations_and_types\": []}'}\n",
      "\n",
      "{'instruction': '### You are an expert in Argument Mining. You are given a paragraph which contains argument components enclosed by <AC></AC> tags. Your task is to classify the argument components as well as to identify and classify argument relations between argument components in the paragraph. For each argument component, its AC type (str) is either \"MajorClaim\", \"Claim\" or \"Premise\". For each argument relation (target AC (int), source AC (int)), its link type (str) is either \"Support\" or \"Attack\". You must return two lists in following JSON format: {\"list_component_types\": [AC type (str), ..., AC type (str)], \"list_argument_relations_and_types\": [[target AC (int), source AC (int), link type (str)], ..., [target AC (int), source AC (int), link type (str)]]}\\n', 'input': '### Here is the paragraph text: First of all , <AC0> through cooperation , children can learn about interpersonal skills which are significant in the future life of all students </AC0> . <AC1> What we acquired from team work is not only how to achieve the same goal with others but more importantly , how to get along with others </AC1> . <AC2> During the process of cooperation , children can learn about how to listen to opinions of others , how to communicate with others , how to think comprehensively , and even how to compromise with other team members when conflicts occurred </AC2> . <AC3> All of these skills help them to get on well with other people and will benefit them for the whole life </AC3> .', 'output': '{\"list_component_types\": [\"Claim\", \"Premise\", \"Premise\", \"Premise\"], \"list_argument_relations_and_types\": [[0, 1, \"Support\"], [0, 2, \"Support\"], [0, 3, \"Support\"]]}'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    \n",
    "    print(data_file_train[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e073169c-930f-4247-9bc8-f403fc0c4186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 'Support'], [0, 2, 'Support'], [0, 3, 'Support']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(data_file_train[2][\"output\"])[\"list_argument_relations_and_types\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f60effa7-5990-4cfe-851b-ffd42d08d3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1796"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_file_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d704569-fbb9-4fdd-bc3a-4baf4acbbb38",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "158d164b-817a-40db-a3c8-718e286568f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_test = []\n",
    "\n",
    "for i, _ in pe_df[pe_df.split == \"TEST\"].iterrows():\n",
    "    \n",
    "    question = build_input(pe_df.iloc[i].para_text, pe_df.iloc[i].AC_types)\n",
    "    answer = build_answer(pe_df.iloc[i].AC_types, pe_df.iloc[i].AR_pairs, pe_df.iloc[i].AR_types)\n",
    "    \n",
    "    data_file_test.append( formatting_fct(instruction, question, answer, mode=\"train\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0edc2c43-0f6f-42a6-b73b-1643150b451b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1796, 439)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_file_train), len(data_file_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63843ae8-4157-47da-8ae1-4113ca764535",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': '### You are an expert in Argument Mining. You are given a paragraph which contains argument components enclosed by <AC></AC> tags. Your task is to classify the argument components as well as to identify and classify argument relations between argument components in the paragraph. For each argument component, its AC type (str) is either \"MajorClaim\", \"Claim\" or \"Premise\". For each argument relation (target AC (int), source AC (int)), its link type (str) is either \"Support\" or \"Attack\". You must return two lists in following JSON format: {\"list_component_types\": [AC type (str), ..., AC type (str)], \"list_argument_relations_and_types\": [[target AC (int), source AC (int), link type (str)], ..., [target AC (int), source AC (int), link type (str)]]}\\n', 'input': '### Here is the paragraph text: Will newspapers become a thing of the past ?', 'output': '{\"list_component_types\": [], \"list_argument_relations_and_types\": []}'}\n",
      "\n",
      "{'instruction': '### You are an expert in Argument Mining. You are given a paragraph which contains argument components enclosed by <AC></AC> tags. Your task is to classify the argument components as well as to identify and classify argument relations between argument components in the paragraph. For each argument component, its AC type (str) is either \"MajorClaim\", \"Claim\" or \"Premise\". For each argument relation (target AC (int), source AC (int)), its link type (str) is either \"Support\" or \"Attack\". You must return two lists in following JSON format: {\"list_component_types\": [AC type (str), ..., AC type (str)], \"list_argument_relations_and_types\": [[target AC (int), source AC (int), link type (str)], ..., [target AC (int), source AC (int), link type (str)]]}\\n', 'input': '### Here is the paragraph text: The internet has been more and more popular for recent years , providing people with a huge source of information . As a result of this , print media such as newspapers have experienced a dramatic decline in the number of readers . Some people , however , still believe that they can exist for long time ; others disagree , arguing that <AC0> newspapers have lost their competitive advantage to sustain their prolonged existence </AC0> . Personally , I am inclined to agree with the latter view for following reasons .', 'output': '{\"list_component_types\": [\"MajorClaim\"], \"list_argument_relations_and_types\": []}'}\n",
      "\n",
      "{'instruction': '### You are an expert in Argument Mining. You are given a paragraph which contains argument components enclosed by <AC></AC> tags. Your task is to classify the argument components as well as to identify and classify argument relations between argument components in the paragraph. For each argument component, its AC type (str) is either \"MajorClaim\", \"Claim\" or \"Premise\". For each argument relation (target AC (int), source AC (int)), its link type (str) is either \"Support\" or \"Attack\". You must return two lists in following JSON format: {\"list_component_types\": [AC type (str), ..., AC type (str)], \"list_argument_relations_and_types\": [[target AC (int), source AC (int), link type (str)], ..., [target AC (int), source AC (int), link type (str)]]}\\n', 'input': '### Here is the paragraph text: First of all , <AC0> to obtain information , using the internet is quicker and more convenient than reading newspapers </AC0> . <AC1> Contrary to the past when people had to wait long hours to take a daily newspaper , nowadays , they can acquire latest news updated every second through their mobile phones or computers connected to the internet , everywhere and at anytime </AC1> . <AC2> As can be seen , these devices and machines are very common in all parts of the world , making it easier for people to read a number of things that newspapers can not provide in only some pages </AC2> . Hence , <AC3> the print media has failed to keep its important role in the provision of information </AC3> .', 'output': '{\"list_component_types\": [\"Premise\", \"Premise\", \"Premise\", \"Claim\"], \"list_argument_relations_and_types\": [[3, 0, \"Support\"], [3, 1, \"Support\"], [3, 2, \"Support\"]]}'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    \n",
    "    print(data_file_test[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a8dad5-0a92-4460-a027-64e9d6ffba6a",
   "metadata": {},
   "source": [
    "## Save `jsonl` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc6ec3c9-7bee-4221-ba9e-1db23a6ed912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1796"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_file_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "828863ac-a9f2-497a-8a1f-92b7685d1a48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = os.path.join(os.getcwd(), \"datasets/PE_ATC-LI-LTC_paragraph_wo_tags_train.json\")\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    \n",
    "    json.dump(data_file_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c0ed1c8-af63-42e5-831b-7a4b501241f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = os.path.join(os.getcwd(), \"datasets/PE_ATC-LI-LTC_paragraph_wo_tags_test.json\")\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    \n",
    "    json.dump(data_file_test, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b6234952-fc1f-4f58-9a0a-25131e430049",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# file_path = os.path.join(os.getcwd(), \"datasets/PE_LI_val.json\")\n",
    "\n",
    "# with open(file_path, 'w') as file:\n",
    "    \n",
    "#     json.dump(data_file_val, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b947b2f-2989-4d1b-a07d-87ff80aa8cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
